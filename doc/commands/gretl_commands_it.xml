<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE commandref SYSTEM "gretl_commands.dtd">

<commandref language="italian">

  <?PSGML NOFILL label code altforms altform menu-path equation other-access?>

  <command name="add" section="Tests" label="Aggiunge variabili al modello">

    <usage>
      <arguments>
        <argument>varlist</argument>
      </arguments>
      <options>
	<option>
	  <flag>--lm</flag>
	  <effect>effettua un test LM, solo OLS</effect>
	</option>
	<option>
	  <flag>--auto</flag>
	  <optparm>criterio</optparm>
	  <effect>stepwise <quote>in avanti</quote>, solo OLS</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le stime del modello aumentato</effect>
	</option>
 	<option>
 	  <flag>--silent</flag>
 	  <effect>non mostra nulla</effect>
 	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
        <option>
          <flag>--both</flag>
          <effect>aggiunge come regressore e come strumento (vedi sotto)</effect>
        </option>
      </options>
      <examples>
        <example>add 5 7 9</example>
        <example>add xx yy zz --quiet</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Va invocato dopo un comando di stima. A meno che non siano
	usate le opzioni <opt>lm</opt> o <opt>auto</opt>, esegue un
	test congiunto per l'aggiunta delle variabili specificate
	all'ultimo modello stimato. Viene stimata una versione
	ampliata del modello originale, includendo le variabili in
	<repl>varlist</repl>, e viene eseguito un test di Wald sul
	modello ampliato. Il modello ampliato sostituisce l'originale
	come <quote>ultimo modello</quote> allo scopo, ad esempio, di
	recuperare i residui come <fncref targ="$uhat"/> o di eseguire
	ulteriori test. Si può avere accesso ai risultati
	del Wald test tramite <fncref targ="$test"/> e <fncref
	targ="$pvalue"/>.
      </para>
      <para context="cli">
	L'opzione <opt>both</opt> è specifica per le stime con i
	minimi quadrati a due stadi: essa indica che le nuove
	variabili vanno aggiunte sia alla lista dei regressori che a
	quella degli strumenti; di default, infatti, la
	<repl>varlist</repl> viene aggiunta soltanto ai regressori.
      </para>
      <subhead context="cli">L'opzione lm</subhead>
      <para context="cli">
	Con l'opzione <opt>lm</opt> (disponibile solo per i modelli
	stimati via OLS), viene effettuato un test LM. Viene eseguita
	una regressione ausiliaria in cui la variabile dipendente è il
	residuo dell'ultimo modello e le variabili indipendenti sono
	quello del modello originale più <repl>varlist</repl>. Sotto
	l'ipotesi nulla che le variabili aggiuntive non abbiano potere
	esplicativo, il prodotto fra l'R-quadro non aggiustato della
	regressione ausiliaria e il numero di osservazioni si
	distribuisce come una chi quadro con tanti gradi di libertà
	quante sono le variabili in <repl>varlist</repl>. In questo
	caso, il modello originale non viene rimpiazzato.
      </para>
      <subhead context="cli">L'opzione auto</subhead>
      <para context="cli">
	Con l'opzione <opt>auto</opt> (incompatibile con
	<opt>lm</opt>) si effettua una regressione stepwise in avanti,
	utilizzando l'algoritmo QR descritto da <cite
	key="hastie20">Hastie et al (2020)</cite>. In questo caso,
	<repl>varlist</repl> viene interpretata come un elenco di
	<emphasis>candidati</emphasis> da aggiungere al modello
	originale. A ogni passaggio, il metodo determina quale
	candidato offre il maggiore miglioramento nell'adattamento in
	base al criterio specificato (indicato come parametro
	dell'opzione). L'algoritmo si arresta quando non è possibile
	alcun ulteriore miglioramento. Il criterio deve assumere una
	di queste forme:
      </para>
      <ilist context="cli">
	<li>
	  <para>
	    Un criterio di informazione: <lit>AIC</lit>,
	    <lit>BIC</lit> o <lit>HQC</lit>. Il candidato
	    <quote>migliore</quote> a ogni passaggio è quindi quello
	    che fornisce la maggiore riduzione nel criterio
	    selezionato.
	</para>
	</li>
	<li>
	  <para>
	    Un valore &alpha; compreso fra 0 e 1. In questo caso, il
	    criterio è dato dalla somma dei quadrati dei
	    residui. L'algoritmo si arresta quando nessun candidato
	    rimanente fornisce una riduzione dell'SSR statisticamente
	    significativa al livello  &alpha; con un test chi-quadro.
      </para>
    </li>
  </ilist>
  <para context="gui">
    Sono disponibili tre opzioni:
  </para>
  <ilist context="gui">
    <li>
      <para>
      Test di Wald: le variabili selezionate vengono aggiunte al
      modello precedente e il modello ampliato viene stimato. Viene
      visualizzata una statistica del test di Wald per la
      significatività congiunta delle variabili aggiunte, insieme al
      relativo p-value.
      </para>
    </li>
    <li>
      <para>
	Test LM: viene eseguito un test del moltiplicatore di Lagrange
	per la significatività congiunta delle variabili aggiunte,
	senza stima del modello ampliato.
      </para>
    </li>
    <li>
      <para>
	Aggiunta stepwise: le variabili aggiuntive vengono aggiunte
	sequenzialmente. A ogni passaggio viene aggiunta la variabile
	che fornisce il maggiore miglioramento nel modello. Il
	processo si interrompe quando nessuna delle variabili
	rimanenti produce un miglioramento. In questo caso è
	necessario scegliere un criterio: uno dei criteri informativi
	(AIC, BIC, HQC) o SSR. Se si seleziona SSR, è necessario
	specificare anche un livello di significatività, &alpha;, per
	verificare se ciascuna variabile merita l'inclusione.
      </para>
    </li>
  </ilist>
</description>

<gui-access>
  <menu-path>Finestra del modello, /Test/ADD - Aggiungi variabili</menu-path>
</gui-access>

  </command>

  <command name="addline" section="Graphs" label="Aggiunge una linea al grafico"
	   context="gui">

    <description>
      <para>
        Questa finestra di dialogo permette di aggiungere a un grafico
        una linea, definita attraverso una formula che deve essere
        un'espressione accettabile da gnuplot. Occorre usare
        <lit>x</lit> per indicare il valore della variabile sull'asse
        x. Si noti inoltre che gnuplot usa <lit>**</lit> per
        l'elevamento a potenza, e il punto <quote>.</quote> come
        separatore decimale. Esempi:
      </para>
      <code>
	10+0.35*x
	100+5.3*x-0.12*x**2
	sin(x)
	exp(sqrt(pi*x))
      </code>
    </description>
  </command>

  <command name="adf" section="Tests" label="Test Dickey-Fuller aumentato">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>test senza costante</effect>
	</option>
	<option>
	  <flag>--c</flag>
	  <effect>solo con la costante</effect>
	</option>
	<option>
	  <flag>--ct</flag>
	  <effect>con costante e trend</effect>
	</option>
	<option>
	  <flag>--ctt</flag>
	  <effect>con costante, trend e trend al quadrato</effect>
	</option>
        <option>
	  <flag>--seasonals</flag>
	  <effect>include variabili dummy stagionali</effect>
        </option>
        <option>
          <flag>--gls</flag>
          <effect>rimuove la media o il trend usando GLS</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i risultati della regressione</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
	<option>
	  <flag>--difference</flag>
	  <effect>usa la differenza prima della variabile</effect>
	</option>
	<option>
	  <flag>--test-down</flag>
	  <optparm optional="true">criterio</optparm>
	  <effect>ordine di ritardo automatico</effect>
	</option>
	<option>
	  <flag>--perron-qu</flag>
	  <effect>si veda di seguito</effect>
	</option>
      </options>
      <examples>
	<example>adf 0 y</example>
        <example>adf 2 y --nc --c --ct</example>
        <example>adf 12 y --c --test-down</example>
	<demos>
	  <demo>jgm-1996.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="gui">
	Questo comando richiede un ordine di ritardo intero; se si
	indica un ordine pari a zero, viene eseguito un test
	Dickey&ndash;Fuller standard (non aumentato). Il comando
	calcola una serie di test Dickey&ndash;Fuller sulla variabile
	selezionata, assumendo come ipotesi nulla che la variabile
	abbia una radice unitaria. Se si usa l'opzione di
	differenziazione, i test vengono condotti sulla differenza
	prima della variabile e la discussione che segue va riferita a
	questa trasformazione della variabile.
      </para>

      <para context="cli">
	Le opzioni precedenti e la discussione seguente si riferiscono
	per lo più all'uso del comando <lit>adf</lit> con serie
	storiche vere e proprie. La discussione dell'uso con dati
	panel è esposta nella sezione <quote>Dati Panel</quote>.
      </para>

      <para context="cli">
	Calcola una serie di test Dickey&ndash;Fuller sulle variabili
	specificate, assumendo come ipotesi nulla che le variabili
	abbiano una radice unitaria. Se si usa l'opzione
	<opt>difference</opt>, i test vengono condotti sulla
	differenza prima delle variabili e la discussione che segue va
	riferita a questa trasformazione delle variabili.
      </para>

      <para context="cli">
        Per impostazione predefinita, vengono mostrate due varianti
        del test: una basata su una regressione che contiene solo una
        costante, e una che include la costante e un trend lineare. È
        possibile controllare le varianti specificando una o più fra
        le opzioni <opt>nc</opt>, <opt>c</opt>, <opt>ct</opt>,
        <opt>ctt</opt>.
      </para>

      <para context="cli">
	L'opzione <opt>gls</opt> può essere utilizzata congiuntamente
	alle opzioni <opt>c</opt> e <opt>ct</opt>.  L'effetto di
	questa opzione è che la rimozione della media o del trend
	lineare dalla variabile che deve essere testata è fatta
	utilizzando la procedura GLS suggerita da <cite
	key="ERS96">Elliott, Rothenberg e Stock (1996)</cite>, la
	quale restituisce un test di potenza superiore al test
	standard di Dickey&ndash;Fuller.  Questa opzione non è
	compatibile con <opt>nc</opt>,<opt>ctt</opt> o
	<opt>seasonals</opt>.
      </para>

      <para>
	In tutti i casi, la variabile dipendente nella regressione
	usata per calcolare il test è la differenza prima della
	variabile specificata, <math>y</math>, e la variabile
	indipendente più importante è il ritardo (di ordine uno) di
	<math>y</math>. Il modello è costruito in modo che il
	coefficiente della variabile ritardata <math>y</math> sia pari a
	1 meno la radice. Ad esempio, il modello con una costante può
	essere scritto come <equation status="display"
	tex="\[(1-L)y_t=\beta_0+(\alpha-1)y_{t-1}+\epsilon_t\]"
	ascii="(1 - L)y(t) = b0 + (a-1)y(t-1) + e(t)" graphic="adf1"/>
	Sotto l'ipotesi nulla di radice unitaria il coefficiente della
	<math>y</math> ritardata è nullo; sotto l'alternativa che
	<math>y</math> sia stazionaria il coefficiente è negativo. Di
	conseguenza, questo test è intrinsecamente a una coda.
      </para>

      <subhead context="cli">Selezione dell'ordine dei ritardi</subhead>

      <para context="cli">
	Nella versione più semplice del test si assume che il termine
	di errore nella regressione del test sia serialmente
	incorrelato.  Poiché questo è spesso implausibile, di solito
	la specificazione viene estesa includendo uno o più ritardi
	della variabile dipendente, dando così luogo al cosiddetto
	test ADF (Augmented Dickey&ndash;Fuller).  L'argomento
	<repl>ordine</repl> indica il numero di tali ritardi,
	<math>k</math>, che può dipendere dall'ampiezza campionaria
	<math>T</math>.
      </para>
      <ilist context="cli">
	<li>
	  <para>
	    Per selezionare un <math>k</math> fisso, basta inserire un
	    numero non negativo per <repl>ordine</repl>.
	  </para>
	</li>
	<li>
	  <para>
	    Per avere un numero di ritardi dipendente da
	    <math>T</math>, specificare come <repl>ordine</repl> il
	    numero &minus;1. In questo caso, l'ordine viene
	    automaticamente scelto secondo l'indicazione di <cite
	    key="schwert89">Schwert (1989)</cite>, ossia la parte
	    intera di 12(<math>T</math>/100)<sup>0.25</sup>.
	  </para>
	</li>
      </ilist>

      <para context="cli">
	In generale, però, non si sa quanti ritardi siano necessari
	per <quote>pulire</quote> i residui della regressione test.
	Spesso si specifica il valore <emphasis>massimo</emphasis> di
	<math>k</math>, lasciando decidere ai dati il numero di
	ritardi effettivo. Per fare questo, c'è l'opzione
	<opt>test-down</opt>: il criterio usato per scegliere il
	<math>k</math> ottimale è determinato dal parametro dato a
	questa opzione, che deve essere uno fra <lit>AIC</lit>
	(default), <lit>BIC</lit> o <lit>tstat</lit>.
      </para>

      <para context="gui">
        Se l'ordine di ritardi, <math>k</math>, è maggiore di 0, ai
        regressori di ognuna delle regressioni calcolate per il test
        saranno aggiunti <math>k</math> ritardi della variabile
        dipendente, con la precisazione che segue. Se viene
        selezionata la casella <quote>test per il ritardo
        massimo</quote>, l'ordine selezionato verrà considerato come
        ordine massimo, e l'ordine da usare effettivamente sarà
        ricavato applicando la seguente procedura di test
        <quote>all'indietro</quote>, usando il criterio scelto tramite
        la tendina associata.
      </para>

      <para context="cli">
	Quando si testa "all'indietro" con l'AIC o il BIC, l'ordine
	dei ritardi finale viene scelto in modo da ottimizzare
	rispettivamente una versione modificata del Criterio di
	Informazione di Akaike o del Criterio Bayesiano di
	Schwartz. La procedura varia a seconda se sia stata scelta
	l'opzione <opt>gls</opt>: con la detrendizzazione GLS, i
	valori AIC e BIC sono quelli <quote>modificati</quote>
	descritti in <cite key="ng-perron01">Ng e Perron
	(2001)</cite>, altrimenti sono quelli standard. Nel caso GLS è
	disponibile un'ulteriore opzione, e cioè <opt>perron-qu</opt>;
	essa fa sì che i criteri di informazione modificati siano
	calcolati secondo il metodo raccomandato in <cite
	key="perron-qu07">Perron e Qu (2007)</cite>. In quest'ultimo
	caso, i dati sono prima centrati in media o detrendizzati mediante
	OLS; il GLS viene applicato dopo aver scelto l'ordine dei ritardi.
      </para>

      <para context="gui">
	Quando si testa "all'indietro", l'ordine dei ritardi finale
	viene scelto in modo da ottimizzare rispettivamente una
	versione modificata del Criterio di Informazione di Akaike o
	del Criterio Bayesiano di Schwartz.
      </para>

      <para>
	Quando si testa "all'indietro" usando la statistica
	<math>t</math>, la procedura è la seguente:
      </para>
      <nlist>
	<li><para>
	  Stima della regressione Dickey&ndash;Fuller con
	  <math>k</math> ritardi della variabile dipendente.
	</para>
	</li>
	<li><para>Se l'ultimo ritardo è significativo, si esegue il
	test con l'ordine di ritardo <math>k</math>.  Altrimenti, si
	imposta <math>k</math> = <math>k</math> &minus; 1; se
	<math>k</math> = 0, si esegue il test con ordine di ritardo 0,
	altrimenti si va al punto 1.
      </para>
	</li>
      </nlist>

      <para>
        Durante il punto 2 spiegato sopra, <quote>significativo</quote>
        significa che la statistica <math>t</math> per l'ultimo ritardo
        abbia un <emphasis>p</emphasis>-value asintotico a due code per la
        distribuzione normale pari a 0.10 o inferiore.
      </para>

      <para context="cli">
	In sostanza, se accettiamo i vari argomenti di Perron, Ng, Qu
	e Schwert citati sopra, il comando più appropriato per testare
	una serie <lit>y</lit> è qualcosa del tipo:
      </para>
      <code context="cli">
	adf -1 y --c --gls --test-down --perron-qu
      </code>
      <para context="cli">
	(Sostituendo <opt>ct</opt> a <opt>c</opt> se la serie
	contiene un trend evidente.)  L'ordine dei ritardi del test
	verrà determinato testando all'indietro con il criterio AIC
	modificato partendo del massimo di Schwert maximum, col
	raffinamento di Perron&ndash;Qu.
      </para>

      <para>
        I <emphasis>p-</emphasis>value per questo test sono basati su
        stime della superficie di risposta. Se non si usa il GLS, essi
        sono tratti da <cite key="mackinnon96">MacKinnon
        (1996)</cite>. Altrimenti, si usa <cite
        key="cottrell15">Cottrell (2015)</cite> o, quando si testa
        all'indietro, <cite key="sephton21">Sephton (2021)</cite>.  I
        <emphasis>P</emphasis>-value sono specifici per ampiezza
        campionaria, a meno che non vengano dichiarati come asintotici
        nell'output.
      </para>

      <subhead context="cli">Dati panel</subhead>

      <para context="cli">
	Quando il comando <lit>adf</lit> è usato con dati panel per
	calcolare un test panel di radici unitarie le opzioni
	applicabili sono piuttosto diverse.
      </para>
      <para context="cli">
	In primo luogo, mentre nel caso di serie storiche pure è
	possibile indicare un elenco di variabili da testare, con dati
	panel ciascun comando può esaminare una sola variabile alla
	volta.  In secondo luogo, le opzioni che governano
	l'inclusione di trend deterministici diventano mutualmente
	esclusive: è necessario scegliere fra il caso senza costante,
	quello con solo la costante, e quello che la costante e il
	trend; il default è il secondo.  L'opzione
	<opt>seasonals</opt>, inoltre, non è disponibile.  Infine,
	l'opzione <opt>verbose</opt> ha un significato diverso:
	produce un breve resoconto del test per ciascuna singola serie
	storica (il default prevede di mostrare solo il risultato
	complessivo).
      </para>
      <para context="cli">
	Il test complessivo (ipotesi nulla: la variabile in questione
	ha una radice unitaria per tutte le unità panel) viene
	calcolata in uno o in entrambi i modi disponibili: usando il
	metodo di <cite key="IPS03">Im, Pesaran e Shin (Journal of
	Econometrics, 2003)</cite> oppure quello di <cite
	key="choi01">Choi (Journal of International Money and Finance,
	2001)</cite>. Il test di Choi richiede che siano disponibili i
	<emphasis>P</emphasis>-value dei test singoli; se così non
	fosse, per via delle opzioni selezionate, esso viene
	omesso. La statistica riportata per il test di Im, Pesaran e
	Shin varia come segue: se l'ordine di ritardi per il test è
	positivo, viene riportata la statistica <math>W</math>;
	altrimenti, viene riportata o la statistica <math>Z</math> se la
	lunghezza delle serie è diversa fra individui o la statistica
	<math>t</math> barrato se è uguale per tutte le unità. Vedi
	anche il comando <cmdref targ="levinlin"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Test di radice unitaria/Test Dickey-Fuller aumentato</menu-path>
    </gui-access>

  </command>

  <command name="anova" label="ANOVA" section="Statistics">
    <usage>
      <arguments>
        <argument>response</argument>
        <argument>treatment</argument>
        <argument optional="true">block</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa i risultati</effect>
	</option>
      </options>
    </usage>
    <description>
      <para>
	Analisi della varianza: <repl>response</repl> è una serie che
	misura un effetto di interesse e <repl>treatment</repl> deve
	essere una variabile discreta che identifica due o più tipi di
	trattamento (o non trattamento).  Nel caso dell'ANOVA a due
	vie, la variabile <repl>block</repl> (anch'essa discreta)
	identifica i valori di qualche variabile di controllo.
      </para>
      <para context="cli">
	Se non è stata selezionata l'opzione <opt>quiet</opt>,
	questo comando stampa una tabella che mostra le somme e le
	medie dei quadrati, nonché un test <math>F</math>.  Il test
	<math>F</math> e il suo <emphasis>p-</emphasis>value possono
	essere recuperati rispettivamente con gli accessori
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>.
      </para>
      <para>
	L'ipotesi nulla del test <math>F</math> è che la risposta
	media sia invariante rispetto al tipo di trattamento; in altre
	parole, che il trattamento non abbia alcun
	effetto. Formalmente, la validità del test richiede che la
	varianza della risposta sia la stessa per tutti i tipi di
	trattamento.
      </para>
      <para>
	Si noti che i risultati prodotti da questo comando
	costituiscono in realtà un sottoinsieme dell'informazione
	fornita dalla procedura seguente, facilmente implementabile in
	gretl. Create un insieme di variabili dummy associate a tutti
	i tipi di trattamento, tranne uno. Nel caso dell'ANOVA a due
	vie, create anche un insieme di variabili dummy associate a
	tutti i <quote>blocchi</quote>, tranne uno. Una volta fatto
	questo, regredite <repl>response</repl> su una costante e le
	dummy usando <cmdref targ="ols"/>.  Per un'analisi a una via
	la tabella ANOVA può essere creata ricorrendo all'opzione
	<opt>anova</opt> del comando <lit>ols</lit>.  Nel caso di
	un'analisi a due vie il test <math>F</math> può essere
	calcolato usando il comando <cmdref targ="omit"/>. Per
	esempio, se assumiamo che <lit>y</lit> sia la risposta,
	<lit>xt</lit> identifichi il trattamento e <lit>xb</lit>
	identifichi i blocchi:
      </para>
      <code>
	# analisi a una via
	list dxt = dummify(xt)
	ols y 0 dxt --anova
	# analisi a due vie
	list dxb = dummify(xb)
	ols y 0 dxt dxb
	# test di significatività congiunta di dxt
	omit dxt --quiet
      </code>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/ANOVA</menu-path>
    </gui-access>

  </command>

  <command name="append" section="Dataset" label="Aggiunge dati" context="cli">

    <usage>
      <arguments>
        <argument>file-dati</argument>
      </arguments>
      <options>
	<option>
	  <flag>--time-series</flag>
	  <effect>si veda oltre</effect>
	</option>
	<option>
	  <flag>--fixed-sample</flag>
	  <effect>si veda oltre</effect>
	</option>
	<option>
	  <flag>--update-overlap</flag>
	  <effect>si veda oltre</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
	</option>
	<optnote>Si veda oltre per opzioni speciali addizionali</optnote>
      </options>
    </usage>

    <description>
      <para>
        Apre un file di dati e aggiunge il suo contenuto al dataset
        attuale, se i nuovi dati sono compatibili. Il programma cerca
        di riconoscere il formato del file di dati (interno, testo
        semplice, CSV, Gnumeric, Excel, ecc.). Si noti che il comando
        <cmdref targ="join"/> fornisce un controllo molto più puntuale
        sul modo in cui i nuovi dati vengono gestiti. Inoltre,
        l'aggiunta di dati ad un dataset con struttura panel può
	essere una faccenda piuttosto intricata. Si veda la sezione
	<quote>Dati panel</quote> più avanti.
      </para>
      <para>
	I dati aggiunti possono avere la forma di osservazioni
	aggiuntive su variabili già presenti nel dataset, o di nuove
	variabili. In quest'ultimo caso occorre che il numero delle
	nuove osservazioni sia pari a quello delle osservazioni
	presenti nel dataset, oppure che i nuovi dati includano
	informazioni precise sulle osservazioni in modo che gretl
	possa capire come aggiungere i valori. Si noti che se c'è una
	<quote>corrispondenza perfetta</quote> delle informazioni
	sulle osservazioni (ovvero, se le condizioni (a) e (b) sono
	entrambe soddisfatte), si presume che le serie, piuttosto che
	le osservazioni, debbano essere aggiunte. E se capita che non
	ci siano nomi di serie nel file i cui dati devono essere
	aggiunti che non siano già presenti nel dataset corrente,
	allora l'intera operazione è annullata viene visualizzato un
	avviso.
      </para>
      <para>
	Attenzione: non è supportato il caso i nuovo dati inizino
	prima e finiscano dopo quelli originali. Per aggiungere nuove
	serie in tal caso bisogna usare l'opzione
	<opt>fixed-sample</opt>; ciò ha l'effetto di di sopprimere
	l'aggiunta di osservazioni, e quindi restringere l'operazione
	all'aggiunta di nuove serie.
      </para>
      <para>
	Quando viene scelto per l'aggiunta un file di dati, potrebbe
	esserci una parziale sovrapposizione con il dataset esistente;
	in altre parole, una o più serie potrebbero avere
	osservazioni in comune dalle due fonti. Se viene passata l'opzione
	<opt>update-overlap</opt>, il comando <lit>append</lit>
	sostituirà le osservazioni in comune con quelle provenienti
	dal file dei dati; se no, i valori presenti nel dataset in
	quel momento saranno lasciati inalterati.
      </para>
      <para>
	Le opzioni specializzate aggiuntive <opt>sheet</opt>,
	<opt>coloffset</opt>, <opt>rowoffset</opt> e
	<opt>fixed-cols</opt> funzionano come quelle corrispondenti per
	il comando <cmdref targ="open"/>.
      </para>
      <para>
	Vedi anche <cmdref targ="join"/> per una gestione più
	sofisticata di più di un file di dati esterno.
      </para>
      <subhead>Dati panel</subhead>
      <para>
	Quando il comando è usato su un dataset di tipo panel, i
	risultati saranno corretti solo se le informazioni sulle
	<quote>unità</quote> e sul tempo sono ben allineate.
      </para>
      <para>
	Il comando dovrebbe gestire con facilità due casi
	semplici. Siano <math>n</math> il numero di unità
	cross-sezionali e <math>T</math> il numero di periodi nel
	panel attualmente aperto, e <math>m</math> il numero di
	osservazioni dei dati da aggiungere.  Se <math>m = n</math> i
	nuovi dati sono considerati invarianti nel tempo, e inseriti
	come tali. Se, per converso, <math>m = T</math> i dati sono
	trattati come invarianti fra le unità, e ripetuti per ognuna
	di esse. Nel caso ambiguo <math>T = n</math>, per default i
	dati sono trattati come invarianti nel tempo, a meno che non
	venga usata l'opzione <opt>time-series</opt>, che forza gretl
	a considerarli una serie storica.
      </para>
      <para>
	Se il dataset corrente e i dati in ingresso sono entrambi
	riconosciuti come dei panel, vanno considerati due casi. (1)
	La lunghezza temporale <math>T</math> e diversa fra i due
	dataset. Quaesta situazione provoca un errore. (2) Se invece
	<math>T</math> è uguale, si dà per scontato che le unità
	combacino, a <emphasis>partire dalla prima unità</emphasis>
	doi ognuno dei due dataset. Per situazioni più sofisticate o
	complesse, consigliamo di usare <cmdref targ="join"/> anziché
	<lit>append</lit>.
      </para>

    </description>

    <gui-access>
      <menu-path>/File/Aggiungi dati</menu-path>
    </gui-access>

  </command>

  <command name="ar" section="Estimation" label="Stima autoregressiva">

    <usage>
      <arguments>
        <argument>ritardi</argument>
	<argument separated="true">variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non riporta i parametri stimati</effect>
	</option>
      </options>
      <examples>
        <example>ar 1 3 4 ; y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Calcola le stime parametriche usando la procedura iterativa
	generalizzata di Cochrane&ndash;Orcutt (si veda il Capitolo
	9.5 di <cite key="ramanathan02">Ramanathan (2002)</cite>. La
	procedura termina quando le somme dei quadrati degli errori
	consecutivi non differiscono per più dello 0.005 per cento,
      oppure dopo 20 iterazioni.</para>

      <para context="gui">
	La <quote>lista dei ritardi AR</quote> specifica la struttura
	del processo dell'errore.  Ad esempio, l'indicazione <quote>1
	3 4</quote> corrisponde al processo:
	<equation status="display"
		  tex="\[u_t = \rho_1u_{t-1} + \rho_3 u_{t-3} +
		       \rho_4 u_{t-4} + e_t\]"
		  ascii="u(t) = rho1*u(t-1) + rho3*u(t-3) + rho4*u(t-4)"
		  graphic="arlags"/>
      </para>

      <para context="cli">
	<repl quote="true">ritardi</repl> è una lista di ritardi nei
	residui, conclusa da un punto e virgola. Nell'esempio
	precedente, il termine di errore è specificato come
	<equation status="display"
		  tex="\[u_t = \rho_1u_{t-1} + \rho_3 u_{t-3} +
		       \rho_4 u_{t-4} + e_t\]"
		  ascii="u(t) = rho(1)*u(t-1) + rho(3)*u(t-3) + rho(4)*u(t-4)"
		  graphic="arlags"/>
      </para>

    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/AR - Stima autoregressiva</menu-path>
    </gui-access>

  </command>

  <command name="ar1" section="Estimation" label="Stima AR(1)">

    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
      </arguments>
      <options>
	<option>
	  <flag>--hilu</flag>
	  <effect>usa la procedura di Hildreth&ndash;Lu</effect>
	</option>
	<option>
	  <flag>--pwe</flag>
	  <effect>usa lo stimatore di Prais&ndash;Winsten</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--no-corc</flag>
	  <effect>non affinare i risultati con Cochrane-Orcutt</effect>
	</option>
	<option>
	  <flag>--loose</flag>
	  <effect>usa un criterio di convergenza più blando</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
	</option>
      </options>
      <examples>
        <example>ar1 1 0 2 4 6 7</example>
	<example>ar1 y 0 xlist --hilu --no-corc</example>
	<example>ar1 y 0 xlist --pwe</example>
      </examples>
    </usage>

    <description>
      <para>
        Calcola stime feasible GLS per un modello in cui il termine di errore
        segue un processo autoregressivo del prim'ordine.
      </para>
      <para>
	Il metodo predefinito è la procedura iterativa di
	Cochrane&ndash;Orcutt (si veda ad esempio il capitolo 9.4 di
	<cite key="ramanathan02">Ramanathan, 2002</cite>). La
	procedura termina quando le stime successive del coefficiente
	di autocorrelazione non differiscono per più di 0.001, oppure
	dopo 20 iterazioni. Sarà segnalato un errore se la convergenza
	non è avvenuta dopo 100 iterazioni. Se ciò non si verifica entro la
	100esima iterata verrà stampato un messaggio di errore.
      </para>
      <para>
        Se si usa l'opzione <opt>pwe</opt>, viene usato lo stimatore di
        Prais&ndash;Winsten, che prevede una procedura simile a quella di
        Cochrane&ndash;Orcutt; la differenza è che mentre Cochrane&ndash;Orcutt
        tralascia la prima osservazione, Prais&ndash;Winsten ne fa uso.  Per i
        dettagli, si veda per esempio il capitolo 13 di <book>Econometric
        Analysis</book> di <cite key="greene00">Greene (2000)</cite>.
      </para>
      <para>
	Se si usa l'opzione <opt>hilu</opt>, verrà usata la
	procedura di ricerca di Hildreth&ndash;Lu.  I risultati sono
	quindi ottimizzati con la procedura iterativa di
	Cochrane&ndash;Orcutt, a meno che non si usi l'opzione
	<opt>no-corc</opt> (che viene ignorata se non viene
	specificata <opt>hilu</opt>).
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/Cochrane-Orcutt</menu-path>
      <menu-path>/Modello/Serie storiche/Hildreth-Lu</menu-path>
      <menu-path>/Modello/Serie storiche/Prais-Winsten</menu-path>
    </gui-access>

  </command>

  <command name="arch" section="Estimation" label="Modello ARCH">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
        </option>
      </options>
      <examples>
        <example>arch 4 y 0 x1 x2 x3</example>
      </examples>
    </usage>

    <description>
      <para>
	Questo comando è attualmente mantenuto per ragioni di
	compatibilità con le versioni precedenti, ma è preferibile
	usare lo stimatore di massima verosimiglianza disponibile
	mediante il comando <cmdref targ="garch"/>; per un modello
	ARCH puro, fissate a 0 il primo parametro GARCH.
      </para>
      <para>
	Stima il modello specificato tenendo conto della possibile
        eteroschedasticità condizionale autoregressiva (ARCH,
	Autoregressive Conditional Heteroskedasticity). Per prima cosa il
        modello viene stimato con OLS, quindi viene eseguita una regressione
        ausiliaria, in cui i quadrati dei residui della prima regressione
        vengono regrediti sui loro valori ritardati. Il passo finale è una stima
        con minimi quadrati ponderati, in cui i pesi sono i reciproci delle
        varianze dell'errore della regressione ausiliaria (se la varianza
        prevista di qualche osservazione nella regressione ausiliaria non
        risulta positiva, viene usato il corrispondente residuo al quadrato).
      </para>
      <para>
	I valori <lit>alpha</lit> mostrati sotto i coefficienti sono i parametri
        del processo ARCH stimati nella regressione ausiliaria.
      </para>
      <para>
	Si veda anche <cmdref targ="garch"/> e <cmdref targ="modtest"/>
        (l'opzione <opt>arch</opt>).
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/ARCH</menu-path>
    </gui-access>
  </command>

  <command name="arima" section="Estimation" label="Modello ARIMA">

    <usage>
      <arguments>
        <argblock>
          <argument>p</argument>
          <argument>d</argument>
          <argument>q</argument>
        </argblock>
 	<argblock separated="true" optional="true">
 	  <argument>P</argument>
	  <argument>D</argument>
 	  <argument>Q</argument>
 	</argblock>
	<argument separated="true">variabile-dipendente</argument>
	<argument optional="true">variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
        <option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
	  <flag>--hessian</flag>
	  <effect>si veda sotto</effect>
        </option>
        <option>
          <flag>--opg</flag>
	  <effect>si veda sotto</effect>
        </option>
        <option>
          <flag>--nc</flag>
          <effect>non include l'intercetta</effect>
        </option>
        <option>
	  <flag>--conditional</flag>
	  <effect>usa la massima verosimiglianza condizionale</effect>
        </option>
        <option>
	  <flag>--x-12-arima</flag>
	  <effect>usa X-12-ARIMA, o X13, per la stima</effect>
        </option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa il massimizzatore L-BFGS-B</effect>
	</option>
	<option>
	  <flag>--y-diff-only</flag>
	  <effect>speciale per ARIMAX, si veda sotto</effect>
	</option>
	<option>
          <flag>--lagselect</flag>
          <effect>vedi sotto</effect>
	</option>
      </options>
      <examples>
        <example>arima 1 0 2 ; y</example>
	<example>arima 2 0 2 ; y 0 x1 x2 --verbose</example>
	<example>arima 0 1 1 ; 0 1 1 ; y --nc</example>
	<demos>
	<demo>armaloop.inp</demo>
	<demo>auto_arima.inp</demo>
	<demo>bjg.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>

      <para>
	Nota: <lit>arma</lit> è un sinomimo di questo comando.
      </para>
      <para context="cli">
	Se non viene fornita una lista di
	<repl>variabili-indipendenti</repl>, stima un modello
	autoregressivo integrato a media mobile (ARIMA:
	Autoregressive, Integrated, Moving Average) univariato.  I
	valori <repl>p</repl>, <repl>d</repl> e <repl>q</repl>
	rappresentano rispettivamente gli ordini dei termini
	autoregressivi (AR), l'ordine di differenziazione, e quello
	dei termini a media mobile (MA).  Questi valori possono essere
	indicati in forma numerica o con i nomi di variabili scalari
	preesistenti. Ad esempio, un valore <repl>d</repl> pari a 1
	significa che prima di stimare i parametri ARMA occorre
	prendere la differenza della variabile dipendente.
      </para>
      <para context="cli">
        Se si vuole includere solo alcuni specifici ritardi AR o MA
        (invece che tutti i ritardi fino all'ordine specificato) è
        possibile sostituire <repl>p</repl> e/o <repl>q</repl> in due
        modi: col nome di una matrice predefinita che contiene un
        insieme di valori interi, oppure con un'espressione come
        <lit>{1 4}</lit>, ossia un insieme di ritardi separati da
        spazi e racchiusi tra parentesi graffe.
      </para>
      <para context="cli">
        I valori interi opzionali <repl>P</repl>, <repl>D</repl> e
        <repl>Q</repl> rappresentano rispettivamente, l'ordine dei
        termini AR stagionali, l'ordine di differenziazione stagionale
        e l'ordine dei termini MA stagionali. Essi sono rilevanti solo
        la frequenza dei dati è superiore a 1 (ad esempio, dati
        trimestrali o mensili). Questi valori devono essere indicati
        in forma numerica o come variabili scalari.
      </para>
      <para context="cli">
        Nel caso univariato la scelta predefinita include
        un'intercetta nel modello, ma questa può essere soppressa con
        l'opzione <opt>nc</opt>.  Se vengono aggiunte delle
        <repl>variabili-indipendenti</repl>, il modello diventa un
        ARMAX: in questo caso occorre indicare esplicitamente la
        costante se si desidera un'intercetta (come nel secondo degli
        esempi proposti).
      </para>
      <para context="cli">
        È disponibile una sintassi alternativa per questo comando: se
        non si intende applicare alcuna operazione di differenziazione
        (stagionale o non stagionale), è possibile omettere totalmente
        i termini <repl>d</repl> e <repl>D</repl>, invece che
        impostarli esplicitamente pari a 0. Inoltre, <lit>arma</lit> è
        un sinonimo di <lit>arima</lit>, quindi ad esempio il comando
        seguente è un modo valido per specificare un modello
        ARMA(2,1):
      </para>
      <code context="cli">
	arma 2 1 ; y
      </code>
      <para context="gui">
	Stima un modello ARMA, con o senza regressori esogeni. Se
	l'ordine di differenziazione è maggiore di zero, il modello
	diventa un ARIMA. Se i dati hanno una frequenza superiore a 1,
	viene offerta la possibilità di includere termini stagionali.
      </para>
      <para context="gui">
        Se si vuole includere solo alcuni specifici ritardi AR o MA (invece che
        tutti i ritardi fino all'ordine specificato) è possibile marcare la
        casella a destra del selettore e scrivere nel campo disponibile
        un elenco di ritardi, separati da spazi. In alternativa, se è stata
        definita una matrice che contiene l'insieme dei ritardi desiderati, è
        possibile scrivere il suo nome nel campo.
      </para>
      <para>
        Il funzionamento predefinito utilizza la funzionalità ARMA
        <quote>interna</quote> di gretl, che usa la stima di massima
        verosimiglianza esatta usando il filtro di Kalman; come
        opzione è possibile usare la stima di massima verosimiglianza
        condizionale.  Se è stato installato il programma
        <program>X-12-ARIMA</program> è possibile usare questo al
        posto del codice interno di gretl.  Per i dettagli su queste
        opzioni si veda <guideref targ="chap:timeseries"/>.
      </para>
      <para context="cli">
        Quando si usa il codice ARMA interno, le deviazioni standard
        sono stimate basandosi su un'approssimazione numerica
        all'inversa negativa dell'Hessiana, passando automaticamente
        al prodotto esterno del gradiente (OPG) in caso di problemi
        numerici. Se si usa l'opzione <opt>opg</opt> il prodotto
        esterno del gradiente viene usato in ogni caso. L'opzione
        <opt>hessian</opt>, invece, disabilita il passaggio
        automatico all'OPG in caso di problemi. Si noti, peraltro, che
        l'impossibilità di calcolare numericamente l'hessiana è per
        solito indice di un modello mal specificato.
      </para>
      <para context="cli">
	L'opzione <opt>lbfgs</opt> è riservata alla stima basata su codice
	ARMA nativo e MV esatta; quando viene indicata, la stima usa l'algoritmo
	L-BFGS a <quote>memoria limitata</quote> anziché l'ottimizzatore BFGS
	consueto. Questa variante può essere utile in alcune situazioni nelle quali
	la convergenza all'ottimo è problematica.
      </para>
      <para context="cli">
	L'opzione <opt>y-diff-only</opt> è riservata alla stima di modelli
	ARIMAX (modelli con ordine di integrazione non nullo e che includono
	regressori esogeni), e si applica solo con la stima di MV esatta nativa
	di gretl. Per questi modelli il comportamento di default consiste nel
	differenziare sia la variabile dipendente che i regressori, ma quando
	viene indicata questa opzione viene differenziata solo la variabile
	dipendente, mentre i regressori restano nei livelli.
      </para>
      <para>
        Il valore AIC mostrato nei modelli ARIMA è calcolato secondo la
	definizione usata in <program>X-12-ARIMA</program>, ossia
	<equation status="display"
		  tex="\[\mbox{AIC}=-2\ell+2k\]"
		  ascii="AIC = -2L + 2k"
		  graphic="aic"/> dove
	<equation status="inline"
		  tex="$\ell$" ascii="L"
		  graphic="ell"/>
        è la log-verosimiglianza e <math>k</math> è il numero totale di
        parametri stimati. Si noti che <program>X-12-ARIMA</program> non produce
        criteri di informazione come l'AIC quando la stima è effettuata col
        metodo della massima verosimiglianza condizionale.
      </para>
      <para context="tex">
	Le radici AR e MA mostrate in occasione della stima ARMA sono
	basate sulla seguente rappresentazione di un processo ARMA($p,q$):
	\[
	(1-\phi_1 L - \phi_2 L^2 - \cdots - \phi_p L^p)Y =
        c + (1 + \theta_1 L + \theta_2 L^2 + \cdots +
        \theta_q L^q)\varepsilon_t
        \]
	Di conseguenza, le radici AR sono le soluzioni di
        \[
        1 - \phi_1 z - \phi_2 z^2 - \cdots - \phi_p L^p = 0
        \]
	e la stazionarietà del processo richiede che queste radici si
	trovino al di fuori del cerchio di raggio unitario.
      </para>
      <para context="tex">
	Il valore di <quote>frequency</quote> mostrato assieme alle radici
	AR e MA è il valore di $\lambda$ che risolve
	$z=re^{i2\pi\lambda}$, dove $z$ è la radice in questione e $r$ è
	il suo modulo.
      </para>
      <para context="notex">
	Le radici AR e MA mostrate in occasione della stima ARMA sono
	basate sulla seguente rappresentazione	di un processo ARMA(p,q):
      </para>
      <mono context="notex">
	(1 - a_1*L - a_2*L^2 - ... - a_p*L^p)Y =
        c + (1 + b_1*L + b_2*L^2 + ... + b_q*L^q) e_t
      </mono>
      <para context="notex">
	Di conseguenza le radici AR sono la soluzione di
      </para>
      <mono context="notex">
        1 - a_1*z - a_2*z^2 - ... - a_p*L^p = 0
      </mono>
      <para context="notex">
	e la stazionarietà del processo richiede che queste radici si
	trovino al di fuori del cerchio di raggio unitario.
      </para>
      <para context="notex">
	Il valore di <quote>frequenza</quote> mostrato insieme alle
	radici AR e MA è il valore di &lgr; che risolve <math>z</math>
	= <math>r</math> * exp(i*2*&pi;*&lgr;)dove <math>z</math> è la
	radice in questione e <math>r</math> è il suo modulo.
      </para>
      <subhead context="cli">Selezione dei ritardi</subhead>
      <para context="cli">
	Con l'opzione <opt>lagselect</opt>, il comando non fornisce
	stime specifiche, bensì una tavola coi criteri di informazione
	e la log-verosimiglianza per svariate specificazioni ARMA o
	ARIMA. I parametri <math>p</math> e <math>q</math> sono
	interpretati come ordini massimi, così come <math>P</math> e
	<math>Q</math> se c'è una componente stagionale. In ogni caso,
	il minimo è 0, e i risultati sono mostrati per tutte le
	combinazioni dal minimo al massimo. Gli ordini di
	differenziazione <math>d</math> e/o <math>D</math> sono
	utilizzati ma non sono soggetti a ricerca. Per recuperare la
	matrice dei risultati si usi l'accessore <fncref
	targ="$test"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie Storiche/ARIMA</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
    </gui-access>

  </command>

  <command name="arma" section="Estimation" label="ARMA model">
    <description>
      <para>
	Vedi <cmdref targ="arima"/>; <lit>arma</lit> è un alias.
      </para>
    </description>
  </command>

  <command name="ARMA-lagselect" section="Tests" context="gui"
    label="AR(I)MA lag-length selection">

    <description>
      <para>
	In questa finestra di dialogo è possibile specificare un
	modello ARMA o ARIMA come di consueto, ma gli ordini di
	ritardo specificati sono intesi come massimi.
      </para>
      <para>
	L'output è una tabella che mostra i valori dei criteri di
	informazione di Akaike (AIC), Schwarz (BIC) e
	Hannan&ndash;Quinn (HQC), e anche la log-verosimiglianza,
	calcolata per specifiche che vanno dal minimo al massimo
	scelto. Questo ha lo scopo dare indicazioni per la selezione
	degli ordini ottimali dei ritardi.
      </para>
    </description>
  </command>

  <command name="bds" section="Tests" label="BDS nonlinearity test">
    <usage>
      <arguments>
        <argument>ordine</argument>
	<argument>x</argument>
      </arguments>
      <options>
        <option>
	  <flag>--corr1</flag>
	  <optparm>rho</optparm>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--sdcrit</flag>
	  <optparm>multiple</optparm>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--boot</flag>
	  <optparm>N</optparm>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--matrix</flag>
	  <optparm>m</optparm>
	  <effect>usa una matrice come input</effect>
        </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
        </option>
      </options>
      <examples>
        <example>bds 5 x</example>
	<example>bds 3 --matrix=m</example>
	<example>bds 4 --sdcrit=2.0</example>
      </examples>
    </usage>
    <description>
      <para context="cli">
	Esegue il test BDS (<cite key="brock-etal96">Brock, Dechert,
	Scheinkman and LeBaron, 1996</cite>) per la nonlinearità
	della serie <argname>x</argname>. In un contesto
	econometrico il suo uso è tipicamente associato all'analisi
	dei residui per la violazione della condizione IID. Il test
	si basa su un insieme di integrali di correlazione, pensati
	per rintracciare la nonlinearità in dimensioni via via più
	ampie, e l'argomento <argname>ordine</argname> indica il
	numero di tali integrali. Esso deve essere almeno 2; il
	primo integrale stabilisce una base ma non può essere usato
	per calcolare il test. Il test è di tipo generico: rintraccia ogni
	tipo di deviazione dalla linearità ma non è informativo sul
	perché questa condizione venisse eventualmente violata.
      </para>
      <para context="gui">
	Il test BDS (<cite key="brock-etal96">Brock, Dechert,
	Scheinkman and LeBaron, 1996</cite>) è usato per rintracciare
	la nonlinearità di una serie storica. In un contesto
	econometrico il suo uso è tipicamente associato all'analisi
	dei residui per la violazione della condizione IID. Il test si
	basa su un insieme di integrali di correlazione, pensati per
	rintracciare la nonlinearità in dimensioni via via più ampie;
	il numero di questi integrali può essere scelto usando
	l'elemento <quote>Dimensione massima</quote> e deve essere
	almeno 2; il primo integrale stabilisce una base ma non può
	essere usato per calcolare il test. Il test è di tipo
	generico: rintraccia ogni tipo di deviazione dalla linearità
	ma non è informativo sul perché questa condizione venisse
	eventualmente violata.
      </para>
      <para context="cli">
	Il test può essere calcolato su un vettore (riga o colonna)
	anziché su una serie usando l'opzione <opt>matrix</opt>.
      </para>
      <subhead>Criterio di contiguità</subhead>
      <para context="cli">
	Gli integrali di correlazione sono, in sostanza, misure di
	<quote>contiguità</quote>, ove due punti sono considerati
	vicini se la differenza fra loro non eccede &egr;.  Per
	specificare &egr;, di default gretl segue la raccomandazione
	di <cite key="kanzler99">Kanzler (1999)</cite>: &egr; è scelto
	in modo tale che l'integrale di correlazione del primo ordine
	sia intorno a 0.7. Una possibile alternativa (meno intensiva
	computazionalmente) è quella di specificare &egr; come
	multiplo delle scarto quadratico medio della serie in
	esame. L'opzione <opt>sdcrit</opt> è usata per quest'ultimo
	metodo; nel terzo esempio fornito sopra &egr; è posto al
	doppio dello sqm di <repl>x</repl>. L'opzione <opt>corr1</opt>
	implica invece l'uso del metodo di Kanzler's ma consente di
	specificare un valore di scala diverso da 0.7. Ovviamente,
	queste due opzioni non possono essere usate insieme.
      </para>
      <para context="gui">
	Gli integrali di correlazione sono, in sostanza, misure di
	<quote>contiguità</quote>, ove due punti sono considerati
	vicini se la differenza fra loro non eccede &egr;.  Per
	specificare &egr;, di default gretl segue la raccomandazione
	di <cite key="kanzler99">Kanzler (1999)</cite>: &egr; è scelto
	in modo tale che l'integrale di correlazione del primo ordine
	sia intorno a 0.7. Una possibile alternativa (meno intensiva
	computazionalmente) è quella di specificare &egr; come
	multiplo delle scarto quadratico medio della serie in
	esame.
      </para>
      <subhead context="cli">Bootstrap</subhead>
      <para context="cli">
	Le statistiche test sono asintoticamente distribuite come
	<math>N</math>(0,1) ma il test tende a sovra-rigettare la
	nulla in piccoli campioni. Per questa ragione, i
	<math>P</math>-values sono ottenuti con una procedura di
	bootstrap se la lunghezza di <argname>x</argname> fosse
	minore di 600 (in caso contrario, si fa riferimento alla
	normale standard). Per usare il bootstrap in campioni più
	grandi basta dare un valore non zero all'opzione
	<opt>boot</opt>. Al contrario, per evitare il bootstrap in
	piccoli campioni, basta settarla a 0.
      </para>
      <subhead context="gui">P-values</subhead>
      <para context="gui">
	Le statistiche test sono asintoticamente distribuite come
	<math>N</math>(0,1) ma il test tende a sovra-rigettare in
	piccoli campioni. Per questa ragione, i
	<math>P</math>-values sono ottenuti con una procedura di
	bootstrap se la lunghezza di <argname>x</argname> fosse
	minore di 600 (in caso contrario, si fa riferimento alla
	normale standard).
      </para>
      <para context="cli">
	Il default per il numero di iterazioni bootstrap è di 1999, ma
	questo settaggio può essere modificato dandolo come argomento
	all'opzione <opt>boot</opt>.
      </para>
      <subhead context="cli">Matrice accessore</subhead>
      <para context="cli">
	Se il comando va a buon fine, <fncref targ="$result"/>
	conterrà i risultati sotto forma di una matrice con due righe e
	  <argname>maxdim</argname> &minus; 1 colonne. La prima riga
	  contiene le statistiche test, mentre la seconda contiene i
	  <math>P</math>-values per ognuna delle dimensioni, sotto
	  l'ipotesi nulla per cui <argname>x</argname> sia
	  lineare/IID.
      </para>
    </description>
  </command>

  <command name="bfgs-config" section="Estimation" label="BFGS options"
	   context="gui">
    <description>
      <para>
	Questa finestra di dialogo consente di controllare alcuni
	dettagli dell'algoritmo BFGS. Nel caso di mancata convergenza
	può essere utile, in certi casi, aumentare il numero massimo
	di iterazioni e/o il parametro di tolleranza. Tuttavia,
	risultati ottenuti con tolleranze molto alte dovrebbero
	essere considerati un po' sospetti, e va considerata la
	possibilità che il modello sia mal specificato.
      </para>
      <para>
	Nella maggioranza dei casi, consigliamo l'uso dell'algoritmo
	BFGS standard, ma per alcuni problemi, la sua variante
	<quote>a memoria limitata</quote>, L-BFGS-B, può essere più
	efficace. Con questo algoritmo, è possibile fissare il numero
	di correzioni nella matrice di memoria limitata (tra 3 e 20,
	default 8).
      </para>
    </description>
  </command>

  <command name="biprobit" section="Estimation" label="Bivariate probit"
	   context="cli">
    <usage>
      <arguments>
        <argument>depvar1</argument>
	<argument>depvar2</argument>
        <argument>indepvars1</argument>
	<argument separated="true" optional="true">indepvars2</argument>
      </arguments>
      <options>
        <option>
	  <flag>--vcv</flag>
	  <effect>stampa la matrice di covarianze</effect>
        </option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
        </option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
        </option>
	<option>
	  <flag>--opg</flag>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--save-xbeta</flag>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>stampa informazione extra</effect>
        </option>
      </options>
      <examples>
        <example>biprobit y1 y2 0 x1 x2</example>
	<example>biprobit y1 y2 0 x11 x12 ; 0 x21 x22</example>
	<demos>
	  <demo>biprobit.inp</demo>
	</demos>
      </examples>
    </usage>
    <description>
      <para>
	Stima un modello probit bivariato massimizzando la verosimiglianza
	con il metodo di Newton&ndash;Raphson.
      </para>
      <para>
	L'elenco degli argomenti inizia con due variabili dipendenti (binarie),
	seguite da una lista di regressori. Un'eventuale seconda lista,
	separata dalla precedente da un punto e virgola, viene interpretata come
	contenente l'insieme dei regressori specifici alla seconda equazione,
	mentre <repl>indepvars1</repl> è specifica alla prima equazione;
	in caso contrario il comando assume che <repl>indepvars1</repl>
	rappresenti un insieme di regressori comuni alle due equazioni.
      </para>
      <para>
	Per default, gli errori standard sono calcolati usando
	l'Hessiana analitica calcolata in corrispondenza delle stime
	dei parametri. L'opzione <opt>opg</opt> permette di stimare la
	matrice di covarianza usando il prodotto esterno del gradiente
	(Outer Product of the Gradient, OPG); l'opzione
	<opt>robust</opt> permette di calcolare gli standard error QML
	a partire dalla matrice di covarianza <quote>sandwich</quote>
	che usa sia l'inversa dell'Hessiana che la matrice OPG.
      </para>
      <para>
	Si noti che la stima di rho, il coefficiente di correlazione
	fra i due termini di disturbo, è incluso nel vettore dei
	coefficienti, all'ultimo posto, con le ovvie conseguenze sugli
	accessori <lit>coeff</lit>, <lit>stderr</lit> e <lit>vcv</lit>.
      </para>
      <para>
	Una volta completata con successo la stima, l'accessore
	<fncref targ="$uhat"/> consente di recuperare una matrice di due
	colonne contenente i residui generalizzati delle due
	equazioni; in altre parole, i valori attesi degli errori
	condizionali ai valori osservati delle variabili dipendenti e
	delle covariate. Di default <fncref targ="$yhat"/> restituisce una
	matrice di quattro colonne contenente le stime delle
	probabilità dei quattro possibili esiti congiunti per
	(<math>y</math><sub>1</sub>, <math>y</math><sub>2</sub>),
	nell'ordine (1,1), (1,0), (0,1), (0,0). In alternativa, se il
	comando è seguito dall'opzione <opt>save-xbeta</opt> ,
	<fncref targ="$yhat"/> ha due colonne contenenti i valori delle
	funzioni indice delle rispettive equazioni.
      </para>
      <para>
	L'output comprende un test dell'ipotesi che gli errori delle
	due equazioni siano incorrelati fra loro. Il test è un test di
	tipo LR, a meno che lo stimatore sia inteso come stimatore
	QMLE e quindi venga usata l'opzione <opt>robust</opt>; in
	questo caso, si usa un test di Wald.
      </para>
    </description>
  </command>

  <command name="bkw" section="Tests" context="cli"
	   label="Collinearity Diagnostics">
    <usage>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
        </option>
      </options>
      <examples>
	<demos>
	  <demo>longley.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Deve seguire la stima di un modello che includa almeno due
	variabili indipendenti. Calcola e mostra le informazioni relative
	alla collinearità, ovvero la tabella BKW, basandosi sul lavoro di
	<cite key="belsley-etal80">Belsley, Kuh e Welsch (1980)</cite>.
	Questa tabella riporta una sofisticata analisi del grado di
	collinearità e delle sue fonti, attraverso l'analisi degli
	autovalori ed autovettori dell'inversa della matrice di
	correlazione. Per un resoconto completo circa l'approccio BKW con
	riferimento a gretl, ed a diversi altri esempi, si veda <cite
	key="adkins15">Adkins, Waters e Hill (2015)</cite>.
      </para>
      <para>
	Utilizzando l'accessore <fncref targ="$result"/> è possibile
	recuperare la tabella BKW come matrice. Si veda anche il
	comando <cmdref targ="vif"/> per un approccio semplificato
	alla diagnostica della collinearità.
      </para>
      <para>
	Esiste anche una funzione chiamata <fncref targ="bkw"/> che
	offre maggior flessibilità.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Analisi/Collinearità</menu-path>
    </gui-access>

  </command>

  <command name="bootstrap" section="Tests" label="Opzioni bootstrap"
	   context="gui">

    <description>

      <para>
      In questa finestra di dialogo è possibile scegliere:</para>

      <ilist>
	<li>
	  <para>
	    La variabile o il coefficiente da esaminare (è possibile testare
            solo un coefficiente alla volta usando questo metodo).
	  </para>
	</li>
	<li>
	  <para>
            Il tipo di analisi da eseguire. L'intervallo di confidenza
            predefinito (95 per cento) è basato direttamente sui
            quantili delle stime bootstrap del coefficiente. La
            versione <quote>studentizzata</quote> corrisponde a quella
            presentata nel capitolo 5 di <cite
            key="davidson-mackinnon04">Economic Theory and
            Methods</cite> (ETM) di Davidson e MacKinnon: ad ogni
            replicazione bootstrap, viene calcolato un rapporto
            <math>t</math> come (a) la differenza tra la stima attuale
            del coefficiente e quella di riferimento, divisa per (b)
            l'errore standard di riferimento. Quindi l'intervallo di
            confidenza viene calcolato usando i quantili di questo
            rapporto t, come spiegato in ETM. L'opzione p-value si
            basa sulla distribuzione del rapporto <math>t</math>
            bootstrap: è la proporzione delle replicazioni in cui il
            valore assoluto di questa statistica eccede il valore
            assoluto del rapporto <math>t</math> di riferimento.
	  </para>
	</li>
	<li>
	  <para>
	    Il metodo di bootstrap. Con la prima opzione i residui
	    originali (riscalati, come suggerito in ETM) vengono
	    ricampionati con rimpiazzo. Nel secondo caso, viene
	    effettuato un ricampionamente per <quote>coppie</quote> o
	    <quote>casi</quote>, ossia le righe di dati <math>y</math>,
	    <math>X</math>. Con la terza opzione, i residui originali
	    vengono prima trasformati secondo il metodo di <cite
	    key="davidson-flachaire01">Davidson e Flachaire
	    (2001)</cite>, dopodiché in ogni replicazione bootstrap
	    ognuno di essi viene cambiato di segno con probabilità
	    0.5. Con l'ultima opzione, vengono generati valori normali
	    pseudo-casuali con la varianza dei residui originali.
	  </para>
	</li>
	<li>
	  <para>
	    Il numero di replicazioni da eseguire. Si noti che
	    quando si costruisce un intervallo di confidenza al 95 per
	    cento è opportuno che 0.05(<math>B</math> + 1)/2 sia un
	    intero (dove <math>B</math> è il numero di replicazioni),
	    quindi gretl può aggiustare il numero scelto di replicazioni
	    per assicurare questa condizione.
	  </para>
	</li>
	<li>
	  <para>
	    Se produrre o no un grafico della distribuzione bootstrap.
            Questa opzione usa la procedura di stima kernel di gretl.
	  </para>
	</li>
      </ilist>

    </description>
  </command>


  <command name="boxplot" section="Graphs" label="Grafici boxplot">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--notches</flag>
	  <effect>mostra l'intervallo di confidenza al 90 per cento per la mediana</effect>
	</option>
	<option>
	  <flag>--factorized</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--panel</flag>
	  <effect>vedi sotto</effect>
	</option>
        <option>
	  <flag>--matrix</flag>
	  <optparm>name</optparm>
	  <effect>opera su colonne di una matrice</effect>
        </option>
	<option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>manda l'output a un file specificato</effect>
	</option>
      </options>
    </usage>

    <description>

      <para>
	Questo tipo di grafici (da Tukey e Chambers) mostra la
	distribuzione di una variabile. La <quote>scatola</quote>
	centrale (box) racchiude il 50 per cento centrale dei dati,
	ossia è delimitato dal primo e terzo quartile. I
	<quote>baffi</quote> (whiskers) si estendono fino un valore
	dato da una volta e mezzo il range interquartile a partire dai
	bordi della scatola. Valori esterni a tale intervallo sono
	considerati <quote>outlier</quote> e rappresentati con dei
	punti. Una linea trasversale sulla scatola indica la mediana,
	mentre un segno <quote>+</quote> indica la media. Se viene
	selezionata l'opzione di mostrare un intervallo di confidenza
	per la mediana, questo viene calcolato via bootstrap e
	mostrato sotto forma di lnee tratteggiate orizzontali sopra e
	sotto la mediana.
      </para>

      <para context="gui">
	L'opzione <quote>factorized</quote> permette di esaminare la
	distribuzione di una variabile condizionata ai valori di un
	fattore discreto. Ad esempio, se un dataset contiene salari e
	una variable binaria per il genere, si può scegliere di
	analizzare la distribuzione del salario condizionata al genere
	e visualizzare boxplot dei salari per i maschi e per le femmine
	uno di fianco all'altro.
      </para>

      <para context="cli">
	L'opzione <quote>factorized</quote> permette di esaminare la
	distribuzione di una variabile condizionata ai valori di un
	fattore discreto. Ad esempio, se un dataset contiene salari e
	una variable binaria per il genere, si può scegliere di
	analizzare la distribuzione del salario condizionata al genere
	e visualizzare boxplot dei salari per i maschi e per le femmine
	uno di fianco all'altro, come ad esempio
      </para>
      <code context="cli">
	boxplot wage gender --factorized
      </code>
      <para context="cli">
	Si noti che, in questo caso, bisogna specificare esattamente
	due variabili, col fattore per secondo.
      </para>

      <para context="cli">
	Se il dataset corrente è un panel ed è stata specificata una sola
	variabile, l'opzione <opt>panel</opt> produce una serie di grafici
	boxplot affiancati, uno per ogni <quote>unità</quote> o gruppo panel.
      </para>

      <para context="cli">
	In generale l'argomento <repl>varlist</repl> è necessario e deve
	indicare una o più variabili nel dataset corrente (usando il nome
	o il numero di ID). Se viene fornita una matrice usando l'opzione
	<opt>matrix</opt>, tuttavia, questo argomento diventa opzionale: di
	default viene mostrato un grafico per ciascuna delle colonne della
	matrice specificata.
      </para>

      <para context="cli">
	Il grafici boxplot di gretl sono generati usando <program>gnuplot</program>,
	ed è possibile arricchire il grafico specificando altri comandi
	gnuplot, includendoli fra parentesi graffa. Per maggiori dettagli
	consultate per favore l'help del comando <cmdref targ="gnuplot"/>.
      </para>

      <para context="cli">
	In modalità interattiva il risultato viene mostrato immediatamente.
	In batch il comportamento di default di gretl è di scrivere nella
	directory di lavoro dell'utente un file di comandi gnuplot chiamato
	<filename>gpttmpN.plt</filename>, iniziando da N = <lit>01</lit>.
	I grafici veri e propri possono essere generati in seguito usando
	<program>gnuplot</program> (in MS Windows,
	<program>wgnuplot</program>). Questo comportamento può essere modificato
	usando l'opzione <opt>output=</opt><repl>filename</repl>.
	Per ulteriori dettagli, si veda il comando <cmdref
	targ="gnuplot"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>/Visualizza/Grafico/Boxplot</menu-path>
    </gui-access>

  </command>

  <command name="break" section="Programming"
	   label="Esce da un ciclo" context="cli">
    <description>
      <para>
	Esce da un ciclo. Questo comando può essere usato solo
	all'interno di un ciclo e causa l'immediata interruzione
	dell'esecuzione del ciclo (o di quello più interno, nel caso di
	cicli nidificati). Si veda anche il comando <cmdref
	targ="loop"/>.
      </para>
    </description>
  </command>

  <command name="bwfilter" section="Transformations" context="gui"
	   label="Il filtro di Butterworth">

    <description>
      <para>
	Il filtro di Butterworth è un'approssimazione di un filtro
	ideale a onda quadra che lascia completamente passare tutte le
	frequenze all'interno di un certo intervallo e blocca tutte le
	altre.
      </para>
      <para>
	Valori più elevati del parametro di ordine, <math>n</math>,
	producono una migliore approssimazione del filtro ideale ma al
	costo potenziale di introdurre un certo grado di instabilità
	numerica. Il valore di <quote>cutoff</quote> individua la
	soglia fra intervallo di frequenze lasciate passare e quello
	delle frequenze bloccate. Questo parametro è espresso in gradi
	e deve essere maggiore di 0 e minore di 180&deg; (o &pi;
	radianti, corrispondente alla frequenza massima nei dati).
	Valori inferiori di questa soglia producono un trend più
	regolare.
      </para>
      <para>
	Se si desidera applicare questo filtro è opportuno esaminare
	prima il periodogramma della serie storica considerata. V.
	<guideref targ="chap:genr"/> per maggiori dettagli.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/Filter/Butterworth</menu-path>
    </gui-access>

  </command>

  <command name="catch" section="Programming"
	   label="Catch errors" context="cli">
    <usage>
      <syntax>
        <lit>catch</lit> <repl>command</repl>
      </syntax>
    </usage>
    <description>
      <para>
	Non si tratta di un vero e proprio comando, quanto piuttosto
	di un prefisso applicabile alla maggior parte dei comandi
	consueti; il suo effetto è quello di prevenire l'interruzione
	di uno script nel caso in cui si verifichi un errore
	nell'esecuzione di un comando. Un eventuale errore viene
	registrato in un codice d'errore interno cui è possibile
	accedere con <fncref targ="$error"/> (un valore nullo indica
	che l'esecuzione ha avuto successo). Il valore di <fncref
	targ="$error"/> dovrebbe sempre essere controllato subito dopo
	aver usato <lit>catch</lit>, in modo da adottare le misure più
	opportune nel caso in cui il comando non dovesse aver avuto
	successo.
      </para>
      <para>
	Il comando <lit>catch</lit> non può essere usato prima di
	<lit>if</lit>, <lit>elif</lit> o <lit>endif</lit>. Inoltre,
	non può essere neanche usato per chiamate a funzioni definite
	dall'utente; il suo uso è limitato ai comandi di gretl e alle
	chiamate a funzioni od operatori
	<quote>nativi</quote>. Inoltre, <lit>catch</lit> non si può
	usare con l'operatore <quote>freccia</quote> per
	l'assegnazione di modelli o grafici alla sessione (vedi
	<guideref targ="chap:modes"/>).
      </para>
    </description>
  </command>

  <command name="chow" section="Tests" label="Test di Chow">

    <usage>
      <altforms>
        <altform><lit>chow</lit> <repl>obs</repl></altform>
        <altform><lit>chow</lit> <repl>dummyvar</repl> <lit>--dummy</lit></altform>
      </altforms>
      <options>
	<option>
	  <flag>--dummy</flag>
	  <effect>usa una variabile dummy preesistente</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le stime del modello aumentato</effect>
	</option>
	<option>
	  <flag>--limit-to</flag>
	  <optparm>lista</optparm>
	  <effect>limita il test a un sottoinsieme di regressori</effect>
	</option>
      </options>
      <examples>
        <example>chow 25</example>
        <example>chow 1988:1</example>
	<example>chow female --dummy</example>
      </examples>
    </usage>

    <description>
      <para context="gui">Questo comando richiede un numero di osservazione
      (o una data, se il dataset lo consente).</para>

      <para>
	Va eseguito dopo una regressione OLS e fornisce un test per
        l'ipotesi nulla che non esista un break strutturale del modello
        in corrispondenza del punto di rottura specificato. La procedura
        consiste nel creare una variabile dummy che vale 1 a partire dal punto
        di rottura specificato da <repl>osservazione</repl> fino alla fine del
        campione, 0 altrove; inoltre vengono creati dei termini di interazione
        tra questa dummy e i regressori originali.  Viene quindi stimata una
        regressione che include questi termini.
      </para>
      <para>
        Per impostazione predefinita viene calcolata una statistica
        <math>F</math>, prendendo la regressione aumentata come non
        vincolata e la regressione originale come vincolata. Se il
        modello originale usa uno stimatore robusto per la matrice di
        covarianza, come statistica test viene usato un valore
        chi-quadro di Wald, basato su uno stimatore robusto della
        matrice di covarianza della regressione aumentata.
      </para>
      <para context="cli">
	L'opzione <opt>limit-to</opt> si può usare per limitare
	l'insieme di regressori che verrà interagito con la dummy di
	sottocampionamento a un sottoinsieme di quelli originali. Il
	parametro di questa opzione dev'essere una lista pre-definita,
	contenente un sottoinsieme delle variabili esplicative; la
	costante non può farne parte.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/CHOW</menu-path>
    </gui-access>

  </command>

  <command name="clear" section="Programming" context="cli">
    <usage>
      <options>
	<option>
	  <flag>--dataset</flag>
	  <effect>cancella solo il dataset</effect>
	</option>
	<option>
	  <flag>--other</flag>
	  <effect>cancella tutto fuorché il dataset</effect>
	</option>
	<option>
          <flag>--all</flag>
          <effect>cancella proprio tutto</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Senza alcuna opzione, cancella dalla memoria tutti gli oggetti
	salvati, compreso l'eventuale campione corrente. Si noti che
	anche aprire un nuovo dataset o usare il comando
	<cmd>nulldata</cmd> per creare un dataset vuoto ha lo stesso
	effetto; per questo motivo di solito non è necessario usare
	<cmd>clear</cmd>.
      </para>
      <para>
	Con l'opzione <opt>dataset</opt> viene cancellato dalla
	memoria solo il dataset; tutti gli altri oggetti, come matrici
	e scalari salvati in precedenza, vengono conservati.
      </para>
      <para>
	Con l'opzione <opt>functions</opt>, tutte le funzioni definite
	dall'utente e tutte le funzioni definite dai pacchetti che
	sono stati caricati vengono cancellate dalla memoria. Il
	datasete le altre variabili non vengono toccati.
      </para>
      <para>
	Con l'opzione <opt>all</opt>, la cancellazione è totale, e
	riguarda il dataset, variabili di tutti i tipi, e tutte le
	funzioni, sia definite dall'utente che provenienti da pacchetti.
      </para>
    </description>
  </command>

  <command name="cluster" section="Estimation"
	   label="Robust variance estimation" context="gui">
    <description>
      <para>
	Scegliendo la seconda opzione è necessario fornire il nome di
	una variabile rispetto alla quale si effettua il clustering.
	Questa variabile dovrebbe assumere almeno due valori diversi,
	ma in generale il numero dei suoi valori distinti dovrebbe
	essere significativamente inferiore al numero di osservazioni
	nell'intervallo campionario considerato.
      </para>
      <para>
	Lo stimatore della varianza <quote>cluster-robust</quote>
	divide il campione in più sottoinsiemi o cluster sulla base dei
	valori assunti dalla variabile selezionata. Questo stimatore
	permette di evitare l'ipotesi classica che il termine d'errore
	sia indipendente e identicamente distribuito, perché ammette
	la possibilità che la sua varianza vari da un cluster
	all'altro e che ogni errore possa presentare un certo grado di
	dipendenza dagli altri errori all'interno dello stesso
	cluster.
      </para>
    </description>
  </command>

  <command name="coeffsum" section="Tests" label="Somma dei coefficienti">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
        <option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
	</option>
      </options>
      <examples>
        <example>coeffsum xt xt_1 xr_2</example>
	<demos>
	  <demo>restrict.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="gui">Questo comando richiede una lista di variabili,
      selezionate tra le variabili indipendenti di un modello.
      </para>
      <para context="gui">
	Calcola la somma dei coefficienti delle variabili nella lista
        e mostra l'errore standard e il p-value per l'ipotesi nulla che la
        somma sia zero.
      </para>
      <para context="cli">
	Deve essere usato dopo una regressione. Calcola la somma dei
        coefficienti delle variabili nella <repl>lista-variabili</repl>
        e ne mostra l'errore standard e il p-value per l'ipotesi nulla
        che la loro somma sia zero.
      </para>
      <para>
	Si noti la differenza tra questo test e <cmdref
	targ="omit"/>, che assume come ipotesi nulla l'uguaglianza a zero
        di <emphasis>tutti</emphasis> i coefficienti di un gruppo di variabili
      indipendenti.</para>
      <para context="cli">
	L'opzione <opt>quiet</opt> potrebbe risultare utile se si vuole
	accedere ai valori <fncref targ="$test"/> e <fncref targ="$pvalue"/>,
	che vengono registrati al completamento della procedura.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/Somma dei coefficienti</menu-path>
    </gui-access>

  </command>

  <command name="coint" section="Tests"
	   label="Test di cointegrazione di Engle-Granger">

    <usage>
      <arguments>
        <argument>ordine</argument>
        <argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>non include la costante</effect>
	</option>
 	<option>
	  <flag>--ct</flag>
	  <effect>include la costante e il trend</effect>
	</option>
	<option>
	  <flag>--ctt</flag>
	  <effect>include la costante e il trend quadratico</effect>
	</option>
	<option>
	  <flag>--seasonals</flag>
	  <effect>include dummy stagionali</effect>
	</option>
	<option>
	  <flag>--skip-df</flag>
	  <effect>non esegue i test DF sulle variabili individuali</effect>
	</option>
	<option>
	  <flag>--test-down</flag>
	  <optparm optional="true">criterio</optparm>
	  <effect>scelta automatica dell'ordine dei ritardi</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra dettagli extra sulle regressioni</effect>
	</option>
	<option>
	  <flag>--silent</flag>
	  <effect>non stampa nulla</effect>
	</option>
      </options>
      <examples>
        <example>coint 4 y x1 x2</example>
        <example>coint 0 y x1 x2 --ct --skip-df</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
        Test di cointegrazione di Engle&ndash;Granger. La procedura
        predefinita è la seguente: (1) eseguire dei test
        Dickey&ndash;Fuller aumentati, sull'ipotesi nulla che ognuna
        delle variabili elencate abbia una radice unitaria; (2)
        stimare la regressione di cointegrazione; (3) eseguire un test
        DF sui residui della regressione di cointegrazione. Se si usa
        l'opzione <opt>skip-df</opt>, il passo (1) viene saltato.
      </para>
      <para context="cli">
        Se l'ordine di ritardo specificato è positivo, tutti i test
        Dickey&ndash;Fuller utilizzano questo ordine. Se l'ordine
        indicato viene preceduto da un segno meno, viene interpretato
        come l'ordine massimo, e l'ordine utilizzato effettivamente
        viene ricavato con la stessa procedura di test "all'indietro"
        descritta per il comando <cmdref targ="adf"/>.
      </para>
      <para context="cli">
	L'impostazione predefinita consiste nell'includere una
	costante nella regressione di cointegrazione; se si vuole
	omettere la costante, basta usare l'opzione <opt>nc</opt>. Se
	si vuole aggiungere all'elenco dei termini deterministici
	della regressione un trend lineare o quadratico, basta usare
	le opzioni <opt>ct</opt> o <opt>ctt</opt>. Queste opzioni sono
	mutualmente esclusive.  Volendo, se i dati sono trimestrali o
	mensili, la regressione può comprendere dummy stagionali.
      </para>
      <para context="cli">
        Test di cointegrazione di Engle&ndash;Granger. La procedura
        predefinita è la seguente: (1) eseguire dei test
        Dickey&ndash;Fuller aumentati, sull'ipotesi nulla che ognuna
        delle variabili elencate abbia una radice unitaria; (2)
        stimare la regressione di cointegrazione; (3) eseguire un test
        DF sui residui della regressione di cointegrazione. Se si
        attiva la casella <lit>Salta i test DF iniziali</lit>, il
        passo (1) viene saltato.
      </para>
      <para context="gui">
	Se l'ordine di ritardo, <math>k</math>, è maggior di 0,
	verranno inclusi <math>k</math> ritardi della variabile
	dipendente al secondo membro di ognuna delle regressioni di
	test, a meno che non si usi la casella <quote>test dal massimo
	ordine di ritardi all'indietro</quote>: in questo caso,
	l'ordine specificato viene considerato come massimo e l'ordine
	usato effettivamente viene determinato con la procedura di
	test "all'indietro" descritta per il comando <cmdref
	targ="adf"/>.
      </para>
      <para context="gui">
	L'impostazione predefinita consiste nell'includere una
	costante nella regressione di cointegrazione. Se si vuole
	omettere la costante, o aggiungere dummy stagionali oppure un
	trend lineare o quadratico, basta selezionare le relative
	opzioni nella finestra di dialogo.
      </para>
      <para>
        I <emphasis>pvalue</emphasis> per questo test si basano su
	MacKinnon (1996). Il codice relativo è stato incluso per gentile
        concessione dell'autore.
      </para>
      <para>
	Per il test di cointegrazione di Søren Johansen, si veda il
	comando <cmdref targ="johansen"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/Test di cointegrazione/Engle-Granger</menu-path>
    </gui-access>

  </command>


  <command name="compact" section="Dataset" context="gui"
	   label="Compattamento dei dati">

    <description>

      <para>
	Quando viene aggiunta a un dataset una serie di frequenza
        maggiore, occorre <quote>compattare</quote> la nuova serie.
	Ad esempio, una serie mensile deve essere compattata per
        adattarsi a un dataset trimestrale.
      </para>
      <para>
	Inoltre, a volte può essere necessario compattare un intero
	dataset abbassandone la frequenza (ad esempio, prima di aggiungere
	al dataset una variabile a frequenza minore).
      </para>
      <para>
	Ci sono cinque opzioni per il compattamento:
      </para>
      <ilist>
	<li><para>Media: i nuovi valori saranno la media aritmetica
	dei corrispondenti valori della serie a frequenza maggiore.
        Ad esempio, il valore per il primo trimestre del 1990 sarà la
        media dei valori di gennaio, febbraio e marzo del 1990.</para>
	</li>
	<li><para>Somma: i nuovi valori saranno la somma dei
        corrispondenti valori della serie a frequenza maggiore.
        Ad esempio, il valore per il primo trimestre sarà la somma dei
        valori di gennaio, febbraio e marzo.</para>
	</li>
	<li><para>Valori di fine periodo: il nuovo valore è l'ultimo
        valore corrispondente nella serie a frequenza maggiore.
	Ad esempio, il valore del primo trimestre del 1990 sarà quello
        del marzo 1990.</para>
	</li>
	<li><para>Valori di inizio periodo: il nuovo valore è il primo
        valore corrispondente nella serie a frequenza maggiore.
        Ad esempio, il valore del primo trimestre del 1990 sarà quello
        del gennaio 1990.</para>
	</li>
	<li>
	  <para>
	    Espansione su più serie: in questo caso non viene persa
	    alcuna informazione; piuttosto, essa viene suddivisa su
	    <math>m</math> serie, dove <math>m</math> è il rapporto fra
	    la frequenza più alta e quella più bassa. Ogni serie
	    risultato contiene il valore di uno specifico sottoperiodo,
	    che è identificato da un suffisso ad hoc. Ad esempio, il
	    compattamento per espansione di una serie mensile a un
	    dataset trimestrale provoca la creazione di tre serie, una
	    per ogni mese del trimestre; nei loro nomi compaiono i
	    suffissi <lit>m01</lit>, <lit>m02</lit> e <lit>m03</lit>.
	  </para>
	</li>
      </ilist>

      <para>
	Se si compatta un intero dataset, il metodo di
	compattamento scelto diventa quello predefinito, ma se si è
	scelto un metodo di compattamento per una certa variabile (nel
	menù <quote>Variabile/Modifica attributi</quote>) viene usato
	quel metodo al posto di quello predefinito.  Se il metodo di
	compattamento è già stato scelto per tutte le variabili, non
	viene presentata la scelta per il metodo di compattamento
	predefinito.
      </para>

    </description>
  </command>

  <command name="continue" section="Programming"
    label="Salta alla fine di un loop" context="cli">
    <description>
      <para>
       Questo comando può essere usato solo in un loop; ha l'effetto
       di saltare tutte le istruzioni seguenti nella iterazione
       corrente (più interna) del loop.  Vedi anche <cmdref
       targ="loop"/>, <cmdref targ="break"/>
      </para>
    </description>
  </command>

  <command name="controlled" section="Graphs" context="gui"
	   label="Grafici a dispersione con controllo">

    <description>
      <para>
        Questo comando richiede la scelta di tre variabili, una per l'asse X,
        una per l'asse Y e una variabile di controllo (chiamata Z). Il grafico
        mostra le variabili X e Y controllate per la variabile Z, ossia i
        residui della regressione OLS di ogni variabile su Z.
      </para>
      <para>
	Esempio: si hanno dati sui salari, l'esperienza e il livello
        educativo in un campione di persone e si vuole un grafico dei salari
        rispetto all'educazione, controllando per l'esperienza. In questo caso,
        basta selezionare i salari per l'asse Y, l'educazione per l'asse X e
        l'esperienza come variabile di controllo: il grafico mostrerà la
        relazione tra le due variabili <quote>depurate</quote> dall'effetto
        dell'esperienza.
      </para>
    </description>

  </command>

  <command name="corr" section="Statistics" label="Coefficienti di correlazione">

    <usage>
      <altforms>
	<altform><lit>corr [</lit> <repl>lista-variabili</repl> ]</altform>
	<altform><lit>corr --matrix=</lit><repl>nome-matrice</repl></altform>
      </altforms>
      <options>
 	<option>
	  <flag>--uniform</flag>
          <effect>assicura l'uniformità del campione</effect>
	</option>
	<option>
	  <flag>--spearman</flag>
	  <effect>Rho di Spearman</effect>
	</option>
	<option>
	  <flag>--kendall</flag>
	  <effect>Tau di Kendall</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i ranghi</effect>
	</option>
        <option>
	  <flag>--plot</flag>
	  <optparm>modo o nome del file</optparm>
	  <effect>si veda di seguito</effect>
        </option>
	<option>
	  <flag>--triangle</flag>
	  <effect>stampa solo il triangolo inferiore, vedi sotto</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
      </options>
      <examples>
        <example>corr y x1 x2 x3</example>
	<example>corr ylist --uniform</example>
	<example>corr x y --spearman</example>
	<example>corr --matrix=X --plot=display</example>
      </examples>
    </usage>

    <description context="gui">
      <para>
        Mostra le coppie di coefficienti di correlazione (la correlazione del
        prodotto dei momenti di Pearson) per le variabili selezionate. Il
        comportamento predefinito consiste nell'usare tutte le osservazioni
        disponibili per calcolare ognuno dei coefficienti, ma attivando
        l'opportuna casella il campione verrà limitato (se necessario) in modo
        che per tutti i coefficienti venga usato lo stesso insieme di
        osservazioni. Questa opzione ha effetto solo se le diverse variabili
        contengono un numero diverso di valori mancanti.
      </para>
    </description>

    <description context="cli">
      <para>
        Per impostazione predefinita, mostra le coppie di coefficienti
        di correlazione (la correlazione del prodotto dei momenti di
        Pearson) per le variabili date nella
        <repl>lista-variabili</repl>, o per tutte le variabili del
        dataset se non viene specificata alcuna
        <repl>lista-variabili</repl>. Il comportamento predefinito
        consiste nell'usare tutte le osservazioni disponibili per
        calcolare ognuno dei coefficienti, ma se si usa l'opzione
        <flag>--uniform</flag> il campione verrà limitato (se
        necessario) in modo che per tutti i coefficienti venga usato
        lo stesso insieme di osservazioni. Questa opzione ha effetto
        solo se le diverse variabili contengono un numero diverso di
        valori mancanti.
      </para>
      <para>
	Le opzioni (mutualmente esclusive) <opt>spearman</opt> e
	<opt>kendall</opt> producono rispettivamente, la correlazione
	di rango di Spearman (rho) e la correlazione di rango di
	Kendall (tau), invece del solito coefficiente di
	Pearson. Quando si usa una di queste opzioni, la
	<repl>lista-variabili</repl> deve contenere solo due
	variabili.
      </para>
      <para>
        Quando viene calcolata la correlazione di rango, si può usare
        l'opzione <opt>verbose</opt> per mostrare i dati originali e
        ordinati (altrimenti questa opzione verrà ignorata).
      </para>
      <para>
	Se <repl>lista-variabili</repl> contiene più di due serie e il
	programma non è in modalità batch, verrà mostrato un grafico a
	<quote>temperatura</quote> della matrice di correlazione,
	regolato dall'opzione <opt>plot</opt>. Per questa
	opzione, i parametri possibili sono <lit>none</lit> (per non
	averlo), <lit>display</lit> (per mostrarlo a video anche in
	modo batch), o un nome di file. Quest'ultima scelta ha effetti
	uguali a quelli dell'opzione <opt>output</opt> per il comando
	<cmdref targ="gnuplot"/>. L'opzione <opt>triangle</opt> fa sì
	che il grafico contenga solo il triangolo inferiore della
	matrice.
      </para>
      <para>
	Se si usa la forma alternativa, dando come argomento un nome
	di matrice piuttosto che una lista variabili, le opzioni
	<opt>spearman</opt> e <opt>kendall</opt> non sono
	disponibili&mdash; si veda quindi la funzione <fncref
	targ="npcorr"/>.
      </para>
      <para>
	L'accessore <fncref targ="$result"/> può essere utilizzato per
	salvare i risultati sotto forma di matrice.  Si noti che, se è
	questa matrix l'oggetto di interesse, anziché i singoli
	coefficienti, in presenza di valori mancanti è consigliabile
	l'uso dell'opzione <opt>uniform</opt> option.  Se il campione
	usato non è lo stesso per tutti i coefficienti, non c'è
	garanzia che la matrice di correlazione sia positiva
	semidefinita, proprietà che dovrebbe valere per costruzione.
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Matrice di correlazione</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione multipla)</other-access>
    </gui-access>

  </command>

  <command name="corrgm" section="Statistics" label="Correlogramma">

    <usage>
      <arguments>
        <argument>y</argument>
        <argument optional="true">max-ritardo</argument>
      </arguments>
      <options>
	<option>
	  <flag>--bartlett</flag>
	  <effect>usa gli errori standard di Bartlett</effect>
	</option>
	<option>
	  <flag>--plot</flag>
	  <optparm>modo o nome di file</optparm>
	  <effect>si veda sotto</effect>
	</option>
	<option>
	  <flag>--silent</flag>
	  <effect>sopprime l'ouput</effect>
        </option>
	<option>
	  <flag>--acf-only</flag>
	  <effect>omit partial autocorrelations</effect>
        </option>
      </options>
      <examples>
        <example>corrgm x 12</example>
	<example>corrgm GDP 12 --acf-only</example>
      </examples>
    </usage>

    <description>
      <para context="notex">
	Mostra i valori della funzione di autocorrelazione per la
	serie <repl>y</repl> specificata (dal nome o dal numero).  I
	valori sono definiti come &rgr;(<math>u</math><sub>t</sub>,
	<math>u</math><sub>t-s</sub>) dove <math>u</math><sub>t</sub>
	è la <math>t</math>-esima osservazione della variabile
	<math>u</math> e <math>s</math> è il numero dei
	ritardi.
      </para>
      <para context="tex">
	Mostra i valori della funzione di autocorrelazione per la serie
	<repl>y</repl> specificata (dal nome o dal numero).  I
	valori sono definiti come $\hat{\rho}(u_t, u_{t-s})$, where
	$u_t$ è la $t$-esima osservazione della variabile e $s$ è il
	numero dei ritardi.
      </para>
      <para context="cli">
	A meno che non sia attiva l'opzione <opt>acf-only</opt>,
	vengono mostrate anche le autocorrelazioni parziali (calcolate
	con l'algoritmo di Durbin&ndash;Levinson), ossia al netto
	dell'effetto dei ritardi intermedi.
      </para>
      <para context="gui">
	Per impostazione predefinita, vengono mostrate anche le
	autocorrelazioni parziali (calcolate con l'algoritmo di
	Durbin&ndash;Levinson), ossia al netto dell'effetto dei
	ritardi intermedi, ma volendo questa opzione può essere
	disattivata.
      </para>
      <para context="cli">
	La significatività statistica delle singole autocorrelazioni
	viene indicata per mezzo di asterischi. Di default, questo
	viene valutato utilizzando un errore standard pari all'inversa
	della radice quadrata della dimensione del campione, ma se
	viene specificata l'opzione <opt>bartlett</opt>, vengono
	utilizzati gli errori standard di Bartlett per l'ACF; vedere
	sotto per i dettagli. Questa opzione influisce anche sulla
	banda di confidenza disegnata nel grafico ACF, se
	applicabile. Inoltre, viene mostrata la statistica
	<math>Q</math> di Ljung-Box; questa verifica il valore nullo
	che la serie sia <quote>white noise</quote> fino al ritardo
	specificato.
      </para>
      <para context="gui">
	La significatività statistica delle singole autocorrelazioni
	viene indicata per mezzo di asterischi.  Di default, questo
	viene valutato utilizzando un errore standard pari all'inversa
	della radice quadrata della dimensione del campione, ma se
	viene specificata l'opzione <opt>bartlett</opt>, vengono
	utilizzati gli errori standard di Bartlett per l'ACF; vedere
	sotto per i dettagli. Questa opzione influisce anche sulla
	banda di confidenza disegnata nel grafico ACF, se
	applicabile. Inoltre, viene mostrata la statistica
	<math>Q</math> di Ljung-Box; questa verifica il valore nullo
	che la serie sia <quote>white noise</quote> fino al ritardo
	specificato.
      </para>
      <para context="cli">
	Se viene specificato un valore <repl>max-ritardo</repl>, la
	lunghezza del correlogramma viene limitata al numero di
	ritardi specificato, altrimenti viene scelta automaticamente
	in funzione della frequenza dei dati e del numero di
	osservazioni.
      </para>
      <subhead>Errori standard di Bartlett</subhead>
      <para>
	Si noti che in questo contesto gli errori standard di Bartlett
	non sono solo una variante robusta di quelli predefiniti. Gli
	errori standard predefiniti si riferiscono all'ipotesi nulla
	che la serie in questione sia rumore bianco; in parole povere,
	questa non viene rifiutata al livello del 5% se non più del 5%
	dei valori ACF supera l'errore standard moltiplicato per
	1.96. I valori di Bartlett, invece, sono associati all'ipotesi
	nulla che la serie segua un processo a media mobile. Nello
	specifico, se nessun valore ACF supera i limiti di Bartlett
	con ritardi maggiori di <math>k</math>, non possiamo rifiutare
	l'ipotesi nulla che <math>y</math> sia
	MA(<math>k</math>&minus;1). Si veda il capitolo 7 di <cite
	key="brockwell-davis87">Brockwell e Davis (1987)</cite> per
	ulteriori informazioni su questo punto.
      </para>
      <subhead context="cli">Grafici</subhead>
      <para context="cli">
	Di default, se gretl non è in modalità batch, viene mostrato
	un grafico del correlogramma.  Questo
	comportamento può essere modificato con l'opzione
	<opt>plot</opt>.  Per questa opzione i parametri accettabili
	sono <lit>none</lit> (per eliminare il grafico); <lit>display</lit> (per
	produrre un grafico gnuplot anche in modalità batch); oppure
	il nome di un file. In quest'ultimo caso l'effetto è quello
	descritto per l'opzione <opt>output</opt> del comando <cmdref
	targ="gnuplot"/>.
      </para>
      <subhead context="cli">Accessori</subhead>
      <para>
	Se il comando va a buon fine, gli accessori <fncref targ="$test"/> e
	<fncref targ="$pvalue"/> conterranno i valori corrispondenti per la
	statistica di Ljung&ndash;Box, per l'ordine
	<repl>max-ritardo</repl>. Peraltro, se si vuole semplicemente
	calcolare la statistica <math>Q</math> senza che il programma
	produca alcun output, consigliamo di usare la funzione <fncref
	targ="ljungbox"/> anziché questo comando.
      </para>

    </description>

    <gui-access>
      <menu-path>/Variabile/Correlogramma</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
    </gui-access>

  </command>

  <command name="count-model" section="Estimation" context="gui"
	   label="Models for count data">

    <description>
      <para>
	Il comando assume che la variabile dipendente rappresenti un
	conteggio del numero di volte in cui si è verificato un certo
	evento e deve assumere solo valori interi non negativi. Di
	default viene utilizzata la distribuzione di Poisson, ma il
	menu a tendina da' la possibilità di usare la distribuzione
	Binomale Negativa. (In econometria viene di solito usata la
	variante NegBin 2, ma è comunque disponibile anche la meno
	frequente NegBin 1).
      </para>
      <para>
	Fra le opzioni è possibile aggiungere alla specificazione una
	variabile di <quote>offset</quote>, un fattore di scala il cui
	logaritmo viene aggiunto alla funzione di regressione lineare
	(implicitamente con un coefficiente unitario). Questa
	operazione è ragionevole se si ritiene che il numero di
	realizzazioni dell'evento sia, a parità di tutte le altre
	variabili, proporzionale a un fattore noto. Per esempio,
	potremmo ritenere che, a parità di condizioni, il numero di
	incidenti stradali sia proporzionale al volume del traffico;
	in questo caso quest'ultimo potrebbe essere indicato come
	variabile di <quote>offset</quote> in un modello che studia il
	numero di incidenti. La variabile di offset deve essere
	strettamente positiva.
      </para>
      <para>
	Di default, gli standard error vengono calcolati usando
	un'approssimazione numerica della matrice Hessiana in
	corrispondenza delle stime dei parametri.  Se viene
	selezionata l'opzione <quote>Robust standard errors</quote> il
	comando calcola gli standard error QML a partire dalla matrice
	di covarianza <quote>sandwich</quote> che usa sia l'inversa
	dell'Hessiana che la matrice OPG.
      </para>
    </description>
  </command>

  <command name="curve" section="Graphs" label="Plot a curve"
	   context="gui">

    <description>
      <para>
	Questa finestra di dialogo permette di creare un grafico
	gnuplot specificando una formula, a condizione che
	quest'ultima sia un'espressione che gnuplot è in grado di
	accettare. Per indicare la variabile sull'asse orizzontale
	usate <lit>x</lit>. Si noti che gnuplot usa <lit>**</lit> per
	indicare l'elevamento a potenza e che il separatore dei
	decimali deve essere <quote>.</quote>.  Esempi:
      </para>
      <code>
	10+0.35*x
	100+5.3*x-0.12*x**2
	sin(x)
	exp(sqrt(pi*x))
      </code>
      <para>
	Per inserire una nuova linea in un grafico usando questo comando,
	cliccate sul grafico, selezionate <quote>Edit</quote> e
	<quote>Lines</quote> nel menu dei comandi di modifica del grafico,
	e usate il pulsante <quote>Add line</quote>.
      </para>
    </description>
  </command>

  <command name="cusum" section="Tests" label="Test CUSUM">

    <usage>
      <options>
	<option>
	  <flag>--squares</flag>
	  <effect>esegue il test CUSUMSQ</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>stampa solamente il test di Harvey&ndash;Collier</effect>
	</option>
	<option>
	  <flag>--plot</flag>
	  <optparm>output</optparm>
	  <effect>vedi sotto</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello OLS. Esegue il test
	CUSUM (o, se si usa l'opzione <opt>squares</opt>, il test
        CUSUMSQ) per la stabilità dei parametri. Viene calcolata una
        serie di errori di previsione per il periodo successivo,
        attraverso una serie di regressioni: la prima usa le prime
	<math>k</math> osservazioni e viene usata per generare
        la previsione della variabile dipendente per l'osservazione
	<math>k</math> + 1; la seconda usa le prime
        <math>k</math> + 1 osservazioni per generare una previsione
        per l'osservazione <math>k</math> + 2 e cos via (dove
	<math>k</math> è il numero dei parametri nel modello originale).
      </para>
      <para>
	Viene mostrata, anche graficamente, la somma cumulata degli
	errori scalati di previsione (o dei quadrati degli
	errori). L'ipotesi nulla della stabilità dei parametri è
	rifiutata al livello di significatività del 5 per cento se la
	somma cumulata va al di fuori delle bande di confidenza al 95
	per cento.
      </para>
      <para>
        Nel caso di test CUSUM, viene mostrata anche la statistica
        <math>t</math> di Harvey&ndash;Collier per testare l'ipotesi nulla
        della stabilità dei parametri. Si veda il Capitolo 7 di
        <book>Econometric Analysis</book> di Greene, per i dettagli. Per il test
	CUSUMSQ, la banda di confidenza al 95% è calcolata usando l'algoritmo
        descritto in <cite key="edgerton94">Edgerton e Wells
	(1994)</cite>.
      </para>
      <para>
	Di default, se il programma non è in modalità batch, viene
	mostrato un grafico della series cumulata con la sua banda di
	confidenza. Questo comportamento può essere modificato tramite
	l'opzione <opt>plot</opt>, che può prendere come parametri
	<lit>none</lit> (per non produrre il grafico);
	<lit>display</lit> (per mostrarlo anche quando si è in modo
	batch); oppure, un nome di file. Nell'ultimo caso l'effetto è
	lo stesso dell'opzione <opt>output</opt> del comando <cmdref
	targ="gnuplot"/>.
      </para>

    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/CUSUM(SQ)</menu-path>
    </gui-access>

  </command>

  <command name="daily-purge" section="Dataset"
	   label="Purge daily data" context="gui">
    <description>
      <para>
	Se un dataset giornaliero è nominalmente a 7 giorni, ma di
	fatto include solo quelli lavorativi, raccomandiamo di
	cancellare le righe vuote relative ai fine settimana, e
	convertire il data set a un calendario basato su 5 giorni.
      </para>
      <para>
	Se un dataset a 5 giorni contiene un piccolo numero di righe
	vuote (presumibilmente, festività) è consigliabile
	eliminarle. L'effetto è quello di trattare i valori per i
	festivi come inesistenti anziché come veri <quote>dati
	mancanti</quote>, e trattare così la serie come continua.
      </para>
      <para>
	Si noti che con ambo queste opzioni gretl continuerà a
	preservare l'informazione relativa alla data, e la
	riscostruzione successiva del calendario completo sarà
	comunque possibile se necessario, attraverso il comando <cmdref
	targ="dataset"/> con l'opzione <lit>pad-daily</lit>.
      </para>
    </description>
  </command>

  <command name="data" section="Dataset"
	   label="Importazione da database" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--compact</flag>
	  <optparm>metodo</optparm>
	  <effect>specifica un metodo di aggregazione</effect>
	</option>
	<option>
	  <flag>--interpolate</flag>
	  <effect>interpola i dati a bassa frequenza</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati tranne che in caso di errore</effect>
	</option>
	<option>
	  <flag>--name</flag>
	  <optparm>identificatore</optparm>
	  <effect>rinomina le serie importate</effect>
	</option>
	<option>
	  <flag>--odbc</flag>
	  <effect>importa via ODBC</effect>
	</option>
	<option>
	  <flag>--no-align</flag>
	  <effect>specifico per ODBC, vedi sotto</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
        Legge le variabili nella <repl>lista-variabili</repl> da un
        database (gretl, RATS 4.0 o PcGive), che deve essere stato
        precedentemente aperto con il comando <cmdref targ="open"/>.
        Il comando <lit>data</lit> è anche usat pe rimportare dati da
        DB.NOMICS o da una fonte dati ODBC; per maggiori dettugli su
        queste varianti si vedano rispettivamente <mnu
        targ="gretlDBN">gretl + DB.NOMICS</mnu> e <guideref
        targ="chap:odbc"/>.
      </para>
      <para>
	La frequenza dei dati e l'intervallo del campione
        possono essere impostati usando i comandi <cmdref
        targ="setobs"/> e <cmdref targ="smpl"/> prima di questo
      comando. Ecco un esempio completo:</para>
      <code>
	open fedstl.bin
	setobs 12 2000:01
	smpl ; 2019:12
	data unrate cpiaucsl
      </code>
      <para>
	Questi comandi aprono il database chiamato
	<filename>fedstl.bin</filename> (fornito con gretl), impostano
	un dataset mensile che va da gennaio 2000 a dicembre 2019 e
	infine importano le serie <lit>unrate</lit> e
	<lit>cpiaucsl</lit>.
      </para>
      <para>
        Se non si specificano <lit>setobs</lit> e <lit>smpl</lit> nel
        modo descritto, la frequenza dei dati e l'intervallo del
        campione vengono impostati usando la prima variabile letta dal
        database.
      </para>
      <para>
        Se le serie da leggere hanno frequenza maggiore di quella
        impostata nel dataset, è possibile specificare un metodo di
        compattamento, come mostrato di seguito
      </para>
      <code>
	data LHUR PUNEW --compact=average
      </code>
      <para>
	I cinque metodi di compattamento disponibili sono
	<quote>average</quote> (usa la media delle osservazioni ad
	alta frequenza), <quote>last</quote> (usa l'ultima
	osservazione), <quote>first</quote>, <quote>sum</quote> e
	<quote>spread</quote>. Se non si specifica alcun metodo, verrà
	usata la media delle osservazioni. Il metodo
	<quote>spread</quote> è speciale: l'informazione, anziché
	essere condensata, verrà suddivisa su più serie, una per
	sottoperiodo. Ad esempio, l'aggiunta di una serie mensile ad
	un dataset trimestrale provoca la creazione di tre, serie, una
	per ogni mese del trimestre; nei loro nomi compaiono i
	suffissi <lit>m01</lit>, <lit>m02</lit> e <lit>m03</lit>.
      </para>
      <para>
	Se la serie in ingresso è a frequenza più bassa di quella del
	dataset, il default è ripetere il valore dei dati in ingresso;
	in seguito, si può usare la funzione <fncref targ="tdisagg"/>
	per disaggregare temporalmente la serie.
      </para>
      <para>
	Se il database è in formato nativo gretl, i caratteri
	<quote>glob</quote> <lit>*</lit> e <lit>?</lit> can be used in
	<repl>varlist</repl>, nella ricerca delle serie da
	importare. L'esempio che segue importerà tutte le serie i cui
	nomi comiciano per <lit>cpi</lit>:
      </para>
      <code>
	data cpi*
      </code>
      <para>
	L'opzione <opt>name</opt> può essere utilizzata per impostare
	un nome diverso dall'originale per le nuove serie storiche
	importate nel dataset. Il parametro deve essere un
	identificatore valido.  Questa opzione è circoscritta al caso
	in cui è stata specificata una singola serie storica per
	l'importazione.
      </para>
      <para>
	L'opzione <opt>no-align</opt> produce effetti solo quando si
	importano serie via ODBC. Per impostazione predefinita, la
	query ODBC deve ritornare delle informazioni con cui gretl
	possa piazzare i dati in ingresso nelle righe appropriate del
	dataset&mdash; o per lo meno, che il numero di cifre in
	entrata coincida con la lunghezza del dataset o del
	sottocampione attuale. Con l'opzione <opt>no-align</opt>
	questo requisito viene allentato: se le condizioni di cui
	sopra non sono rispettate, i datri in ingresso sono
	semplicemente messi all'inizio del dataset, partendo dalla
	prima riga. Se i dati in ingresso sono meno della dimensione
	del campione, le righe in eccesso saranno riempite con NAs;
	altrimenti, i dati in più verranno buttati via. Per maggiori
	dettagli sull'importazione via ODBC, si veda <guideref
	targ="chap:odbc"/>.
      </para>
    </description>
    <gui-access>
      <menu-path>/File/Database</menu-path>
    </gui-access>

  </command>

  <command name="data-files" section="Programming"
	   label="Data files" context="gui">
    <description>
      <para>
	Questa finestra di dialogo permette di specificare file
	aggiuntivi da includere al pacchetto. Tale inclusione implica
	che il pacchetto avrà la forma di un file zip.  Se gretl dovrà
	occuparsi di creare il file zip per voi, allora tutti i file
	specificati qui dovranno essere nella stessa directory del
	file gfn. È anche possibile includere delle sottodirectory, nel qual
	caso si dà per inteso che verranno inclusi nel file zip anche
	tutti i file in esse contenuti.
      </para>
      <para>
	Questa funzionalità obbedisce a due scopi: in primis, si potrà
	includere un file di dati per l'uso con lo script di esempio
	del pacchetto, se nessuno dei file di dati di esempio
	normalmente presenti nella distribuzione vanno bene allo
	scopo. In tal caso, i dati dovranno essere in formato nativo
	(<lit>gdt</lit> o binario <lit>gdtb</lit>). In secundis, se il
	pacchetto richiede l'uso di grandi matrici pre-calcolate (ad
	esempio, contenenti i valori critici di una statistica test
	particolare), potrebbe essere più comodo includerle come
	file matrice (<lit>mat</lit>) anziché metterle assieme visa
	dichiarazioni in hansl.
      </para>
      <para>
	Per accedere ad un file <lit>gdt</lit> o <lit>gdtb</lit>
	incluso in un pacchetto dallo script di esempio, si usi
	l'opzione <opt>frompkg</opt> col comando <lit>open</lit>,
	usando il nome del pacchetto come parametro. Ad esempio:
      </para>
      <code>
	open almon.gdt --frompkg=almonreg
      </code>
      <para>
	Per leggere un file matrice da un pacchetto, usare la stringa
	predefinita <lit>$pkgdir</lit>, come ad esempio in
      </para>
      <code>
	string mname = sprintf("%s/A.mat", $pkgdir)
	matrix A = mread(mname)
      </code>
      <para>
	(Si noti che il carattere <quote><lit>/</lit></quote> dovrebbe
	funzionare tranquillamente come separatore di percorso anche
	sotto MS Windows.)
      </para>
    </description>
  </command>

  <command name="dataset" section="Dataset"
	   label="Manipola il dataset" context="cli">

    <usage>
      <arguments>
        <argument>parola-chiave</argument>
	<argument>parametri</argument>
      </arguments>
      <options>
	<option>
	  <flag>--panel-time</flag>
	  <effect>vedi sotto addobs</effect>
	</option>
      </options>
      <examples>
        <example>dataset addobs 24</example>
        <example>dataset insobs 10</example>
        <example>dataset compact 1</example>
        <example>dataset compact 4 last</example>
        <example>dataset expand</example>
        <example>dataset transpose</example>
        <example>dataset sortby x1</example>
	<example>dataset resample 500</example>
	<example>dataset renumber x 4</example>
	<example>dataset pad-daily 7</example>
	<example>dataset clear</example>
        <example>dataset unpad-daily</example>
      </examples>
    </usage>

    <description>
      <para>
	Esegue varie operazioni sull'intero dataset a seconda della
	<repl>parola-chiave</repl> usata, che può essere
	<lit>addobs</lit>, <lit>insobs</lit>, <lit>clear</lit>,
	<lit>compact</lit>, <lit>expand</lit>, <lit>transpose</lit>,
	<lit>sortby</lit>, <lit>dsortby</lit>, <lit>resample</lit>,
	<lit>renumber</lit>, <lit>pad-daily</lit> o
	<lit>unpad-daily</lit>. Nota: ad eccezione di
	<lit>clear</lit> questi comandi non sono disponibili quando
	sul dataset è definito un sotto-campione ottenuto selezionando
	le osservazioni con un criterio Booleano.
      </para>
      <para>
	<lit>addobs</lit>: deve essere seguito da <math>n</math>, un
	intero positivo. Aggiunge <math>n</math> osservazioni alla
	fine del dataset, tipicamente a scopo di ottenere delle
	previsioni. I valori della maggior parte delle variabili
	nell'intervallo aggiunto sono impostati come valori mancanti,
	ma alcune variabili deterministiche, ad esempio le tendenze
	lineari e le variabili dummy periodiche, sono riconosciute ed
	estese. Se il dataset aperto è di tipo panel, l'opzione
	<opt>panel-time</opt> consente di allungare il campione di
	<math>n</math> osservazioni per ogni unità cross-sezionale
	(mentre il default è di aggiungere <math>n</math> unità).
      </para>
      <para>
	<lit>insobs</lit>: Deve essere seguito da un intero positivo
	inferiore o uguale al numero corrente di
	osservazioni. Inserisce una singola osservazione nella
	posizione specificata. Tutti i dati successivi sono spostati
	di una posizione e il dataset è allungato di un'osservazione.
	In corrispondenza della nuova osservazione a tutte le
	variabili, a parte la costante, vengono assegnati valori
	mancanti. Questa azione non è disponibile in dataset panel.
      </para>
      <para>
	<lit>clear</lit>: Non richiede parametri. Elimina il campione
	corrente e riporta gretl al suo stato iniziale senza dati.
      </para>
      <para>
	<lit>compact</lit>: Questo comando è disponibile solo se il
	dataset contiene serie storiche: compatta tutte le serie del
	dataset ad una nuova frequenza. Deve essere seguito da un
	intero positivo rappresentante la frequenza scelta.
	Quest'ultima dovrebbe essere minore di quella attuale (ad
	esempio, un valore 4 quando la frequenza attuale è 12
	compatterà un dataset mensile in uno trimestrale); la sola
	eccezione ammessa è una frequenza di 52 (settimanale) quando
	il dataset è giornaliero (frequenza 5, 6 o 7). È possibile
	fornire un secondo parametro tra <lit>sum</lit>,
	<lit>first</lit>, <lit>last</lit> o <lit>spread</lit>, per
	specificare di compattare, rispettivamente, usando la somma
	dei valori alla frequenza maggiore, i valori di inizio
	periodo, di fine periodo, o di <quote>spalmare</quote> i
	valori ad alta frequenza su più serie (una per
	sottoperiodo). Il comportamento predefinito consiste nel
	prendere la media dei valori sul periodo.
   </para>
   <para>
	Nel caso di compattamento da frequenza giornaliera a
	settimanale, due opzioni aggiuntive sono disponibili,
	<opt>repday</opt> e <opt>weekstart</opt>. La prima permette di
	fissare il valore settimanale sulla base di un <quote>giorno
	rappresentativo</quote> della settimana. Il parametro
	dell'opzione deve essere un numero intero da 0 (Domenica) a 6
	(Sabato). Ad esempio, <opt>--repday=3</opt> fissa il valore
	dell'intera settimana a quello di Mercoledì. Nel caso in cui
	<opt>repday</opt> sia omesso, è necessario indicare quale sia
	il primo giorno della settimana, per allineare correttamente i
	dati.  Per dati giornalieri di 5 o 6 giorni, questo è sempre
	Lunedì; con il formato da 7 giorni è possibile invece
	scegliere tra Domenica (<opt>weekstart=0</opt>) e Lunedì
	(<opt>weekstart=1</opt>), con il secondo come default.
      </para>
      <para>
	<lit>expand</lit>: Questo comando è disponibile solo per serie
	storiche annuali o trimestrali. I dati annuali vengono
	<quote>espansi</quote> a trimestrali, quelli trimestrali a
	mensili.  L'operazione si applica a tutte le serie nel
	dataset, ripetendo il valore a bassa frequenza. Se il dataset
	originale è annuale, l'espansione di default è trimestrale,
	anche se si può far seguire <lit>expand</lit> dal numero
	<lit>12</lit> per effettuare l'espansione mensile.  Consultare
	la funzione <fncref targ="tdisagg"/> per le metodologie più
	avanzate di conversione dati ad alta frequenza.
      </para>
      <para>
	<lit>transpose</lit>: non richiede parametri
	aggiuntivi. Traspone il dataset attuale: ogni osservazione
	(riga) del dataset attuale diventerà una variabile (colonna),
	e ogni variabile un'osservazione. Questo comando è utile
	quando si importano da fonti esterne dei dati organizzati con
	le variabili disposte per riga.
	</para>
	<para>
	  <lit>sortby</lit>: richiede il nome di una variabile o di
	  una lista. Nel primo caso la variabile scelta viene usata
	  come criterio di ordinamento. Le osservazioni di tutte le
	  altre variabili del dataset sono riordinate secondo valori
	  crescenti della variabile indicata. Nel secondo caso
	  (lista), invece, il comando procede gerarchicamente: il
	  primo criterio di ordinamento è la prima variabile, nel caso
	  in cui si arrivi ad una situazione di stallo si passa alla
	  seconda variabile della lista per risolvere il problema, e
	  se il problema persiste si passa alla terza e così via,
	  finché lo stallo non si esaurisce o si esauriscono le
	  variabili presenti nella lista.  Questo comando è
	  disponibile solo per dataset non datati.
	</para>
	<para>
	  <lit>dsortby</lit>: funziona come <lit>sortby</lit> ma riordina le
	  osservazioni secondo i valori decrescenti della variabile specificata.
	</para>
	<para>
	  <lit>resample</lit>: costruisce un nuovo dataset attraverso
	  un campionamento causale, con reimmissione, delle righe del
	  dataset attuale. È richiesto un argomento, ossia il numero
	  di righe da includere, che può essere minore, uguale o
	  maggiore del numero di osservazioni dei dati originali. Il
	  dataset originale può essere recuperato usando il comando
	  <lit>smpl full</lit>.
      </para>
      <para>
	<lit>renumber</lit>: Richiede il nome di una variabile
	esistente seguito da un intero compreso fra 1 e il numero
	delle variabili nel campione meno 1. Sposta la serie
	specificata nel dataset nella posizione indicata, rinumerando
	le altre variabili di conseguenza.  (La posizione 0 è occupata
	dalla costante che non può essere spostata.)
    </para>
    <para>
	<lit>pad-daily</lit>: valido solamente se il dataset corrente
	contiene dei dati giornalieri di un calendario
	incompleto. L'effetto prodotto dal comando sarà quello di
	riempire il calendario aggiungendo le date mancanti come righe
	vuote (ossia righe contenenti solamente valori
	<lit>NA</lit>). Quest'opzione richiede un parametro intero,
	ovvero il numero di giorni della settimana (che deve essere un
	numero tra 5, 6 o 7), e deve essere maggiore, o uguale, alle
	frequenze del dataset attuale. Una volta avvenuto con successo
	il completamento, il calendario dei dati risulterà
	<quote>completo</quote> relativamente al valore del parametro
	dato. Ad esempio, se i giorni della settimana sono 5 allora
	tutti i giorni della settimana verranno rappresentati, sia che
	i dati per questi giorni siano disponibili oppure no.
      </para>
      <para>
	<lit>unpad-daily</lit>: opzione valida solo se il dataset
	corrente contiene dati giornalieri. L'opzione produce
	l'inverso di <lit>pad-daily</lit>, ossia: ogni riga in cui
	tutte le osservazioni sono mancanti viene rimossa. Le
	proprietà di serie storiche del dataset sono preservate,
	assieme alle date delle osservazioni individuali.
      </para>
    </description>

    <gui-access>
      <menu-path>/Dati</menu-path>
    </gui-access>
  </command>

  <command name="datasort" section="Dataset" context="gui"
	   label="Ordina i dati">

    <description>
      <para>
        La variabile selezionata viene usata come chiave di ordinamento per
        l'intero dataset. Le osservazioni di tutte le variabili sono riordinate
        secondo valori crescenti della variabile indicata, o secondo valori
        decrescenti, se si usa l'opzione <quote>Decrescente</quote>.
      </para>
    </description>
  </command>

  <command name="dbnomics" section="Utilities" label="dbnomics access" context="gui">
    <description>
      <para>
	Questa finestra di dialogo permette di cercare e scaricare
	serie di dati dal server di dbnomics. Visitando il sito
	<url>https://next.nomics.world/</url> si trovano gli
	identificatori e i codici di interesse. Essi si compongono in
	gruppi di tre, con i termini separati da barre. Ad esempio
      </para>
      <code>
	ECB/IRS/M.IT.L.L40.CI.0000.EUR.N.Z
      </code>
      <para>
	Il primo termine identifica il forntore dei dati,
	<lit>ECB</lit> (la Banca Centrale Europea).  Il secondo
	identifica un dataset, in questo caso <lit>IRS</lit>
	(statistiche sui tassi di interesse) e il terzo identifica una
	serie all'interno del dataset, in questo caso un tasso
	italiano a 10 anni.
      </para>
      <para>
	Una volta inserito un identificativo di serie, cliccando
	<quote>OK</quote> si aprirà una finestra contenente
	informazioni sulla serie. A quel punto, usando i bottoni in
	alto nella finestra si potranno visualizzare i valori della
	serie in forma numerica o grafica, oppure aggiungere la serie
	al dataset corrente (assumendo che la serie sia conformabile
	ad esso).
      </para>
    </description>
  </command>
  
  <command name="delete" section="Dataset" label="Elimina variabili" context="cli">

    <usage>
      <altforms>
        <altform><lit>delete</lit> <repl>varlist</repl></altform>
        <altform><lit>delete</lit> <repl>varname</repl></altform>
	<altform><lit>delete --type=</lit><repl>type-name</repl></altform>
	<altform><lit>delete</lit> <repl>pkgname</repl></altform>
      </altforms>
      <options>
	<option>
          <flag>--db</flag>
          <effect>rimuove dal database aperto</effect>
	</option>
	<option>
	  <flag>--force</flag>
	  <effect>vedi sotto</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Questo comando è uno strumento multi-uso per eliminare
	oggetti. Deve essere usato con cautela: non viene chiesta
	alcuna conferma.
      </para>
      <para>
	Utilizzandolo nella sua prima forma, <repl>varlist</repl> è un
	lista di variabili aventi un nome ed un numero identificativo
	(ID).  Si noti che quando si elimina una serie tutte le
	restanti serie con un ID maggiore della precedente vengono
	rinumerate dopo l'eliminazione di quelle selezionate. Se si
	utilizza l'opzione <opt>db</opt> con questo comando verranno
	eliminate le liste di variabili non dal corrente dataset ma
	dal database di gretl, assumendo che un database sia stato
	aperto e che l'utente abbia il permesso scritto per il file in
	questione. Si veda anche il comando <cmdref targ="open"/>.
      </para>
      <para>
	Nella seconda forma, il nome di uno scalare, matrice, stringa
	o bundle può essere dato al comando per la cancellazione. In
	questo caso l'opzione <opt>db</opt> non è applicabile. Si noti
	che serie e variabili di tipo diverso non dovrebbero essere
	mixate all'interno della chiamata <lit>delete</lit>.
      </para>
      <para>
	Nella terza forma l'opzione <opt>type</opt> deve essere
	accompagnata da uno dei seguenti
	qualificatori:<lit>matrix</lit>, <lit>bundle</lit>,
	<lit>string</lit>, <lit>list</lit>, <lit>scalar</lit> o
	<lit>array</lit>.  L'effetto è quello di eliminare tutte le
	variabili di un certo tipo. In questo caso nessun altro
	argomento è richiesto oltre l'opzione successiva richiesta.
      </para>
      <para>
	La quarta forma può essere utilizzata per rimuovere un
	pacchetto di funzioni. In questo caso il suffisso
	<lit>.gfn</lit> deve essere fornito, come ad esempio
      </para>
      <code>
	delete somepkg.gfn
      </code>
      <para>
	Si noti che non elimina il pacchetto, quanto piuttosto lo
	deselezione e lo rimuove dalla memoria.
      </para>

      <subhead>Cancellazione di variabili in un loop</subhead>
      <para>
	In generale, non è permesso cancellare variabili durante un
	loop, poiché questo può mettere a repentaglio l'integrità del
	codice. Ciononostante, se siete sicuri che l'operazione è
	senza rischi, questa proibizione può essere disattivata usando
	l'opzione <opt>force</opt>.
      </para>
    </description>

    <gui-access>
      <menu-path>Pop-up nella finestra principale (selezione singola)</menu-path>
    </gui-access>

  </command>

  <command name="density" section="Statistics" context="gui"
	   label="Stima kernel di densità">

    <description>

      <para>
	La stima kernel di densità avviene definendo un insieme di
	punti di riferimento distanziati in modo uniforme su un
	appropriato intervallo dei dati, e attribuendo ad ognuno di
	essi un valore di densità basato sui valori delle osservazioni
	circostanti.
      </para>
      <para>
	È possibile usare un kernel Gaussiano (la densità normale
	standard) o il kernel di Epanechnikov, mentre la larghezza di
	banda predefinita è quella suggerita da <cite
	key="silverman96">Silverman (1986)</cite>. È possibile
	allargare o restringere la banda usando il <quote>fattore di
	aggiustamento della banda</quote>: la banda effettivamente
	utilizzata si ottiene moltiplicando il valore di Silverman per
	il fattore di aggiustamento.
      </para>
      <para>
	Per una buona discussione introduttiva della stima kernel, si
	veda il capitolo 15 di <book>Econometric Theory and
	Methods</book> di Davidson e MacKinnon.
      </para>

    </description>

  </command>

  <command name="dfgls" section="Tests" context="gui"
	   label="Il test ADF-GLS">

    <description>
      <para>
	Il test ADF-GLS è una variante del test Dickey&ndash;Fuller per
	radici unitarie, per il caso in cui la variabile da testare ha
	media diversa da zero o esibisce un trend lineare. La
	differenza consiste nel fatto che la rimozione della media o
	del trend è eseguita secondo la procedura suggerita da <cite
	key="ERS96">Elliott, Rothenberg e Stock (1996)</cite>.  Questa
	produce un test di potenza maggiore rispetto a quello
	dell'approccio standard di Dickey&ndash;Fuller.
      </para>
      <para>
	Quando si testa per un dato ordine massimo di ritardo i
	criteri AIC e BIC sono <quote>modificati</quote> come
	descritto in <cite key="ng-perron01">Ng e Perron
	(2001)</cite>, con o senza la modifica proposta da <cite
	key="perron-qu07">Perron e Qu (2007)</cite>.  La modifica in
	questione riguarda l'utilizzo dei dati OLS detrended durante
	la fase di determinazione dell'ordine di ritardo massimo,
	seguito da un GLS-detrending nella fase conclusiva del test.
      </para>
      <para>
	Si veda anche l'opzione <opt>gls</opt> del comando <cmdref
	targ="adf"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variable/ADF-GLS test</menu-path>
    </gui-access>

  </command>

  <command name="dialog" section="Estimation" context="gui"
	   label="Finestra di dialogo Modello">

    <description>
      <para>
	Per selezionare la variabile dipendente, fare clic su una
	variabile nella lista di sinistra e premere il pulsante
	<quote>Scegli</quote> con la freccia che punta verso il
	riquadro della variabile dipendente.  Selezionando la casella
	<quote>Imposta come predefinito</quote>, la variabile scelta
	verrà sempre pre-selezionata come variabile dipendente durante
	le prossime aperture della finestra di dialogo.  Trucco:
	facendo doppio clic su una variabile sulla sinistra, viene
	selezionata come variabile dipendente e impostata come scelta
	predefinita.
      </para>
      <para>
	Per selezionare le variabili indipendenti, fare clic su di
	esse nella lista di sinistra e premere il pulsante
	<quote>Aggiungi</quote> (o fare clic col pulsante destro del
	mouse). È possibile selezionare più variabili contigue
	trascinando il mouse; se le variabili da selezionare non sono
	contigue, occorre fare clic tenendo premuto il tasto
	<lit>Ctrl</lit>.
      </para>
    </description>

  </command>

  <command name="diff" section="Transformations" label="Differenze prime" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <examples>
	<demos>
	  <demo>penngrow.inp</demo>
	  <demo>sw_ch12.inp</demo>
	  <demo>sw_ch14.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Calcola la differenza prima di ogni variabile nella
	<repl>lista-variabili</repl> e la salva in una nuova variabile
	il cui nome è prefissato con <lit>d_</lit>.  Quindi <cmd>diff
	x y</cmd> crea le nuove variabili
      </para>
      <code>
	d_x = x(t) - x(t-1)
        d_y = y(t) - y(t-1)
      </code>
    </description>

    <gui-access>
      <menu-path>/Aggiungi/Differenze prime delle variabili selezionate</menu-path>
    </gui-access>

  </command>

  <command name="difftest" section="Tests"
	   label="Test non parametrici per le differenze" context="cli">

    <usage>
      <arguments>
        <argument>var1</argument>
	<argument>var2</argument>
      </arguments>
      <options>
	<option>
	  <flag>--sign</flag>
	  <effect>Test del segno, scelta predefinita</effect>
	</option>
	<option>
	  <flag>--rank-sum</flag>
	  <effect>Test "rank-sum" di Wilcoxon</effect>
	</option>
	<option>
	  <flag>--signed-rank</flag>
	  <effect>Test "signed-rank" di Wilcoxon</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>Mostra informazioni aggiuntive</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>Non stampa l'output</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>ooballot.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
        Esegue un test non parametrico per la differenza tra due popolazioni o
        gruppi; il tipo di test dipende dall'opzione usata.
      </para>
      <para>
	Con l'opzione <opt>sign</opt>, viene eseguito il test del segno,
        che si basa sul fatto che per due campioni
	<math>x</math> e <math>y</math> estratti casualmente dalla
        stessa distribuzione, la probabilità che valga
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub> per ogni osservazione
	<math>i</math> dovrebbe valere 0.5. La statistica test è
	<math>w</math>, ossia il numero di osservazioni per cui vale
	<math>x</math><sub>i</sub> &gt;
	<math>y</math><sub>i</sub>. Sotto l'ipotesi nulla, questa
        grandezza si distribuisce come una binomiale con parametri
	(<math>n</math>, 0.5), dove <math>n</math> è il numero di
        osservazioni.
      </para>
      <para>
	Con l'opzione <opt>rank-sum</opt>, viene eseguito il test
	"rank-sum" di Wilcoxon. Questo test procede ordinando le
	osservazioni estratte da entrambi i campioni dalla più piccola
	alla più grande, e quindi calcolando la somma dei ranghi delle
	osservazioni da uno dei campioni. I due campioni non devono
	necessariamente avere la stessa dimensione: se sono diversi,
	viene usato il campione più piccolo per calcolare la somma dei
	ranghi. Sotto l'ipotesi nulla che i campioni siano estratti da
	popolazioni con la stessa mediana, la distribuzione di
	probabilità della somma dei ranghi può essere calcolata per
	ogni valore dell'ampiezza dei due campioni, mentre per
	campioni abbastanza ampi essa approssima la distribuzione
	normale.
      </para>
      <para>
	Con l'opzione <opt>signed-rank</opt>, viene eseguito il test
        "signed-rank" di Wilcoxon. Questo test è valido per "coppie di
        campioni", come possono essere ad esempio i valori di una variabile in
        un gruppo di individui prima e dopo un certo trattamento. Il test
        procede calcolando le differenze tra le coppie di osservazioni
	<math>x</math><sub>i</sub> &minus;
	<math>y</math><sub>i</sub>, ordinando queste differenze per valore
        assoluto e assegnando ad ogni coppia un valore di rango con segno, in
        cui il segno rispecchia il segno della differenza. Quindi viene
        calcolato <math>W</math><sub>+</sub>, la somma di tutti i ranghi
        con segno positivo. Come avviene per il test rank-sum, questa
        statistica ha una distribuzione precisa nell'ipotesi nulla che la
        differenza mediana sia zero, distribuzione che converte alla normale nel
        caso di campioni abbastanza ampi.
      </para>
      <para>
        Usando l'opzione <opt>verbose</opt> con i test di Wilcoxon viene
        mostrato l'ordinamento delle osservazioni (l'opzione non ha effetto se
        usata con il test del segno).
      </para>
      <para>
	Se il comando non ha dato errori, sono disponibili gli
	accessori <fncref targ="$test"/> e <fncref
	targ="$pvalue"/>. Per ottenere solo questi valori, si può
	usare l'opzione <opt>quiet</opt>.
      </para>
    </description>

  </command>

  <command name="discrete" section="Transformations"
	   label="Marca variabili discrete" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--reverse</flag>
	  <effect>marca le variabili come continue</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>ooballot.inp</demo>
	  <demo>oprobit.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
        Marca ogni variabile della <repl>lista-variabili</repl> come discreta.
        In modalità predefinita, tutte le variabili sono considerate come
        continue; marcando una variabile come discreta, essa viene trattata in
        modo speciale nei diagrammi di frequenza, e può esere usata con il
        comando <cmdref targ="dummify"/>.
      </para>
      <para>
        Usando l'opzione <opt>reverse</opt>, l'operazione viene invertita,
        ossia, le variabili nella <repl>lista-variabili</repl> sono marcate come
        continue.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Modifica attributi</menu-path>
    </gui-access>

  </command>

  <command name="dpanel" section="Estimation" label="Modelli panel dinamici">

    <usage>
      <arguments>
	<argument>p</argument>
	<argblock separated="true">
	  <argument>depvar</argument>
	  <argument>indepvars</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>instruments</argument>
	</argblock>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra il modello stimato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
        <option>
	  <flag>--two-step</flag>
	  <effect>calcola la stima GMM a due passi</effect>
        </option>
        <option>
	  <flag>--system</flag>
	  <effect>aggiunge equazioni nei livelli</effect>
        </option>
        <option>
	  <flag>--time-dummies</flag>
	  <effect>aggiunge variabili dummy temporali</effect>
        </option>
        <option>
	  <flag>--dpdstyle</flag>
	  <effect>emula il pacchetto DPD per Ox</effect>
        </option>
        <option>
	  <flag>--asymptotic</flag>
	  <effect>errori standard asintotici non modificati</effect>
        </option>
        <option>
          <flag>--keep-extra</flag>
          <effect>vedi sotto</effect>
        </option>
      </options>
      <examples>
        <example>dpanel 2 ; y x1 x2</example>
	<example>dpanel 2 ; y x1 x2 --system</example>
        <example>dpanel {2 3} ; y x1 x2 ; x1</example>
	<example>dpanel 1 ; y x1 x2 ; x1 GMM(x2,2,3)</example>
	<demos>
	  <demo>bbond98.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Stima modelli dinamici per dati di panel (in altre parole,
	modelli panel con uno o più ritardi della variabile dipendente)
	usando il metodo GMM-DIF o quello GMM-SYS.
      </para>
      <para context="cli">
	Il paramtro <repl>p</repl> rappresenta l'ordine autoregressivo
	della variabile dipendente. Nel caso più semplice si tratta di
	uno scalare, ma per specificare un insieme di ritardi (non
	consecutivi) da è possibile indicare una matrice definita
	in precedenza.
      </para>
      <para>
	La variabile dipendente e i regressori dovrebbero essere indicati
	in livelli; il comando provvede autonomamente a differenziarli
	(dato che questo stimatore usa le differenze per eliminare
	gli effetti individuali).
      </para>
      <para context="cli">
	L'ultimo campo (opzionale) nel comando serve a specificare gli
	strumenti.  Se questi ultimi non vengono indicati si assume
	che le variabili indipendenti siano tutte strettamente
	esogene. Se si sceglie di specificare alcuni strumenti è
	opportuno includere nell'elenco anche le variabili
	indipendenti strettamente esogene. Nel caso di regressori
	predeterminati è possibile usare la funzione <lit>GMM</lit>
	per includere uno specifico intervallo di ritardi seguendo uno
	schema diagonale a blocchi. Una situazione di questo tipo è
	stata illustrata in precedenza nel terzo esempio. Il primo
	argomento di <lit>GMM</lit> è il nome della variabile in
	questione, il secondo è il ritardo minimo da usare come
	strumento e il terzo è il ritardo massimo.  La stessa sintassi
	può essere utilizzata con la funzione <lit>GMMlevel</lit> per
	specificare strumenti di tipo GMM per le equazioni nei
	livelli.
      </para>
      <para context="gui">
	Per quanto riguarda la gestione degli strumenti, si consulti
	la documentazione di questo comando in modalità
	scripting. Attualmente non è possibile specificare
	esplicitamente degli strumenti nella GUI: tutte le variabili
	indipendenti sono considerate strettamente esogene.
      </para>
      <para>
	Di default vengono riportati (con errori standard robusti) i
	risultati della stima al primo stadio; la stima al secondo
	stadio può essere richiesta indicato l'opzione
	corrispondente. In entrambi i casi vengono forniti i test di
	autocorrelazione del primo e del secondo ordine, così come il
	test di sovraidentificazione di Sargan e un test di Wald della
	significatività congiunta dei regressori. Si noti che in
	questo modello nelle differenze l'autocorrelazione del primo
	ordine non impedisce che il modello sia valido;
	l'autocorrelazione al secondo ordine, tuttavia, viola le
	ipotesi statistiche che ne sono alla base.
      </para>
      <para context="cli">
	Nel caso della stima a due passi, gli errori standard sono per
	default calcolati usando la correzione per campioni finiti
	suggerita da <cite key="windmeijer05">Windmeijer
	(2005)</cite>. In generale l'inferenza basata sugli errori
	standard asintotici associati allo stimatore al secondo stadio
	è considerata inaffidabile, ma se per qualche ragione
	desiderate conoscere il loro valore potete usare l'opzione
	<opt>asymptotic</opt> per disattivare la correzione di
	Windmeijer.
      </para>
      <para context="cli">
	Se viene indicata l'opzione <opt>time-dummies</opt> il
	comando aggiunge ai regressori specificati un insieme di
	variabili dummy.  Il numero di queste ultime è pari al numero
	massimo di periodi usati nella stima meno uno, allo scopo di
	evitare di avere collinearità perfetta con la costante.  Le
	dummy vengono incluse in differenza, a meno che non sia
	indicata l'opzione <opt>dpdstyle</opt>; in questo caso le
	dummy sono incluse in livello.
      </para>
      <para context="cli">
	Come per altri comandi di stima, un bundle di nome <fncref
	targ="$model"/> è disponibile se il comando va a buon fine. Nel
	caso del comando <lit>dpanel</lit>, l'opzione
	<opt>keep-extra</opt> provoca l'inclusione nel bundle di
	elementi addizionali, e cioè i pesi GMM e la matrice degli
	strumenti.
      </para>
      <para>
	Per ulteriori dettagli ed esempi, si veda <guideref
	targ="chap:dpanel"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Model/Panel/Dynamic panel model</menu-path>
    </gui-access>

  </command>

  <command name="dummify" section="Transformations" context="gui"
	   label="Create sets of dummies">

    <description>
      <para>
	L'operazione <quote>dummify</quote> è disponibile solo per
	variabili discrete. Ha l'effetto di creare un insieme di
	variabili dummy (binarie) per ognuno dei valori presenti nella
	variabile.
      </para>
      <para>
	Come esempio, si immagini di avere una variabile chiamata
	<lit>statociv</lit>, con valori 1 per
	<quote>celibe/nubile</quote>, 2 per <quote>coniugato</quote>,
	3 per <quote>separato/divorziato</quote> e 4 per
	<quote>vedovo</quote>. L'operazione di cui stiamo parlando
	creerebbe 4 variabili binarie: la prima avrebbe valore 1 per
	chi non si è mai sposato e zero per gli altri; la seconda
	avrebbe valore 1 per chi è sposato e zero per gli altri, e
	così via.
      </para>
      <para>
	Nella pratica, per una serie discreta con <math>k</math>
	categorie di solito il numero di dummy che vengono create è
	<math>k</math> &minus; 1, per evitare la cosiddetta
	<quote>trappola delle dummy</quote>. Di conseguenza, vi
	offriamo l'opzione di saltare il valore più alto o quello più
	basso della codifica.
      </para>
    </description>

  </command>

  <command name="dummify" section="Transformations"
	   label="Crea variabili dummy" context="cli">

    <usage>
      <arguments>
        <argument>lista-variabili</argument>
      </arguments>
      <options>
	<option>
	  <flag>--drop-first</flag>
	  <effect>omette dalla codifica il valore minimo</effect>
	</option>
	<option>
	  <flag>--drop-last</flag>
	  <effect>omette dalla codifica il valore massimo</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Per ogni variabile rilevante nella
	<repl>lista-variabili</repl>, crea un insieme di variabili
	dummy che codificano i valori distinti di quella variabile. Le
	variabili rilevanti sono quelle che sono state marcate
	esplicitamente come discrete, o quelle che assumono un numero
	limitato di valori che devono essere <quote>abbastanza
	arrotondati</quote> (multipli di 0.25).
      </para>
      <para>
	Per impostazione predefinita, viene aggiunta una variabile
	dummy per ognuno dei valori distinti della variabile in
	questione.  Ad esempio, se una variabile discreta <lit>x</lit>
	ha 5 valori distinti, verranno create 5 variabili dummy, di
	nome <lit>Dx_1</lit>, <lit>Dx_2</lit> e così via. La prima
	variabile dummy avrà valore 1 per le osservazioni in cui
	<lit>x</lit> assume il suo valore minimo, e 0 altrove; la
	successiva variabile dummy avrà valore 1 dove <lit>x</lit>
	assume il secondo tra i suoi valori, e così via. Se viene
	usata una delle opzioni <opt>drop-first</opt> o
	<opt>drop-last</opt>, il più basso o il più alto dei valori
	della variabile viene omesso dalla codifica (questa funzione
	può essere utile per evitare la cosiddetta <quote>trappola
	delle variabili dummy</quote>).
      </para>
      <para>
       Esiste anche una funzione corrispondente a questo comando, e
       cioè <fncref targ="dummify"/>. Con tale funzione è possibile
       creare delle dummy direttamente nel contesto di una
       regressione.  Ad esempio, la riga seguente specifica un modello
       in cui <lit>y</lit> viene regredita sull'insieme di variabili
       dummy che codificano <lit>x</lit> (in questo contesto non è
       possibile passare opzioni al comando <cmd>dummify</cmd>).
      </para>
      <code>
	ols y dummify(x)
      </code>
    </description>

  </command>

  <command name="duration" section="Estimation" label="Duration models"
	   context="cli">
    <usage>
      <arguments>
        <argument>depvar</argument>
        <argument>indepvars</argument>
        <argument separated="true" optional="true">censvar</argument>
      </arguments>
      <options>
        <option>
          <flag>--exponential</flag>
          <effect>usa la distribuzione esponenziale</effect>
        </option>
        <option>
          <flag>--loglogistic</flag>
          <effect>usa la distribuzione log-logistica</effect>
        </option>
        <option>
          <flag>--lognormal</flag>
          <effect>usa la distribuzione log-normale</effect>
        </option>
        <option>
          <flag>--medians</flag>
          <effect>i valori previsti sono mediane</effect>
        </option>
        <option>
          <flag>--robust</flag>
          <effect>errori standard robusti (QML)</effect>
        </option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>v. <cmdref targ="logit"/> per una spiegazione</effect>
        </option>
        <option>
          <flag>--vcv</flag>
          <effect>mostra la matrice di covarianza</effect>
        </option>
        <option>
          <flag>--verbose</flag>
          <effect>mostra dettagli delle iterazioni</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra nulla</effect>
        </option>
      </options>
      <examples>
        <example>duration y 0 x1 x2</example>
	<example>duration y 0 x1 x2 ; cens</example>
	<demos>
	  <demo>weibull.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Stima un modello di durata: la variabile dipendente (che deve essere
	positiva) rappresenta la durata di un certo fenomeno, per esempio
	la lunghezza di un periodo di disoccupazione per una cross-section
	di intervistati. Di default viene utilizzata una distribuzione Weibull,
	ma sono disponibili anche le distribuzioni esponenziale, log-logistica
	e log-normale.
      </para>
      <para>
	Se alcune delle durate misurate sono censurate a destra (&eg;
	il periodo di disoccupazione di un individuo non si è concluso
	all'interno del periodo di osservazione), deve essere
	specificato l'argomento accessorio <repl>censvar</repl> che
	indica una variabile i cui valori positivi segnalano
	osservazioni censurate a destra.
      </para>
      <para>
	Di default i valori stimati ottenuti mediante l'accessore
	<fncref targ="$yhat"/> rappresentano le medie condizionali delle
	durate; se tuttavia viene indicata l'opzione
	<opt>medians</opt>, <fncref targ="$yhat"/> fornisce le mediane
	condizionali.
      </para>
      <para>
	Vedi <guideref targ="chap:probit"/> per ulteriori dettagli.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Variabile dipendente limitata/Dati di durata</menu-path>
    </gui-access>

  </command>

  <command name="elif" section="Programming" label="Strutture di controllo" context="cli">

    <description><para>Si veda <cmdref targ="if"/>.</para>
    </description>

  </command>

  <command name="else" section="Programming" label="Strutture di controllo" context="cli">

    <description>
      <para>
	Si veda <cmdref targ="if"/>. Si noti che <cmd>else</cmd>
	dev'essere su un linea a sé stante, prima del comando
	corrispondente. Si può aggiungere un commento, come ad esempio
      </para>
      <code>
	else # OK, fa' un'altra cosa
      </code>
      <para>
	ma non si può aggiungere un comando, come in
      </para>
      <code>
	else x = 5 # wrong!
      </code>
    </description>

  </command>

  <command name="ema-filter" section="Transformations" context="gui"
	   label="Exponential Moving Average">

    <description>
      <para>
	La formula per la media mobile esponenziale (EMA) usata in
	gretl è tratta da <cite key="roberts59">Roberts
	(1959)</cite>, ossia
      </para>
      <para>
	<math>s</math><sub>t</sub> =
	&agr;<math>y</math><sub>t</sub> +
        (1&minus;&agr;)<math>s</math><sub>t&minus;1</sub>
      </para>
      <para>
	dove <math>s</math> è la EMA, <math>y</math> è la serie
	originale, e &agr; è una costante fra 0 e 1. Valori più grandi
	di &agr; danno più peso all'osservazione attuale; valori più
	piccoli provocano un risultato più <quote>liscio</quote>.
      </para>
      <para>
	Il <quote>valore EMA iniziale</quote>, comunque sia
	specificato, è dato dal più recente valore antecedente
	all'inizio del campione, ciò che implica che il calcolo del
	filtro comincia con la prima osservazione del campione
	attuale.
      </para>
      <para>
	Per la funzionalità equivalente a linea di comando, si veda la
	funzione <fncref targ="movavg"/>.
      </para>
    </description>

  </command>

  <command name="end" section="Programming"
	   label="Chiude un blocco di comandi" context="cli">
    <description>
      <para>
	Termina un blocco di comandi di qualsiasi tipo.  Ad esempio,
	<cmd>end system</cmd> termina un <cmdref targ="system"/>
	(sistema di equazioni).
      </para>
    </description>
  </command>

  <command name="endif" section="Programming" label="Strutture di controllo" context="cli">

    <description><para>Si veda <cmdref targ="if"/>.</para>
    </description>
  </command>

  <command name="endloop" section="Programming" label="Chiude un ciclo di comandi" context="cli">
    <description>
      <para>
	Indica la fine di un ciclo (loop) di comandi.  Si veda <cmdref targ="loop"/>.
      </para>
    </description>

  </command>

  <command name="eqnprint" section="Printing" label="Stampa un modello come equazione" context="cli">

    <usage>
      <options>
        <option>
	  <flag>--complete</flag>
	  <effect>crea un documento completo</effect>
        </option>
        <option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>indirizza l'output ad uno specifico file</effect>
        </option>
      </options>
    </usage>

    <description>
      <para>
	Va eseguito dopo la stima di un modello. Stampa il modello
	stimato sotto forma di equazione &latex;. Se viene specificato
	un nome di file usando l'opzione <opt>output</opt>, il
	risultato viene scritto in quel file, altrimenti viene scritto
	in un file il cui nome ha la forma
	<filename>equation_N.tex</filename>, dove <lit>N</lit> è il
	numero di modelli stimati finora nella sessione in corso. Si
	veda anche <cmdref targ="tabprint"/>.
      </para>
      <para>
	Il file di output verrà scritto nella directory correntamente
	impostata <cmdref targ="workdir"/>, a meno che la stringa
	<repl>filename</repl> contenga il percorso specifico completo.
      </para>
      <para>
	Usando l'opzione <opt>complete</opt>, il file &latex; è un
        documento completo, pronto per essere processato; altrimenti il
        file va incluso in un documento.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /LaTeX</menu-path>
    </gui-access>

  </command>

  <command name="equation" section="Estimation"
	   label="Definisce un'equazione in un sistema" context="cli">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
      </arguments>
      <examples>
        <example>equation y x1 x2 x3 const</example>
      </examples>
    </usage>

    <description>
      <para>
	Specifica un'equazione all'interno di un sistema di equazioni
	(si veda <cmdref targ="system"/>). La sintassi per specificare
	un'equazione in un sistema SUR è la stessa usata ad esempio in
	<cmdref targ="ols"/>. Per un'equazione in un sistema con
	minimi quadrati a tre stadi, invece è possibile usare una
	specificazione simile a quella usata per OLS e indicare una
	lista di strumenti comuni usando l'istruzione <cmd>instr</cmd>
	(si veda ancora <cmdref targ="system"/>), oppure si può usare
	la stessa sintassi di <cmdref targ="tsls"/>.
      </para>
    </description>

  </command>

  <command name="estimate" section="Estimation"
	   label="Stima sistemi di equazioni" context="cli">

    <usage>
      <arguments>
        <argument optional="true">nome-sistema</argument>
	<argument optional="true">stimatore</argument>
      </arguments>
      <options>
	<option>
          <flag>--iterate</flag>
          <effect>itera fino alla convergenza</effect>
	</option>
	<option>
          <flag>--no-df-corr</flag>
          <effect>nessuna correzione per i gradi di libertà</effect>
	</option>
	<option>
          <flag>--geomean</flag>
          <effect>si veda oltre</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>mostra i dettagli delle iterazioni</effect>
	</option>
      </options>
      <examples>
        <example>estimate "Klein Model 1" method=fiml</example>
	<example>estimate Sys1 method=sur</example>
        <example>estimate Sys1 method=sur --iterate</example>
      </examples>
    </usage>

    <description>
      <para>
	Esegue la stima di un sistema di equazioni, che deve essere
	stato definito in precedenza usando il comando <cmdref
	targ="system"/>.  Per prima cosa va indicato il nome del
	sistema, racchiuso tra virgolette se contiene spazi, quindi il
	tipo di stimatore, preceduto dalla stringa
	<lit>method=</lit>. Gli stimatori disponibili sono:
	<cmd>ols</cmd>, <cmd>tsls</cmd>, <cmd>sur</cmd>,
	<cmd>3sls</cmd>, <cmd>fiml</cmd> o <cmd>liml</cmd>. Questi
	argomento sono opzionali si il sistema in questione è già
	stato stimato e occupa il posto dell'<quote>ultimo
	modello</quote>; in tal caso, per default viene usato il
	metodo di stima precedente.
      </para>
      <para>
	Se al sistema in questione sono stati imposti dei vincoli (si veda
	il comando <cmdref targ="restrict"/>), la stima sarà soggetta a tali
	vincoli.
      </para>
      <para>
	Se il metodo di stima è <cmd>sur</cmd> o <cmd>3sls</cmd>
	e viene usata l'opzione <opt>iterate</opt>, lo stimatore verrà
	iterato. Nel caso di SUR, se la procedura converge, i risultati
	saranno stime di massima verosimiglianza. Invece l'iterazione della
	procedura dei minimi quadrati a tre stadi non produce in genere
	risultati di massima verosimiglianza a informazione completa.
	L'opzione <opt>iterate</opt> viene ignorata con gli altri metodi di
	stima.
      </para>
      <para>
	Se vengono scelti gli stimatori "equazione per equazione"
	<cmd>ols</cmd> o <cmd>tsls</cmd>, nel calcolo degli errori
	standard viene applicata in modo predefinito una correzione
	per i gradi di libertà, che può essere disabilitata usando
	l'opzione <opt>no-df-corr</opt>. Questa opzione non ha effetti
	nel caso vengano usati altri stimatori, che non prevedono
	correzioni per i gradi di libertà.
      </para>
      <para>
	La formula usata in modo predefinito per calcolare gli
	elementi della matrice di covarianza tra equazioni è
	<equation status="display"
		  tex="\[\hat{\sigma}_{i,j}=\frac{\hat{u}_i' \hat{u}_j}{T}\]"
		  ascii="sigma(i,j) = u(i)' * u(j) / T"
		  graphic="syssigma1"/>
	Se viene usata l'opzione <opt>geomean</opt>, viene applicata
	una correzione per i gradi di libertà secondo la formula
	<equation status="display"
		  tex="\[\hat{\sigma}_{i,j}=\frac{\hat{u}_i' \hat{u}_j}{\sqrt{(T-k_i)(T-k_j)}}\]"
		  ascii="sigma(i,j) = u(i)' * u(j) / sqrt((T - ki) * (T - kj))"
		  graphic="syssigma2"/>
	dove i <math>k</math> indicano il numero di parametri
	indipendenti in ogni equazione.
      </para>
      <para>
        Se si usa l'opzione <opt>verbose</opt> e un metodo iterativo, vengono
        mostrati i dettagli delle iterazioni.
      </para>
    </description>

  </command>

  <command name="eval" section="Utilities" context="cli">
    <usage>
      <arguments>
        <argument>espressione</argument>
      </arguments>
      <examples>
        <example>eval x</example>
	<example>eval inv(X'X)</example>
	<example>eval sqrt($pi)</example>
      </examples>
    </usage>
    <description>
      <para>
	Con questo comando, gretl diventa una specie di grande
	calcolatrice. Il programma valuta l'<repl>espressione</repl> e
	stampa il risultato. L'argomento può essere il nome di una
	variabile, o qualcosa di più complicato. In ogni caso,
	dev'essere un'espressione ammissibile a destra dell'operatore
	di assegnamento.
      </para>
      <para>
	Si noti che un comando del tipo
      </para>
      <code>
	print x^2
      </code>
      <para>
	non funziona in gretl, poiché <lit>x^2</lit> non è (né può essere)
	il nome di una variabile, ma (data una variabile scalare di nome
	<lit>x</lit>)
      </para>
      <code>
	eval x^2
      </code>
      <para>
	funzionerà tranquillamente, e mostrerà il quadrato di <lit>x</lit>.
      </para>
      <para>
	Vedi anche <cmdref targ="printf"/>, per il caso in cui si
	voglia combinare testo e output numerici.
      </para>

    </description>
  </command>

  <command name="expand" section="Dataset" context="gui"
	   label="Espansione dei dati">

    <description>
      <para>
        L'operazione di espansione dei dati è riservata gli utenti
        <quote>esperti</quote>: occorre sapere bene cosa si sta
        facendo. Quando si combinano serie di frequenza diversa nello
        stesso dataset, di solito è più consigliabile compattare i
        dati ad alta frequenza piuttosto che espandere quelli a bassa
        frequenza
      </para>
      <para>
	Ciò premesso, gretl può espandere una serie ripetendo il
	valore a bassa frequuenza per il numero necessario di
	volte. Si consideri la conversione da trimestrale a mensile fa
	sì che il valore del trimestre venga ripetuto in tutti e tre i
	mesi. È improbabile che la seri risultante sia di una qualche
	utilità, ma dopo l'espansione si può usare la funzione <fncref
	targ="tdisagg"/> per produrre una versione dei dati interpolata
	o distribuita.
      </para>
      <para>
	Alcune funzionalità di <lit>tdisagg</lit> sono accessibili
	attraverso l'interfaccia grafica: basta selezionare la serie
	candidata nella finestra principale e scegliere la voce
	<quote>Disaggregazione</quote> sotto il menu
	<quote>Variabile</quote>.
      </para>
    </description>
  </command>

  <command name="export" section="Dataset" context="gui"
	   label="Esportazione dei dati">

    <description>
      <para>
	È possibile esportare dati in formato separato da virgole
	(CSV: Comma-Separated Values), in modo che possano essere
	aperti con fogli elettronici e molti altri programmi
	applicativi. Selezionando questa opzione, sarà possibile
	scegliere diverse caratteristiche del file CSV.
      </para>
      <para>
	E' anche possibile esportare dati sotto forma di file di dati
	<quote>native</quote> di gretl, oppure (se i dati lo rendono possibile)
	esportare un database di gretl. Vedi <url>gretl.sourceforge.net/gretl_data.html</url>
	per una discussione dei database di gretl.
      </para>
      <para>
	E' anche possibile esportare i dati in un formato pronto per essere usato
	dai programmi seguenti:
      </para>
      <ilist>
	<li>
	  <para>
	    GNU R (<url>www.r-project.org</url>): i dati verranno scritti
	    in un formato separato da spazi in maniera che sia facilmente digeribile
	    dalla function <lit>read.table</lit> di R. Il nome di default del file
	    avrà il suffisso <lit>.txt</lit>
	  </para>
	</li>
	<li>
	  <para>
	    GNU octave (<url>www.gnu.org/software/octave</url>): i dati verranno
	    scritti in forma matriciale secondo il formato preferito da Octave.
	    Di default il nome del file avrà come suffisso <lit>.m</lit>
	  </para>
	</li>
	<li>
	  <para>
	    JMulTi (<url>www.jmulti.de</url>): di default il nome del file
	  avrà il suffisso: <lit>.dat</lit></para>
	</li>
	<li>
	  <para>
	    PcGive (<url>www.pcgive.com</url>): di default il nome del file
	  avrà il suffisso: <lit>.dat</lit></para>
	</li>
      </ilist>
      <para>
	Se desiderate esportare i dati copiandoli negli appunti invece di
	scriverli in un file di dati, selezionate le variabili che volete
	copiare nella finestra principale, cliccate sul pulsante destro e
	selezionate <quote>Copia negli appunti</quote>.
	(In questo contesto è supportato solo il formato CSV.)
      </para>

    </description>
  </command>

  <command name="factorized" section="Graphs" context="gui"
	   label="Grafici X-Y con fattore">

    <description>
      <para>
	Questo comando richiede che si selezionino tre variabili,
	l'ultima delle quali deve essere una variabile dummy (con valori
	1 o 0). La variabile Y è rappresentata rispetto alla variabile X,
	con i punti colorati diversamente a seconda del valore della terza
	variabile.
      </para>
      <para>
	Esempio: si hanno dati sui salari e il livello di scolarità
	per un campione di persone; si dispone anche di una variabile
	dummy che vale 1 per gli uomini e 0 per le donne (come nel file
	<filename>data7-2</filename> di Ramanathan).  Un <quote>grafico
	X-Y con fattore</quote> di <lit>WAGE</lit> rispetto a <lit>EDUC</lit>
	usando la dummy <lit>GENDER</lit> mostrerà le osservazioni che si
	riferiscono agli uomini in un colore e quelle delle donne in un altro
	(insieme a una legenda per identificarli).
      </para>
    </description>

  </command>

  <command name="fcast" section="Prediction" label="Genera previsioni">

    <usage>
      <altforms>
	<altform><lit>fcast [</lit><repl>oss-iniziale
	oss-finale</repl><lit>]
	[</lit><repl>nome-variabile</repl><lit>]</lit></altform>
	<altform><lit>fcast [</lit><repl>oss-iniziale
	oss-finale</repl><lit>]
	</lit><repl>passi-avanti</repl><lit>[</lit><repl>nome-variabile</repl><lit>]
	--recursive </lit> </altform>
      </altforms>
      <options>
	<option>
	  <flag>--dynamic</flag>
	  <effect>crea previsioni dinamiche</effect>
	</option>
	<option>
	  <flag>--static</flag>
	  <effect>crea previsioni statiche</effect>
	</option>
	<option>
	  <flag>--out-of-sample</flag>
	  <effect>genera previsioni fuori dal campione</effect>
	</option>
	<option>
	  <flag>--no-stats</flag>
	  <effect>non mostra le statistiche di previsione</effect>
	</option>
	<option>
	  <flag>--stats-only</flag>
	  <effect>stampa solo le statistiche di previsione</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra le previsioni</effect>
	</option>
	<option>
	  <flag>--recursive</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--all-probs</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--plot</flag>
	  <optparm>nome di file</optparm>
	  <effect>vedi sotto</effect>
	</option>
      </options>
      <examples>
	<example>fcast 1997:1 2001:4 f1</example>
	<example>fcast fit2</example>
	<example>fcast 2004:1 2008:3 4 rfcast --recursive</example>
	<demos>
	  <demo>gdp_midas.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="gui">
	Deve seguire un comando di stima.  Calcola previsioni
	per l'intervallo specificato. A seconda del tipo di modello, calcola
	anche gli errori standard (si veda oltre).
      </para>
      <para context="cli">
	Deve seguire un comando di stima.  Calcola previsioni
	per un certo intervallo delle osservazioni. L'intervallo può essere
	specificato indicando <repl>oss-iniziale</repl>
	e <repl>oss-finale</repl>, oppure con l'opzione
	<opt>out-of-sample</opt> (in questo caso la previsione sarà per le
	osservazioni successive a quelle su cui è stato stimato il modello); se
	non si usa alcuna opzione, l'intervallo sarà quello attualmente
	impostato. Se si sceglie una previsione fuori dal campione ma non sono
	disponibili osservazioni, viene segnalato un errore. A seconda del tipo
	di modello, calcola anche gli errori standard (si veda oltre).
	L'opzione <opt>recursive</opt> produce un comportamento speciale
	spiegato oltre.
      </para>
      <para context="cli">
	Se l'ultimo modello stimato consiste in un'equazione singola,
	l'argomento opzionale <repl>nome-variabile</repl> ha l'effetto seguente:
	i valori della previsione non sono mostrati, ma vengono salvati nel
	dataset con il nome di variabile indicato. Se l'ultimo modello stimato è
	un sistema di equazioni, <repl>nome-variabile</repl> ha un effetto
	diverso, ossia seleziona una particolare variabile endogena per cui
	effettuare la previsione (l'impostazione predefinita consiste nel
	produrre previsioni per tutte le variabili endogene). Nel caso del
	sistema, o se non viene specificata <repl>nome-variabile</repl>, i
	valori della previsione possono essere recuperati usando la variabile
	accessoria <fncref targ="$fcast"/>, mentre gli errori standard, se
	disponibili, sono recuperabili con <fncref targ="$fcse"/>.
      </para>
      
      <subhead>Previsioni statiche e dinamiche</subhead>
      <para>
	La scelta tra previsione statica e dinamica è rilevante solo nel caso di
	modelli dinamici, che comprendono un processo di errore autoregressivo,
	o che comprendono uno o più valori ritardati della variabile dipendente
	come regressori. Le previsioni statiche sono per il periodo successivo,
	basate sui valori effettivi nel periodo precedente, mentre quelle
	dinamiche usano la regola della previsione a catena.
	Ad esempio, se la previsione per <math>y</math> nel 2008
	richiede come input il valore di <math>y</math> nel 2007,
	non è possibile calcolare una previsione statica se non si hanno dati
	per il 2007. È possibile calcolare una previsione dinamica per il 2008
	se si dispone di una precedente previsione per
	<math>y</math> nel 2007.
      </para>
      <para>
	La scelta predefinita consiste nel fornire una previsione statica per
	ogni porzione dell'intervallo di previsione che fa parte 
	del campione su cui il modello è stato stimato, e una previsione
	dinamica (se rilevante) fuori dal campione. L'opzione
	<lit>dynamic</lit> richiede di produrre previsioni dinamiche a partire
	dalla prima data possibile, mentre l'opzione <lit>static</lit>
	richiede di produrre previsioni statiche anche fuori dal campione.
      </para>

      <subhead context="cli">Previsioni ricorsive</subhead>
      <para context="cli">
	L'opzione <lit>recursive</lit> al momento è disponibile solo per i
	modelli composti da una singola equazione e stimati via OLS. Quando si
	usa questa opzione, le previsioni calcolate sono ricorsive, ossia: ogni
	previsione è generata da una stima del modello che usa i dati
	a partire da un certo punto fisso (ossia l'inizio dell'intervallo del
	campione usato per la stima originaria) fino alla data di previsione
	meno <math>k</math> osservazioni, dove <math>k</math> è il numero di
	<lit>passi-avanti</lit> specificato come argomento. Le previsioni sono
	sempre dinamiche quando è possibile. Si noti che l'argomento
	<lit>passi-avanti</lit> deve essere utilizzato solo insieme all'opzione
	<lit>recursive</lit>.
      </para>

      <subhead>Modelli ordinali e multinomiali</subhead>
      <para>
	Dopo la stima di un modello logit o probit ordinale, o di un
	logit multinomiale, si potrebbero voler calcolare le
	probabilità di ogni possibile esito anziché una previsione
	<quote>secca</quote> per ogni osservazione. Per questo si usa
	l'opzione <opt>all-probs</opt>: l'output di <lit>fcast</lit>
	diventa una matrice con una colonna per ogni esito
	possibile. Per dare un nome a tale matrice, si usi l'argomento
	<repl>vname</repl>, col quale la stampa dell'output è
	soppressa. Se l'argomento <repl>vname</repl> non viene
	fornito, la matrice può essere recuperata attraverso
	l'accessore <fncref targ="$fcast"/>. Le opzioni <opt>plot</opt>
	e <opt>all-probs</opt> sono incompatibili.
      </para>

      <subhead context="cli">Grafici</subhead>
      <para context="cli">
	L'opzione <opt>plot</opt> provoca la rappresentazione grafica
	della previsione. Nel caso di sistemi di equazioni
	quest'opzione è disponibile solo quando l'argomento
	<repl>vname</repl> seleziona per la previsione una variabile
	singola. L'estensione dell'argomento <repl>filename</repl> di
	questa opzione controlla il formato del grafico:
	<lit>.eps</lit> per EPS, <lit>.pdf</lit> per PDF,
	<lit>.png</lit> per PNG, <lit>.plt</lit> per un file di
	comandi gnuplot. Il nome di file <lit>display</lit> può essere
	usato per mostrare il grafico in una finestra.  Per esempio,
      </para>
      <code>
	fcast --plot=fc.pdf
      </code>
      <para>
	genererà un grafico in formato PDF. Vengono rispettati gli
	indirizzi di file assoluti; in caso contrario i file vengono
	scritti nella directory di lavoro di gretl.
      </para>

      <para>
	La natura degli errori standard della previsione (se
	disponibili) dipende dalla natura del modello e della
	previsione. Per i modelli lineari statici, gli errori standard
	sono calcolati seguendo il metodo descritto in <cite
	key="davidson-mackinnon04">Davidson e MacKinnon (2004)</cite>;
	essi incorporano sia l'incertezza dovuta al processo d'errore,
	sia l'incertezza dei parametri (sintetizzata dalla matrice di
	covarianza delle stime dei parametri). Per modelli dinamici,
	gli errori standard della previsione sono calcolati solo nel
	caso di previsione dinamica, e non incorporano incertezza dei
	parametri. Per modelli non lineari, al momento non sono
	disponibili errori standard della previsione.
      </para>

    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Analisi/Previsioni</menu-path>
    </gui-access>

  </command>

  <command name="flush" section="Programming" context="cli">

    <description>
      <para>
	Questo semplice comando non ha argomenti né opzioni; è pensato
	per l'esecuzione di script, la cui esecuzione richieda qualche
	tempo, attraverso l'interfaccia grafica (la versione di gretl
	da linea di comando lo ignora). L'idea è di fornire all'utente
	un'indicazione visuale che sta succedendo qualcosa e il
	programma non si è <quote>piantato</quote>.
      </para>
      <para>
	Normalmente, quando uno script viene fatto girare nel client
	grafico, non viene mostrato alcun output finché l'esecuzione
	non è completa; se perà si usa  <lit>flush</lit> l'effetto
	prodotto è il seguente:
      </para>
      <ilist>
	<li>
	  <para>
	    Alla prima invocazione, gretl apre una finestra, mostra
	    l'output prodotto fino a quel momento, e aggiunge il
	    messaggio <quote>elaborazione in corso...</quote>.
	  </para>
	</li>
	<li>
	  <para>
	    Ad ogni invocazione successiva, il testo mostrato nella
	    finestra di output viene aggiornato e un nuovo messaggio
	    <quote>elaborazione in corso...</quote> viene aggiunto.
	  </para>
	</li>
      </ilist>
      <para>
	Tutto il resto dell'output viene automaticamente mostrato al
	completamenteo dell'esecuzione dello script.
      </para>
      <para>
	Attenzione: non ha senso usare <lit>flush</lit> in uno script
	la cui esecuzione richiede pochi secondi. Inoltre, bisognerebbe
	evitare di usare questo comando in un punto dello script dove
	non c'è più output da mostrare, perché il messaggio
	<quote>elaborazione in corso...</quote> risulterebbe fuorviante.
      </para>
      <para>
	L'uso che abbiamo in mente per il comando <lit>flush</lit> è
	esemplificato dal seguente frammento:
      </para>
      <code>
	set echo off
	scalar n = 10
	loop i=1..n
	# qualcosa che richiede del tempo
	loop 100 --quiet
	a = mnormal(200,200)
	b = inv(a)
	endloop
	# stampa qualcosa in output
	printf "Iterazione %2d fatta\n", i
	if i &lt; n
	flush
	endif
	endloop
      </code>
    </description>

  </command>

  <command name="foreign" section="Programming"
	   label="Script esterni" context="cli">

    <usage>
      <syntax><lit>foreign language=</lit><repl>lang</repl></syntax>
      <options>
	<option>
          <flag>--send-data</flag>
          <effect>pre-carica il dataset attuale</effect>
	</option>
	<option>
          <flag>--quiet</flag>
          <effect>sopprime l'output dal programma esterno</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Questo comando apre una modalità speciale, in cui vengono
	accettati comandi che verranno eseguiti da un programma
	esterno.  Con il comando <lit>end foreign</lit> si esce da
	questa modalità e i comandi verranno eseguiti.
      </para>
      <para>
	Al momento, i programmi esterni compatibili con questa modalità
	sono GNU R (<lit>language=R</lit>), Ox di Jurgen Doornik Ox
	(<lit>language=Ox</lit>), GNU Octave
	(<lit>language=Octave</lit>), Python, Julia e Stata.
	I nomi dei programmi esterni sono case-insensitive.
      </para>
      <para>
	Con R, Octave e Stata l'opzione <opt>send-data</opt> ha
	l'effetto di rendere disponibile all'interno del programma di
	destinazione l'intero dataset corrente. È possibile limitare
	l'invio dell'intero dataset al programma di destinazione attraverso
	la creazione preventiva di una lista di variabili, a cui va assegnato
	un nome che dovrà essere dato in specifica al comando.
	Di seguito un esempio:
      </para>
      <code>
	list Rlist = x1 x2 x3
	foreign language=R --send-data=Rlist
      </code>
      <para>
	Si veda <guideref targ="chap:gretlR"/> per dettagli ed esempi.
      </para>
    </description>

  </command>

  <command name="fractint" section="Statistics" label="Fractional integration">

    <usage>
      <arguments>
	<argument>series</argument>
	<argument optional="true">order</argument>
      </arguments>
      <options>
	<option>
	  <flag>--gph</flag>
	  <effect>calcola il test di Geweke e Porter-Hudak</effect>
	</option>
	<option>
	  <flag>--all</flag>
	  <effect>calcola entrambi i test</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Verifica la presenza di integrazione frazionale
	(<quote>long memory</quote>) per la variabile specificata.
	L'ipotesi nulla è che l'ordine di integrazione della variabile
	sia zero. Di default viene utilizzato lo stimatore locale di
	Whittle <cite key="robinson95" p="true">(Robinson,
	1995)</cite>, ma se si indica l'opzione <opt>gph</opt> il comando
	usa il test GPH <cite key="GPH83" p="true">(Geweke e
	Porter-Hudak, 1983)</cite>. L'opzione
	<opt>all</opt> permette di ottenere i risultati di
	entrambi i test.
      </para>
      <para>
	Per maggiori dettagli su questo tipo di test, v. <cite
	key="phillips04">Phillips e Shimotsu (2004)</cite>.
      </para>
      <para>
	Se non si specifica l'argomento opzionale <repl>order</repl>,
	l'ordine del test (o dei test) è automaticamente fissato al
	più piccolo fra
	<math>T</math>/2 e <math>T</math><sup>0.6</sup>.
      </para>
      <para>
	Gli ordini di integrazione stimati e i loro errori standard
	sono disponibili con l'accessore <fncref targ="$result"/>. Con
	l'opzione <opt>all</opt>, lo stimatore Local Whittle è nella
	prima riga e il GPH nella seconda.
      </para>
      <para>
	I risultati possono essere recuperati usando gli accessori
	<fncref targ="$test"/> e <fncref targ="$pvalue"/>. Questi valori sono
	basati sullo stimatore locale di Whittle a meno che non sia
	stata indicata l'opzione <opt>gph</opt>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Variabile/Test per radici unitarie/Integrazione frazionale</menu-path>
    </gui-access>

  </command>

<command name="freq" section="Statistics" label="Distribuzione di frequenza">

  <usage>
    <arguments>
      <argument>variabile</argument>
    </arguments>
    <options>
      <option>
	<flag>--nbins</flag>
	<optparm>n</optparm>
	<effect>specifica il numero di intervalli</effect>
      </option>
      <option>
	<flag>--min</flag>
	<optparm>minval</optparm>
	<effect>specifica il valore minimo, v. oltre</effect>
      </option>
      <option>
	<flag>--binwidth</flag>
	<optparm>width</optparm>
	<effect>specifica l'ampiezza degli intervalli, v. oltre</effect>
      </option>
      <option>
        <flag>--normal</flag>
        <effect>test per la distribuzione normale</effect>
      </option>
      <option>
        <flag>--gamma</flag>
        <effect>test per la distribuzione gamma</effect>
      </option>
      <option>
        <flag>--silent</flag>
        <effect>non mostra nulla</effect>
      </option>
      <option>
	<flag>--matrix</flag>
	<optparm>nome</optparm>
	<effect>usa una colonna di una matrice specificata</effect>
      </option>
      <option>
	<flag>--plot</flag>
	  <optparm>mode-or-filename</optparm>
	  <effect>vedi oltre</effect>
      </option>
    </options>
    <examples>
      <example>freq x</example>
      <example>freq x --normal</example>
      <example>freq x --nbins=5</example>
      <example>freq x --min=0 --binwidth=0.10</example>
    </examples>
  </usage>

  <description context="cli">

    <para>
      Se non vengono indicate opzioni, mostra la distribuzione di
      frequenza per la <repl>variabile</repl> (indicata con il nome o
      il numero), con il numero di intervalli e ampiezza scelti
      automaticamente; a seconda dei casi un grafico può essere
      mostrato o no (vedi sotto). Se il comando viene eseguito
      correttamente, la tabella delle frequenze può essere salvata in
      una matrice utilizzando l'accessore <fncref targ="$result"/>.
    </para>
    <para>
      Se viene indicata l'opzione <opt>matrix</opt>, <repl>var</repl>
      (un numero intero in questo caso) viene invece interpretato come 
      un indice di base 1 che individua una colonna nella matrice indicata. 
      Nel caso in cui la matrice in questione sia un vettore colonna allora
      l'argomento <repl>var</repl> può essere omesso.
    </para>
    <para>
      Per impostazione predefinita, il comando usa un numero di
      intervalli calcolato automaticamente se i dati sono continui
      oppure nessun intervallo se i dati sono discreti. A questo fine,
      si può (a) utilizzare il comando <cmdref targ="discrete"/> per
      impostare lo stato di <repl>variabile</repl> o (b), se i dati
      sono continui, specificare il numero di categorie
      <emphasis>oppure</emphasis> il valore minimo e la loro larghezza
      dei contenitori, come mostrato negli ultimi due esempi
      sopra. L'opzione <opt>min</opt> imposta il limite inferiore della
      categoria più a sinistra.
    </para>
    <para>
      Usando l'opzione <opt>normal</opt>, vengono mostrati i
      risultati del test chi-quadro di Doornik&ndash;Hansen per la
      normalità.  Usando l'opzione <opt>gamma</opt>, al posto del
      test di normalità viene eseguito il test non parametrico di
      Locke per l'ipotesi nulla che la variabile segua la
      distribuzione gamma; si veda <cite key="locke76">Locke
      (1976)</cite>, <cite key="shapiro-chen01">Shapiro e Chen
      (2001)</cite>. Si noti che la parametrizzazione della
      distribuzione gamma in gretl è (forma, scala).
    </para>
    <para>
      Se il programma non è in batch mode, viene mostrato di default un 
      grafico della distribuzione in modalità interattiva. 
      Questo comportamento può essere modulato con l'opzione <opt>plot</opt>. 
      I parametri accettabili per questa opzione sono <lit>none</lit>, 
      per sopprimere il grafico; <lit>display</lit>, per mostrare il 
      grafico a video anche in batch mode; un nome di file. L'effetto 
      del fornire un nome di file è lo stesso di quello descritto dall'opzione
      <opt>output</opt> del comando <cmdref targ="gnuplot"/>.
    </para>
    <para>
      L'opzione <opt>silent</opt> sopprime interamente l'output
      mostrato di solito. Ha senso usarla insieme a una delle opzioni
      riguardanti la distribuzione: in questo modo la statistica test
      e il suo p-value verranno salvati, e potranno essere recuperati
      attraverso l'utilizzo degli accessori <fncref targ="$test"/> e
      <fncref targ="$pvalue"/>. Può anche essere utilizzato assieme
      all'opzione <opt>plot</opt> se si è solamente interessati alla
      visione dei relativi istogrammi e non si è interessati al resto
      del testo.
    </para>
    <para>
      Si noti che in gretl non è disponibile una funzione analoga 
      a questo comando, anche se la funzione generica <fncref targ="aggregate"/> 
      consente di raggiungere un risultato equivalente. 
      Inoltre, la distribuzione di frequenza costruita con il comando
      <lit>freq</lit> può essere ottenuta in forma matriciale
      attraverso l'utilizzo dell'accessore <fncref targ="$result"/>.
    </para>
  </description>

  <description context="gui">
    <para>
      Nella finestra di dialogo della distribuzione di frequenza è
      possibile controllare le caratteristiche del grafico in due
      modi diversi.
    </para>
    <para>
      Per prima cosa è possibile scegliere il numero di intervalli;
      in questo caso la larghezza e la posizione degli intervalli
      sono calcolate automaticamente.
    </para>
    <para>
      In alternativa, è possibile specificare il limite inferiore del primo
      intervallo e la larghezza degli intervalli; anche in questo caso il
      numero di intervalli viene calcolato automaticamente.
    </para>
    <para>
      Se si vuole che gli intervalli corrispondano a numeri interi, è
      possibile procedere in questo modo: iniziare specificando il numero di
      intervalli, controllare il grafico prodotto, prendere nota delle
      modifiche da fare (ad esempio impostare l'inizio del primo intervallo al
      valore 100 e la larghezza pari a 200), quindi ricreare il grafico
      specificando i valori scelti.
    </para>
    <para>
      Questa finestra permette inoltre di scegliere una distribuzione teorica
      da sovrapporre ai dati: la normale o la gamma. Se si sceglie la
      distribuzione normale, viene calcolato il test di normalità di
      Doornik&ndash;Hansen. Se si sceglie la gamma, gretl calcola il test
      non parametrico di Locke per l'ipotesi nulla che la variabile segua
      questa distribuzione. Si noti che la parametrizzazione della
      distribuzione gamma in gretl è (forma, scala).
    </para>
  </description>

  <gui-access>
    <menu-path>/Variabile/Distribuzione di frequenza</menu-path>
  </gui-access>

</command>

<command name="funcerr" section="Programming"
	 label="Uscita dopo errore" context="cli">

  <usage>
    <arguments>
      <argument optional="true">messaggio</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Questo comando è utilizzabile soltanto nel contesto di funzioni
      definite dall'utente (vedi <cmdref targ="function"/>); esso
      provoca un'interruzione della funzione con errore.
    </para>
    <para>
      Il parametro opzionale <argname>messaggio</argname> dev'essere
      una stringa (anche sotto forma di variabile); se presente,
      viene stampato assieme al messaggio di errore inviato alla
      funzione chiamante.
    </para>
      <para>
	Vedi anche la funzione <fncref targ="errorif"/>.
      </para>
  </description>

</command>

<command name="function" section="Programming" label="Definisce una funzione" context="cli">

  <usage>
    <arguments>
      <argument>nome_funzione</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Apre un blocco di istruzioni che definiscono una funzione. Il
      blocco va chiuso con <lit>end function</lit>. (Eccezione: per
      cancellare dalla memoria una funzione definita dall'utente, si
      usa il comando <lit>function pippo delete</lit>, dove
      <quote>pippo</quote> è la funzione da cancellare.) Per maggiori
      dettagli, si veda <guideref targ="chap:functions"/>.
    </para>
  </description>

</command>

<command name="garch" section="Estimation" label="Stima GARCH">
  <usage>
    <arguments>
      <argument>p</argument>
      <argument>q</argument>
      <argument separated="true">variabile-dipendente</argument>
      <argument optional="true">variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa nulla</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--nc</flag>
	<effect>non include una costante</effect>
      </option>
      <option>
	<flag>--stdresid</flag>
	<effect>standardizza i residui</effect>
      </option>
      <option>
	<flag>--fcp</flag>
	<effect>usa l'algoritmo di Fiorentini, Calzolari e Panattoni</effect>
      </option>
      <option>
	<flag>--arma-init</flag>
	<effect>parametri di varianza iniziale da ARMA</effect>
      </option>
    </options>
    <examples>
      <example>garch 1 1 ; y</example>
      <example>garch 1 1 ; y 0 x1 x2 --robust</example>
      <demos>
	<demo>garch.inp</demo>
	<demo>sw_ch14.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para context="cli">
      Stima un modello GARCH (Generalized Autoregressive
      Conditional Heteroskedasticity) univariato, o, se sono specificate delle
      <repl>variabili-indipendenti</repl>, includendo delle variabili esogene.
      I valori interi <repl>p</repl> e <repl>q</repl> (che possono essere
      indicati in forma numerica o col nome di variabili scalari preesistenti)
      rappresentano gli ordini di ritardo nell'equazione della varianza
      condizionale.
      <equation status="display"
		tex="\[h_t = \alpha_0 + \sum_{i=1}^q \alpha_i \varepsilon^2_{t-i} +
		     \sum_{j=1}^p \beta_j h_{t-j}\]"
		ascii="h(t) = a(0) + somma(per i da 1 a q) a(i)*u(t-i)^2 + somma( per j da 1 a p) b(j)*h(t-j)"
		graphic="garch_h"/>
    </para>
    <para context="cli">
      Il parametro <repl>p</repl> rappresenta quindi l'ordine
      generalizzato (o <quote>AR</quote>), mentre <repl>q</repl>
      rappresenta il consueto ordine ARCH (o <quote>MA</quote>). Se
      <repl>p</repl> è diverso da zero, anche <repl>q</repl> deve
      essere diverso da zero, altrimenti il modello non è
      identificato. Comunque, è possibile stimare un semplice
      modello ARCH impostando <repl>q</repl> a un valore positivo e
      <repl>p</repl> a zero. La somma di <repl>p</repl> e
      <repl>q</repl> non deve superare 5.  Si noti che
      nell'equazione della media viene automaticamente inclusa una
      costante, a meno che non si usi l'opzione <opt>nc</opt>.
      </para>

      <para context="gui">
	Stima un modello GARCH (Generalized Autoregressive Conditional
	Heteroskedasticity) univariato, o, se sono specificate delle
	variabili-indipendenti, includendo delle variabili esogene.
	L'equazione della varianza condizionale è la seguente:
	<equation status="display" tex="\[h_t = \alpha_0 +
					\sum_{i=1}^q \alpha_i \varepsilon^2_{t-i} + \sum_{j=1}^p
					\beta_i h_{t-j}\]" ascii="h(t) = a(0) + somma (i da 1 a q) a(i)*u(t-i) +
								  somma(j da 1 a p) b(j)*h(t-j)" graphic="garch_h"/>
      </para>
      <para context="gui">
	Il parametro <repl>p</repl> rappresenta quindi l'ordine
      generalizzato (o <quote>AR</quote>), mentre <repl>q</repl>
      rappresenta il consueto ordine ARCH (o <quote>MA</quote>). Se
      <repl>p</repl> è diverso da zero, anche <repl>q</repl> deve
      essere diverso da zero, altrimenti il modello non è
      identificato. Comunque, è possibile stimare un semplice
      modello ARCH impostando <repl>q</repl> a un valore positivo e
      <repl>p</repl> a zero. La somma di <repl>p</repl> e
      <repl>q</repl> non deve superare 5.
      </para>

      <para>
	Per impostazione predefinita, i modelli GARCH vengono stimati
	usando il codice nativo gretl, ma è anche possibile usare
	l'algoritmo di <cite key="fiorentini96">Fiorentini, Calzolari
	e Panattoni (1996)</cite>.  Il primo usa il massimizzatore
	BFGS, mentre il secondo usa un algoritmo di tipo
	Newton-Raphson con la matrice di informazione e un successivo
	raffinamento usando l'Hessiana.
      </para>

      <para context="cli">
	Sono disponibili varie stime della matrice di covarianza dei
	coefficienti. Il metodo predefinito è quello dell'Hessiana, a meno che
	non si usi l'opzione <opt>robust</opt>, nel qual caso viene usata la
	matrice di covarianza QML (White).  Altre possibilità (ad es. la matrice
	di informazione, o lo stimatore di Bollerslev&ndash;Wooldridge) possono
	essere specificate con il comando <cmdref targ="set"/>.
    </para>

    <para context="gui">
      Sono disponibili varie stime della matrice di covarianza dei
      coefficienti. Il metodo predefinito è quello dell'Hessiana, a meno di
      non selezionare la casella <quote>Errori standard robusti</quote>, nel
      qual caso viene usata la matrice di covarianza QML (White). Altre
      possibilità (ad es. la matrice di informazione, o lo stimatore di
      Bollerslev&ndash;Wooldridge) possono essere specificate con il comando
      <cmdref targ="set"/>.
    </para>

    <para context="gui">La varianza condizionale stimata, insieme ai
    residui e ad altre statistiche del modello, può essere
    richiamata ed aggiunta al dataset usando il menù
    <quote>Analisi</quote> presente nella finestra del modello. Se
    viene spillata la casella <quote>Standardizza i residui</quote>,
    i residui vengono divisi per la radice della varianza
    condizionale stimata.
    </para>

    <para context="cli">
      In modalità predefinita, le stime dei parametri di varianza
      sono inizializzate usando la varianza dell'errore non
      condizionale, ottenuta dalla stima OLS iniziale, per la
      costante, e piccoli valori positivi per i coefficienti dei
      valori passati dell'errore al quadrato e per la varianza
      dell'errore. L'opzione <opt>arma-init</opt> fa in modo che i
      valori iniziali per questi parametri siano ricavati da un
      modello ARMA iniziale, sfruttando la relazione tra GARCH e
      ARMA mostrata nel capitolo 21 di <book>Time Series
      Analysis</book> di Hamilton.  In alcuni casi, questo metodo
      può aumentare le probabilità di convergenza.
    </para>

    <para context="cli">
      I residui GARCH e la varianza condizionale stimata sono memorizzate
      rispettivamente nelle variabili <fncref targ="$uhat"/> e <fncref targ="$h"/>. Ad
      esempio, per ottenere la varianza condizionale è possibile scrivere:
    </para>
    <code context="cli">
      genr ht = $h
    </code>
    <para context="cli">
      Con l'opzione <opt>stdresid</opt>, i valori di <fncref targ="$uhat"/>
      vengono divisi per la radice di <math>h</math><sub>t</sub>.
    </para>

</description>

<gui-access>
  <menu-path>/Modello/Serie storiche/GARCH</menu-path>
</gui-access>

</command>

<command name="genr" section="Dataset"
	 label="Generazione di una nuova variabile">

  <usage>
    <arguments>
      <argument>nuova-variabile</argument>
      <argument>= formula</argument>
    </arguments>
  </usage>

  <description>
    <para>
      NOTA: questo comando ha subito molti cambiamenti e migliorie
      da quando l'help seguente è stato scritto, per cui per
      informazioni complete e aggiornate consigliamo di far
      riferimento al<guideref targ="chap:genr"/>. D'altro canto,
      il testo che segue non contiene informazioni erronee, per cui
      può essere interpretato come <quote>questo ed altro</quote>.
    </para>

    <para>
      In contesti appropriati, <lit>series</lit>, <lit>scalar</lit>,
      <lit>matrix</lit>, <lit>string</lit> e <lit>bundle</lit> sono
      sinonimi per questo comando.
    </para>
    <para context="cli">
      Crea nuove variabili, di solito per mezzo di trasformazioni di
      variabili esistenti. Si veda anche <cmdref targ="diff"/>,
      <cmdref targ="logs"/>, <cmdref targ="lags"/>, <cmdref
      targ="ldiff"/>, <cmdref targ="sdiff"/> e <cmdref
      targ="square"/> per alcune scorciatoie. Nel contesto di una
      formula <lit>genr</lit>, le variabili esistenti devono essere
      referenziate per nome, non per numero identificativo. La
      formula dev'essere una combinazione ben definita di nomi di
      variabile, costanti, operatori e funzioni (descritte
      oltre). Ulteriori dettagli su alcuni aspetti di questo comando
      si possono trovare nel<guideref targ="chap:genr"/>.
    </para>

    <para context="gui">
      Usate questa riga per definire una nuova variabile seguendo lo schema
      <repl>nome</repl> = <repl>formula</repl>.  La formula dovrebbe essere
      una combinazione sintatticamente corretta di nomi di variabili,
      operatori e funzioni (v. oltre per ulteriori dettagli). Per essere sicuri
      di ottenere una variabile del tipo desiderato è possibile premettere alla
      formula il nome di un tipo, &eg;
      <lit>scalar</lit>, <lit>series</lit> o <lit>matrix</lit>.  Per esempio,
      per creare una variabile con un valore costante pari a 10 possiamo digitare
    </para>
    <code context="gui">
      series c = 10
    </code>
    <para context="gui">
      (in caso contrario <lit>c = 10</lit> creerebbe una variabile scalare).
    </para>

    <para>
      Il comando <lit>genr</lit> può produrre come risultato una serie
      o uno scalare. Ad esempio, la formula <lit>x2 = x * 2</lit>
      produce una serie se la variabile <lit>x</lit> è una serie e uno
      scalare se <lit>x</lit> è uno scalare.  Le formule <lit>x =
      0</lit> e <lit>mx = mean(x)</lit> producono degli scalari. In
      alcune circostanze, può essere utile che un risultato scalare
      sia espanso in una serie o in un vettore: è possibile ottenere
      questo risultato usando <lit>series</lit> come
      <quote>alias</quote> per il comando <lit>genr</lit>. Ad esempio,
      <lit>series x = 0</lit> produce una serie con tutti i valori
      pari a 0. Allo stesso modo, è possibile usare <lit>scalar</lit>
      come alias per <lit>genr</lit>, ma non è possibile forzare un
      risultato vettoriale in uno scalare: con questa parola chiave si
      indica che il risultato <emphasis>dovrebbe essere</emphasis> uno
      scalare; se non lo è, viene emesso un messaggio di errore.
    </para>

    <para>
      Quando una formula produce come risultato una serie,
      l'intervallo su cui essi sono definiti dipende dall'impostazione
      attuale del campione. È quindi possibile definire una serie a
      pezzi, alternando l'uso dei comandi <lit>smpl</lit> e
      <lit>genr</lit>.
    </para>

    <para>
      Gli <emphasis>operatori aritmetici</emphasis> supportati sono, in
      ordine di precedenza: <lit>^</lit> (esponenziale); <lit>*</lit>,
      <lit>/</lit> e <lit>%</lit> (modulo o resto); <lit>+</lit> e
      <lit>-</lit>.
    </para>

    <para>
      Gli <emphasis>operatori Booleani</emphasis> disponibili sono
      (ancora in ordine di precedenza): <lit>!</lit> (negazione),
      <lit>&amp;&amp;</lit> (AND logico), <lit>||</lit> (OR logico),
      <lit>&gt;</lit>, <lit>&lt;</lit>, <lit>=</lit>,
      <lit>&gt;=</lit> (maggiore o uguale), <lit>&lt;=</lit>
      (minore o uguale) e <lit>!=</lit> (disuguale).  Gli operatori
      Booleani possono essere usati per costuire variabili dummy:
      ad esempio <lit>(x > 10)</lit> produce 1 se <lit>x</lit>
    &gt; 10, 0 altrimenti.</para>

    <para>
      Le costanti predefinite sono <lit>pi</lit> e <lit>NA</lit>. L'ultima
      rappresenta il codice per i valori mancanti: è possibile inizializzare
      una variabile con valori mancanti usando <lit>scalar x = NA</lit>.
    </para>

    <para>
      Il comando <lit>genr</lit> supporta un'ampia gamma di funzioni
      matematiche e statistiche, da quelle più comuni a quelle di uso
      specifico in econometria. Inoltre offre l'accesso a numerose variabili
      interne che vengono definite nel corso della stima di regressioni,
      dell'esecuzione di test, e così via.
      <refnote xref="false">
	Per un elenco delle funzioni e degli accessori, eseguire:
	<quote>help functions</quote>.
      </refnote>
      <refnote xref="true">
	Per un elenco delle funzioni e degli accessori, si veda:
	<gfr targ="chap:funcref"/>.
      </refnote>
    </para>

    <para>
      Oltre agli operatori e alle funzioni mostrati, ci sono alcuni
      usi speciali del comando <cmd>genr</cmd>:
    </para>

    <ilist>
      <li><para><cmd>genr time</cmd> crea una variabile trend temporale
      (1,2,3,&hellip;) chiamata <cmd>time</cmd>.
      <cmd>genr index</cmd> fa la stessa cosa, ma chiamando la variabile
      <lit>index</lit>.</para>
      </li>
      <li>
	<para>
	  <cmd>genr dummy</cmd> crea una serie di variabili dummy a seconda
	  della periodicità dei dati. Ad esempio, nel caso di dati trimestrali
	  (periodicità 4) il programma crea <lit>dq1</lit>, che vale 1
	  nel primo trimestre e 0 altrove, <lit>dq2</lit> che vale 1
	  nel secondo trimestre e 0 altrove, e così via. Nel caso di dati
	  mensili, le dummy si chiamano <lit>dm1</lit>, <lit>dm2</lit> e così
	  via. Con altre frequenze dei dati, i nomi delle dummy sono <lit>dummy_1</lit>,
	  <lit>dummy2</lit>, ecc.
	</para>
      </li>
      <li><para><cmd>genr unitdum</cmd> e <cmd>genr timedum</cmd> creano insiemi di
      variabili dummy speciali da usare in un dataset di tipo panel. Il
      primo comando crea dummy che rappresentano le unità cross section,
      il secondo i periodi di osservazione.
    </para>
      </li>
    </ilist>

    <para>
      <emphasis>Nota</emphasis>: nella versione a riga di comando
      del programma, i comandi <cmd>genr</cmd> che estraggono dati
      relativi al modello si riferiscono sempre al modello stimato
      per ultimo. Questo vale anche per la versione grafica del
      programma se si usa <cmd>genr</cmd> nel <quote>terminale di
      gretl</quote> o si immette una formula usando l'opzione
      <quote>Definisci nuova variabile</quote> nel menù Variabile
      della finestra principale. Usando la versione grafica, però, è
      possibile anche estrarre i dati da qualunque modello mostrato
      in una finestra (anche se non è il modello più recente) usando
      il menù <quote>Analisi</quote> nella finestra del modello.
    </para>

    <para>
      La variabile speciale <lit>obs</lit> serve da indice per le
      osservazioni.  Ad esempio, <lit>genr dum = (obs==15)</lit> crea
      una variabile dummy che vale 1 per l'osservazione 15 e 0
      altrove. È anche possibile usare questa variabile per
      selezionare alcune osservazioni particolari secondo la data o
      il nome. Ad esempio
      <lit>genr d = (obs&gt;1986:4)</lit>,
      <lit>genr d = (obs&gt;"2008/04/01")</lit>, oppure
      <lit>genr d = (obs=="CA")</lit>. Quando si usano in questo contesto date
      giornaliere o etichette per le osservazioni, bisogna
      racchiuderle fra virgolette.  Questo non è necessario per date
      trimestrali o annuali. Si noti che, per serie storiche
      annuali, l'anno non è sintatticmante distiguibile da un
      semplice intero; per cui, per confrontare un'osservazione con
      <lit>obs</lit> per anno, bisogna usare la funzione
      <lit>obsnum</lit> per convertire l'anno in un numero
      progressivo, come ad esempio in in <lit>genr d =
      (obs&gt;obsnum(1986))</lit>.
      </para>

      <para>
	È possibile estrarre dei valori scalari da una serie usando
	una formula <lit>genr</lit> con la sintassi
	<repl>nome-variabile</repl><lit>[</lit><repl>osservazione</repl><lit>]</lit>.
	Il valore di <repl>osservazione</repl> può essere specificato con
	un numero o una data.
	Esempi: <lit>x[5]</lit>, <lit>CPI[1996:01]</lit>.  Per i dati
	giornalieri occorre usare la forma <repl>AAAA/MM/GG</repl>, ad esempio
	<lit>ibm[1970/01/23]</lit>.
      </para>

      <para>
	È possibile modificare una singola osservazione in una serie
	usando <lit>genr</lit>. Per farlo, occorre aggiungere un numero
	di osservazione o una data valida tra parentesi quadre al nome
	della variabile nel lato sinistro della formula. Ad esempio:
	<lit>genr x[3] = 30</lit> o <lit>genr x[1950:04] =
	303.7</lit>.
      </para>

      <table id="tab-genr" title="Esempi di utilizzo del comando genr"
	     lhead="Formula" rhead="Commento"
	     lwidth="100pt" rwidth="300pt"
	     style="rpara">
	<row>
	  <cell><lit>y = x1^3</lit></cell>
	  <cell><lit>x1</lit> al cubo</cell>
	</row>
	<row>
	  <cell><lit>y = ln((x1+x2)/x3)</lit></cell>
	  <cell></cell>
	</row>
	<row>
	  <cell><lit>z = x&gt;y</lit></cell>
	  <cell><lit>z(t)</lit> = 1 se <lit>x(t) &gt; y(t)</lit>,
	  0 altrove</cell>
	</row>
	<row>
	  <cell><lit>y = x(-2)</lit></cell>
	  <cell><lit>x</lit> ritardata di 2 periodi</cell>
	</row>
	<row>
	  <cell><lit>y = x(+2)</lit></cell>
	  <cell><lit>x</lit> anticipata di 2 periodi</cell>
	</row>
	<row>
	  <cell><lit>y = diff(x)</lit></cell>
	  <cell><lit>y(t) = x(t) - x(t-1)</lit></cell>
	</row>
	<row>
	  <cell><lit>y = ldiff(x)</lit></cell>
	  <cell><lit>y(t) = log x(t) - log x(t-1)</lit>, il
	  tasso di crescita istantaneo di <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>y = sort(x)</lit></cell>
	  <cell>ordina <lit>x</lit> in senso crescente e la salva in
	  <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>y = dsort(x)</lit></cell>
	  <cell>ordina <lit>x</lit> in senso decrescente</cell>
	</row>
	<row>
	  <cell><lit>y = int(x)</lit></cell>
	  <cell>tronca <lit>x</lit> e salva il valore intero in
	  <lit>y</lit></cell>
	</row>
	<row>
	  <cell><lit>y = abs(x)</lit></cell>
	  <cell>salva il valore assoluto di <lit>x</lit></cell>
	</row>
	<row>
	  <cell><lit>y = sum(x)</lit></cell>
	  <cell>somma i valori di <lit>x</lit> escludendo i valori mancanti <lit>NA</lit></cell>
	</row>
	<row>
	  <cell><lit>y = cum(x)</lit></cell>
	  <cell>cumulativa:
	  <equation status="inline"
		    tex="$y_t = \sum_{\tau=1}^t x_{\tau}$"
		    ascii="y(t) = somma di x(s) per s da 1 a t"
		    graphic="cumulate"/>
	  </cell>
	</row>
	<row>
	  <cell><lit>aa = $ess</lit></cell>
	  <cell>imposta <lit>aa</lit> uguale alla somma dei quadrati degli errori
	  dell'ultima regressione</cell>
	</row>
	<row>
	  <cell><lit>x = $coeff(sqft)</lit></cell>
	  <cell>estrae il coefficiente stimato per la variabile
	  <lit>sqft</lit> nell'ultima regressione</cell>
	</row>
	<row>
	  <cell><lit>rho4 = $rho(4)</lit></cell>
	  <cell>estrae il coefficiente di autoregressione del quarto
	  ordine dall'ultimo modello (presume un modello
	  <lit>ar</lit> model)</cell>
	</row>
	<row>
	  <cell><lit>cvx1x2 = $vcv(x1, x2)</lit></cell>
	  <cell>estrae il coefficiente di covarianza stimato tra le
	  variabili <lit>x1</lit> e <lit>x2</lit> dall'ultimo modello</cell>
	</row>
	<row>
	  <cell><lit>foo = uniform()</lit></cell>
	  <cell>variabile pseudo-casuale uniforme nell'intervallo
	  0&ndash;1</cell>
	</row>
	<row>
	  <cell><lit>bar = 3 * normal()</lit></cell>
	  <cell>variabile pseudo-casuale normale con &mu; = 0, &sigma; =
	  3</cell>
	</row>
	<row>
	  <cell><lit>samp = ok(x)</lit></cell>
	  <cell>vale 1 per le osservazioni dove il valore di <lit>x</lit>
	  non è mancante.</cell>
	</row>
      </table>

    </description>

    <gui-access>
      <menu-path>/Variabile/Definisci nuova variabile</menu-path>
      <other-access>Menù pop-up nella finestra principale</other-access>
    </gui-access>

  </command>

  <command name="genrand" section="Programming" context="gui"
	   label="Generazione di variabili casuali">

    <description>
      <para>
	In questa finestra occorre specificare il nome da dare alla
	variabile da generare, seguito da alcune informazioni aggiuntive
	che dipendono dal tipo di distribuzione.
      </para>

      <ilist>
	<li>
	  <para>
	    Uniforme: limite superiore e inferiore per la distribuzione.
	  </para>
	</li>
	<li>
	  <para>
	    Normale: la media e lo scarto quadratico medio (deve essere positivo).
	  </para>
	</li>
	<li>
	  <para>
	    Chi-quadro e t di Student: i gradi di libertà (devono essere positivi).
	  </para>
	</li>
	<li>
          <para>
	    F: gradi di libertà al numeratore e denominatore.
          </para>
	</li>
	<li>
          <para>
            Gamma: parametri di forma e scala (entrambi positivi).
          </para>
	</li>
	<li>
          <para>
            Binomiale: numero di prove (un intero positivo)
            e la probabilità di <quote>successo</quote>.
          </para>
	</li>
	<li>
          <para>
            Poisson: la media (che è pari anche alla varianza).
          </para>
	</li>

      </ilist>

      <para>
	Se occorre generare sequenze ripetibili di numeri pseudo-casuali, è
	possibile impostare il seme del generatore, nel menù Strumenti.
      </para>

    </description>
  </command>

  <command name="genseed" section="Programming" context="gui"
	   label="Impostare il seme per i numeri casuali">

    <description>
      <para>
	Il "seme" rappresenta il punto di partenza per la sequenza di numeri
	pseudo-casuali generati in una sessione di gretl. Per impostazione
	predefinita, il seme viene impostato all'avvio del programma, basandosi
	sull'orologio di sistema. Ciò fa sì che si ottenga una diversa sequenza
	di numeri casuali ogni volta che si usa il programma; se invece si vuole
	usare sequenze ripetibili di numeri, occorre impostare manualmente il
	seme (e ricordarsi il valore usato).
      </para>
      <para>
	Si noti che il generatore viene re-impostato ogni volta che si fa clic
	sul pulsante "OK" di questa finestra di dialogo, quindi, ad esempio,
	se si imposta il seme a 147, si genera una serie dalla distribuzione
	normale standard, si riapre questa finestra di dialogo e si fa clic su
	"OK" indicando ancora 147 come seme, e infine si genera una seconda
	serie dalla normale standard, le due serie generate saranno identiche.
      </para>
    </description>
  </command>


  <command name="gibbs" section="Statistics" label="campionatore di Gibbs">

    <usage>
      <arguments>
        <argument>burnin</argument>
        <argument>N</argument>
        <argument>output</argument>
      </arguments>  
      <options>
	<option>
	  <flag>--keep</flag>
	  <effect>vedi sotto</effect>
        </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
        </option>
	<option>
	  <flag>--thinning</flag>
	  <effect>vedi sotto</effect>
        </option>
      </options>
      <examples>
	<demos>
	  <demo>casella_ex1.inp</demo>
	</demos>
      </examples>
    </usage>  

    <description>
      <para>
        <emphasis>Questa documentazione è preliminare e provvisoria.</emphasis>
      </para>
      <para>
	Questo comando è progettato per facilitare la costruzione e
	l'esecuzione di un campionatore di Gibbs; per una spiegazione
	approfondita vedere <cite key="casella92">Casella e George
	(1992)</cite>. In sintesi, il campionatore di Gibbs è un
	metodo per approssimare la distribuzione marginale di una o
	più variabili casuali appartenenti a una distribuzione
	congiunta, nel caso in cui non esista una formula analitica
	per le variabili marginali, o se esiste una formula, questa
	sia eccessivamente complicata. Questo risultato si ottiene
	mediante la simulazione delle distribuzioni condizionali
	associate. Se le marginali esistono, possono essere
	approssimate con precisione arbitraria con un numero
	sufficiente di iterazioni.
      </para>
      <para>
	Il comando ha la forma di un blocco di istruzioni che
	definiscono scalari o matrici; il blocco inizia con
	<lit>gibbs</lit> e termina con <lit>end gibbs</lit>. Le
	eventuali opzioni vanno all'ultima riga. La struttura è
	illustrata nel seguente semplice esempio, dove <lit>x</lit>
	condizionata a <lit>y</lit> è una binomiale mentre
	<lit>y</lit> condizionata a <lit>x</lit> è una beta; quel che
	interessa è la distribuzione marginale di <lit>x</lit>.
      </para>
      <code>
	gibbs burnin=500 N=5000 output=GB
	  init y = randgen1(beta, a, n - b)
	  record x = randgen1(b, y, n)
	  y = randgen1(beta, x + a, n - x + b)
	end gibbs
      </code>
      <para>
	Nella prima riga, <lit>burnin</lit> deve essere un intero non
	negativo e <lit>N</lit> un intero positivo (sia come valori
	numerici che come variabili scalari). Il valore
	<lit>burnin</lit> determina il numero di iterazioni
	preliminari, che servono a stabilizzare la ricorsione e non
	verranno registrate, mentre <lit>N</lit> indica il numero di
	iterazioni da registrare, in una matrice denominata
	dall'argomento <lit>output</lit>.
      </para>
      <para>
	All'interno del blocco vengono utilizzate due parole chiave,
	<lit>init</lit> e <lit>record</lit>, che sono mutualmente
	esclusive e controllano come vengono gestite le istruzioni.
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>init</lit> identifica un'istruzione come un inizializzatore,
	    da eseguire una sola volta prima dell'iterazione di Gibbs.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>record</lit> contrassegna un'istruzione come
	    un'istruzione il cui risultato deve essere registrato a
	    ogni iterazione.
	  </para>
        </li>
      </ilist>
    <para>
      Le istruzioni che non contengono nessuna delle due parole chiave
      vengono considerate parte dell'iterazione, ma i loro risultati
      non vengono registrati nella matrice di output. Le istruzioni
      contrassegnate con <lit>init</lit> devono essere fornite per
      prime.
    </para>
    <para>
      Il contenuto principale del bundle di output è una matrice
      denominata <lit>H</lit> che per default ha <lit>N</lit> righe e
      una dimensione in colonna che dipende dal numero e dal tipo di
      marginali da registrare; i risultati della matrice vengono
      registrati in formato vec trasposto. Oltre a questa matrice, il
      bundle contiene diversi elementi di metadati: si veda "Metadati"
      più sotto. Se il bundle indicato nell'argomento
      <lit>output</lit> esiste già, viene sovrascritto, altrimenti
      viene creato un nuovo bundle.
    </para>
    <subhead>Opzioni</subhead>
    <para>
      Sono supportate tre opzioni, che vanno nella riga finale del
      blocco.
    </para>
    <ilist>
      <li>
	<para>
	  L'opzione <opt>quiet</opt> sopprime l'output di default
	  (un breve report sullo stato di avanzamento e alcune statistiche
	  di riepilogo di base relative alla matrice di output).
	</para>
      </li>
      <li>
	<para>
	  Per default, tutte le variabili appena create all'interno
	  del blocco <lit>gibbs</lit> vengono eliminate al termine
	  dell'iterazione. L'opzione <opt>keep</opt> preserva tali
	  variabili, il che può essere utile in fase di debug.
	</para>
      </li>
      <li>
	<para>
	L'opzione <opt>thinning</opt> può essere usata per limitare
	l'output a un sottoinsieme del numero totale di iterazioni. Ad
	esempio, <lit>--thinning=10</lit> significa che verrà salvata
	solo un'iterazione ogni 10. In tal caso, la dimensione di riga
	della matrice <lit>H</lit> sarà <math>N</math>/10 anziché
	<math>N</math>.
	</para>
      </li>
    </ilist>
    <subhead>Metadati</subhead>
      <para>
      I membri aggiuntivi del bundle di output contengono i valori di
      <lit>burnin</lit>, <lit>N</lit> e <lit>thinning</lit>. Inoltre,
      l'output contiene un sotto-bundle relativo a (e denominato in
      base a) ciascuna variabile selezionata per la
      registrazione. Questi sotto-bundle contengono
      </para>
      <ilist>
	<li>
	  <para>
	    la colonna iniziale (<lit>startcol</lit>) e il numero di colonne
	    (<lit>ncols</lit>) nella matrice <lit>H</lit> relative alla
	    variabile in questione;
	  </para>
	</li>
	<li>
	  <para>
	    un valore booleano <lit>discrete</lit> che indica se la
	    variabile è discreta o meno;
	  </para>
	</li>
	<li>
	  <para>
	    una stringa <lit>type</lit>, che può essere <lit>scalar</lit> o
	    <lit>matrix</lit>;
 	  </para>
	</li>
	<li>
	  <para>
	    una matrice di nome <lit>stats</lit> con alcune
	    statistiche descrittive.
	  </para>
	</li>
      </ilist>
    </description>
</command>
  
  <command name="gmm" section="Estimation" label="Stima GMM">

    <usage>
      <options>
	<option>
	  <flag>--two-step</flag>
	  <effect>Stima a due passi</effect>
	</option>
	<option>
	  <flag>--iterate</flag>
	  <effect>GMM iterato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>Mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--verbose</flag>
	  <effect>Mostra i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa nulla</effect>
	</option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa il massimizzatore L-BFGS-B anziché il BFGS standard</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>hall_cbapm.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>

      <para>
	Esegue la stima col metodo dei momenti generalizzato
	(Generalized Method of Moments, GMM) usando l'algoritmo BFGS
	(Broyden, Fletcher, Goldfarb, Shanno). Occorre specificare uno
	o più comandi per aggiornare le quantità rilevanti
	(tipicamente i residui GMM), una o più condizioni di
	ortogonalità, una matrice iniziale dei pesi e un elenco dei
	parametri da stimare, il tutto racchiuso tra le parole chiave
	<lit>gmm</lit> e <lit>end gmm</lit>. Ogni opzione aggiuntiva
	va messa nella riga del comando <lit>end gmm</lit>.
      </para>
      <para>
	Si veda <guideref targ="chap:gmm"/> per i dettagli. Quello che segue
	è un semplice esempio illustrativo.
      </para>
      <code>
	gmm e = y - X*b
	orthog e ; W
	weights V
	params b
	end gmm
      </code>
      <para>
	Nell'esempio si assume che <lit>y</lit> e <lit>X</lit> siano matrici di
	dati, <lit>b</lit> sia un vettore con i valori dei parametri, <lit>W</lit>
	sia una  matrice di strumenti, e <lit>V</lit> un'appropriata matrice dei pesi.
	La dichiarazione
      </para>
      <code>
	orthog e ; W
      </code>
      <para>
	indica che il vettore dei residui <lit>e</lit> è in linea di principio
	ortogonale ad ognuno degli strumenti che compongono le colonne di
	<lit>W</lit>.
      </para>
      <subhead>Nome dei parametri</subhead>
      <para>
	Nella stima di un modello non lineare spesso risulta
	conveniente rinominare i parametri in maniera concisa. Durante
	la stampa dei risultati, comunque, risulta desiderabile
	l'utilizzo di etichette il più informative possibile. Questo
	può essere fatto attraverso l'aggiunta della parola chiave
	<lit>param_names</lit> dentro il blocco di comando. Per un
	modello con <math>k</math> parametri l'argomento che segue
	questa parola chiave dovrebbe essere o una stringa letterale
	contenente tutti i <math>k</math> nomi separati da spazi e
	racchiusi dentro le doppie virgolette, oppure il nome di nome
	di una variabile stringa contenente tutti <math>k</math> nomi
	dell'elenco.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/GMM</menu-path>
    </gui-access>

  </command>

  <command name="gnuplot" section="Graphs" label="Crea un grafico Gnuplot" context="cli">

    <usage>
      <altforms>
        <altform><lit>gnuplot</lit> <repl>yvars</repl> <repl>xvar</repl></altform>
        <altform><lit>gnuplot</lit> <repl>yvars</repl> <lit>--time-series</lit></altform>
        <altform><lit>gnuplot</lit> <repl>yvars</repl> <repl>xvar</repl> <repl>factor</repl> <lit>--factorized</lit></altform>
	<altform><lit>gnuplot</lit> <repl>yvar</repl> <repl>xvar</repl> <repl>zvars</repl> <lit>--control</lit></altform>
      </altforms>
      <options>
	<option>
	  <flag>--with-lines</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee invece che punti</effect>
	</option>
	<option>
	  <flag>--with-lp</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee e punti</effect>
	</option>
	<option>
	  <flag>--with-impulses</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa linee verticali</effect>
	</option>
        <option>
	  <flag>--with-boxes</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>produce un istogramma</effect>
        </option>
	<option>
	  <flag>--with-steps</flag>
	  <optparm optional="true">varspec</optparm>
	  <effect>usa segmenti orizzontali e verticali</effect>
	</option>
	<option>
	  <flag>--time-series</flag>
	  <effect>mostra rispetto al tempo</effect>
	</option>
	<option>
	  <flag>--single-yaxis</flag>
	  <effect>forza l'uso di un solo asse delle ordinate</effect>
	</option>
	<option>
	  <flag>--y2axis</flag>
	  <optparm>yvar</optparm>
	  <effect>mette la variabile specificata sul secondo asse delle ordinate</effect>
	</option>
	<option>
	  <flag>--ylogscale</flag>
	  <optparm optional="true">base</optparm>
	  <effect>ordinate in scala logaritmica</effect>
	</option>
	<option>
	  <flag>--control</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--dummy</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--fit</flag>
	  <optparm>fitspec</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--font</flag>
	  <optparm>fontspec</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--band</flag>
	  <optparm>bundle</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--bands</flag>
	  <optparm>array</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--matrix</flag>
	  <optparm>name</optparm>
	  <effect>mostra le colonne di una data matrice</effect>
	</option>
	<option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>ridirige l'output su file</effect>
	</option>
	<option>
	  <flag>--outbuf</flag>
	  <optparm>nomestringa</optparm>
	  <effect>ridirige l'output in una stringa</effect>
	</option>
	<option>
	  <flag>--input</flag>
	  <optparm>filename</optparm>
	  <effect>prende l'input da file</effect>
	</option>
	<option>
	  <flag>--inbuf</flag>
	  <optparm>nomestringa</optparm>
	  <effect>prende l'input da una stringa</effect>
	</option>
      </options>
      <examples>
	<example>gnuplot y1 y2 x</example>
	<example>gnuplot x --time-series --with-lines</example>
	<example>gnuplot wages educ gender --factorized</example>
	<example>gnuplot y x --fit=quadratic</example>
	<example>gnuplot y1 y2 x --with-lines=y2</example>
      </examples>
    </usage>

    <description>
      <para>
	Le variabili nella lista <repl>variabili-y</repl> vengono
	disegnate rispetto a <repl>variabile-x</repl>. Per avere un
	grafico a serie storica è possibile usare <lit>time</lit> come
	<repl>variabile-x</repl>, oppure usare l'opzione
	<opt>time-series</opt>. Vedi anche i comandi <cmdref
	targ="plot"/> e <cmdref targ="panplot"/>.
      </para>
      <para>
	Di default, i dati sono mostrati come punti, ma questa scelta
	può essere modificata usando una delle opzioni
	<opt>with-lines</opt>, <opt>with-lp</opt>,
	<opt>with-impulses</opt> o <opt>with-steps</opt>. Se il
	grafico contiene più di una serie, l'effetto di queste opzioni
	può essere limitato ad un sottoinsieme delle stesse usando il
	parametro <repl>varspec</repl>.  Questo deve essere una lista
	di variabili oppure un elenco dei nomi (o dei numeri),
	separati da virgole, delle variabili da tracciare. L'ultimo
	tra gli esempi di cui sopra mostra come tracciare
	<lit>y1</lit> e <lit>y2</lit> contro <lit>x</lit>,in modo tale
	che <lit>y2</lit> sia rappresentata da una linea, ma
	<lit>y1</lit> da punti.
      </para>
      <para>
	Quando <repl>yvars</repl> contiene più di una variabile
	potrebbe essere preferibile utilizzare due scale (sinistra e
	destra) per le ordinate. Per default, questo viene gestito
	automaticamente, tramite un'euristica basata sugli ordini di
	grandezza relativi delle variabili, ma è possibile utilizzare
	due opzioni (mutuamente esclusive) per cambiare l'impostazione
	di default. L'opzione <opt>single-yaxis</opt> impedisce l'uso
	di un secondo asse, mentre <opt>y2axis=</opt><repl>yvar</repl>
	specifica che una variabile selezionata deve essere plottata
	usando un secondo asse delle ordinate.
      </para>
      <subhead>Grafici fattorizzati</subhead>
      <para>
	L'opzione <opt>factorized</opt> supporta un grafico X&ndash;Y
	in cui le variabili <repl>yvars</repl> sono tracciate in stili
	diversi (tipo di punto, colore) a seconda del valore di una
	variabile fattore discreta. Il fattore deve essere specificato
	dopo la variabile <math>x</math>.
      </para>
      <para>
	Il caso più semplice è quello di una singola variabile
	<math>y</math> e di una variabile dummy 0/1 come fattore, come
	nel terzo esempio di utilizzo riportato sopra, che mette in
	grafico il salario rispetto all'istruzione, fattorizzata per
	il genere.  Ma è possibile avere più di una variabile
	<math>y</math> e il fattore può avere più di due
	valori. Quando più variabili <math>y</math> devono essere
	tracciate è possibile limitare il trattamento della
	fattorizzazione a un sottoinsieme aggiungendo un parametro al
	flag di opzione: il nome di una serie o di un elenco di
	serie. Nell'esempio seguente <lit>y</lit> e <lit>yhat</lit>
	sono tracciate rispetto a <lit>x</lit>, con la fattorizzazione
	per <lit>id</lit> limitata a <lit>y</lit>.
      </para>
      <code>
	gnuplot y yhat x id --with-lines=yhat --factorized=y
      </code>
      <subhead>Grafici con controllo</subhead>
      <para>
	Quando l'opzione <opt>control</opt> è specificata, devono
	essere fornite tre o più variabili: una singola variabile
	<math>y</math> e due variabili <quote>esplicative</quote>
	<math>x</math> e una o più variabili di controllo
	<math>zvars</math>.  L'effetto è che sia <math>y</math> che
	<math>x</math> sono regredite su <math>zvars</math> e i
	residui della <math>y</math> vengono plottati contro i residui
	della <math>x</math>.  Questo grafico visualizza la relazione
	tra <math>x</math> e <math>y</math>, tenendo conto
	dell'effetto che i controlli hanno su
	entrambe.
      </para>
      <subhead>Scala logaritmica</subhead>
      <para>
	L'opzione <opt>ylogscale</opt> fa sì che l'asse delle ordinate
	sia logaritmico anziché lineare. L'opzione accetta un
	parametro come base. Ad esempio,
      </para>
      <code>
	gnuplot y x --ylogscale=2
      </code>
      <para>
	produce un grafico in cui l'asse delle ordinate è espresso in
	termini di potenze di 2. Se la base è omessa, si userà il
	valore 10.
      </para>
      <subhead>Creare un grafico da una matrice</subhead>
      <para>
	In generale, il comando richiede di specificare sia
	l'argomento <repl>variabili-y</repl> che quello
	<repl>variabile-x</repl> in termini di variabili del dataset
	corrente (per nome o numero identificativo).  Questi argomenti
	diventano tuttavia opzionali se viene impiegata l'opzione
	<opt>matrix</opt> seguita da una matrice definita in
	precedenza: se la matrice specificata ha <math>k</math>
	colonne, di default le prime <math>k</math> &minus; 1 sono
	considerate come <repl>variabili-y</repl>, mentre l'ultima
	come <repl>variabile-x</repl>. Se viene indicata l'opzione
	<opt>time-series</opt>, tuttavia, il comando fornisce il
	grafico di tutte le <math>k</math> variabili rispetto al
	tempo. Se si desidera il grafico di solo alcune colonne,
	allora è necessario identificare <repl>variabili-y</repl> e
	<repl>variabile-x</repl> fornendo l'indice delle colonne
	corrispondenti, dove la prima colonna ha indice 1. Per
	esempio, se si desidera un grafico a dispersione della colonna
	2 della matrice <lit>M</lit> rispetto alla colonna 1, il
	comando da digitare è:
      </para>
      <code>
	gnuplot 2 1 --matrix=M
      </code>
      <subhead>Mostrare una linea interpolante</subhead>
      <para>
	L'opzione <quote>fit</quote> si applica solo al caso di un
	diagramma a dispersione bivariato, o quando il grafico
	contiene un'unica serie storica. Il comportamento predefinito
	consiste nel mostrare la linea con le stime OLS, se il
	coefficiente di pendenza è significativo almeno al 10 per
	cento. Azioni diverse possono essere effettuate usando questa
	opzione con una delle seguenti specificazioni
	<repl>fitspec</repl>. Se il grafico contiene un'unica serie
	storica, <math>x</math> è implicitamente dato dal tempo.
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>linear</lit>: la linea OLS viene mostrata a
	    prescindere dalla sua significatività.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>none</lit>: non mostrare alcuna interpolazione.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>inverse</lit>, <lit>quadratic</lit>,
	    <lit>cubic</lit>, <lit>semilog</lit> o <lit>linlog</lit>:
	    mostrano una linea interpolante basata su una regressione
	    del tipo corrispondente. Per <lit>semilog</lit>, si
	    intende una regressione del logaritmo di <math>y</math> su
	    <math>x</math>; la linea interpolante mostra la media
	    condizionale di <math>y</math>, ottenuta per
	    esponenziazione. Per <lit>linlog</lit>, si intende una
	    regressione di <math>y</math> sul logaritmo di
	    <math>x</math>.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>loess</lit>: usa una regressione robusta ponderata
	    localmente (anche nota come <quote>lowess</quote>).
	  </para>
	</li>
      </ilist>
      <subhead>Bande</subhead>
      <para>
	L'opzione <opt>band</opt> si usa per mostrare una o più serie
	assieme ad una <quote>banda</quote> (spesso, ma non sempre,
	associata ad un intervallo di confidenza). Il modo consigliato
	per definire e personalizzare la banda è tramite un bundle, da
	fornire come parametro dell'opzione.  Il bundle richiede la
	chiave <lit>center</lit> che identifica il nome della serie
	attorno a cui si costruirà la banda, e la chiave
	<lit>width</lit> per il nome della serie rappresentante
	l'ampiezza della banda&mdash; entrambe le chiavi accettano
	stringhe di testo.  Inoltre, quattro elementi opzionali sono
	previsti:
      </para>
      <ilist>
	<li>
	  <para>la chiave <lit>factor</lit>, corrispondente ad uno scalare che
	  moltiplicherà l'ampiezza della banda (default pari ad 1).
	  </para>
	</li>
	<li>
	  <para>la chiave <lit>style</lit>, una stringa di testo per definire come la
	  banda sarà rappresentata. I valori ammessi sono <lit>line</lit>(default),
	  <lit>fill</lit>, <lit>dash</lit>, <lit>bars</lit> or <lit>step</lit>.
	  </para>
	</li>
	<li>
	  <para>la chiave <lit>color</lit> identifica il colore della
	  banda; può essere usata o una stringa riportante la
	  denominazione del colore à la gnuplot o mediante la
	  rappresentazione RGB esadecimale (come stringa o
	  scalare). Di default il colore è scelto automaticamente.
	  </para>
	</li>
	<li>
	  <para>la chiave <lit>title</lit>, è una stringa
	  corrispondente alla denominazione della banda nella legenda
	  del grafico. Di default, le bande non hanno denominazioni.
	  </para>
	</li>
      </ilist>
      <para>
	Di seguito sono riportati due esempi per la personalizzazione
	delle bande, sfruttando in entrambi i casi la sintassi
	<lit>_()</lit> per costruire bundle. La prima implementazione
	è essenziale, mentre nella seconda tutte le opzioni sono
	sfruttate. Assumiamo che <lit>y</lit>, <lit>x</lit> e
	<lit>w</lit> siano serie del dataset in uso.
      </para>
      <code>
	bundle b1 = _(center="x", width="w")
	gnuplot y --time-series --with-lines --band=b1
	bundle b2 = _(center="x", width="w", factor=1.96, style="fill")
	b2.color=0xcccccc
	b2.title = "95% interval"
	gnuplot y --time-series --with-lines --band=b2
      </code>
      <para>
	Se il grafico fosse destinato a contenere due o più bande, il
	flag dell'opzione dovrebbe essere riportato al plurale
	(<lit>bands</lit> anziché <lit>band</lit>) e i relativi
	parametri come <emphasis>array</emphasis> di bundle. Ciò è
	illustrato nel seguente esempio (che richiama quello
	precedente):
        </para>
      <code>
	bundles bb = defarray(b1, b2)
	gnuplot y --time-series --with-lines --bands=bb
      </code>
      <para>
	La sola differenza nel caso di grafici di matrici, anziché di
	serie, concerne la sostituzione di <lit>center</lit> e
	<lit>width</lit> con la chiave <lit>bandmat</lit>. Questa deve
	essere una matrice a due colonne contenente in centro nella
	prima e la larghezza nella seconda. In alternativa, si può
	passare come stringa (e cioè fra virgolette doppie) il nome di
	una matrice già esistente, di contenuto e dimensioni
	opportune. Ciò può essere preferibile quando tale matrice deve
	essere riutilizzata in più di un bundle, per evitare spreco di
	memoria.
      </para>
      <subhead>Barre di recessione</subhead>
      <para>
	L'opzione <quote>band</quote> sopra descritta può inoltre
	essere utilizzata per aggiungere delle barre di recessione al
	grafico. Con ciò si intendono barre verticali che occuperanno
	l'intera dimensione <math>y</math> del grafico ed indicheranno
	la presenza (con barra) o l'assenza (senza barra) di alcune
	caratteristiche qualitative in una serie storica.  Queste
	barre sono comunemente utilizzate per indicare periodi di
	recessione/guerra/qualsiasi cosa codificabile da una variabile
	dummy 0/1.
      </para>
      <para>
	In questo caso, il bundle per la banda ha solo un
	prerequisito, la chiave <lit>dummy</lit>, che ospiterà il nome
	virgolettato di una serie binaria 0/1 (o nel caso di una
	matrice, il nome virgolettato di una specifica colonna). Le
	barre verticali appariranno <quote>sulle</quote> osservazioni
	corrispondenti al valore 1 della serie (o vettore) dummy.  Le
	chiavi <lit>center</lit>, <lit>width</lit>, <lit>factor</lit>
	e <lit>style</lit> sono ininfluenti; <lit>color</lit>, per
	contro, può essere usato. Si noti che solo una di queste
	specificazioni può essere usata per grafico. Un esempio,
      </para>
      <code>
	open AWM17 --quiet
	series dum = obs &gt;= 1990:1 &amp;&amp; obs &lt;= 1994:2
	bundle b = _(dummy="dum", color=0xcccccc)
	gnuplot YER URX --with-lines --time-series \
	  --band=b --output=display {set key top left;}
      </code>
      <subhead>Nomi dei colori</subhead>
      <para>
	I colori sono identificati tramite numeri RGB, solitamente
	espressi in formato esadecimale a 6 cifre: le prime due cifre
	indicano la quantità di rosso (da 0 a 255), quelle centrali la
	quantità di verde e le ultime due la quantità di blu. Ad
	esempio, <lit>0xff0080</lit> ha il massimo del rosso, nessun
	verde e un po' di blu (è un viola rossastro). A partire dalla
	versione 5.2 di gnuplot, è possibile utilizzare quattro cifre
	invece di tre: in questo caso, le prime due cifre indicano la
	trasparenza, che va da 0 (opaco) a 255 (trasparente). Ad
	esempio, <lit>0xc0ff0080</lit> attribuirebbe al colore il
	valore 192 (c0 in esadecimale) per la trasparenza.  È
	possibile verificare la versione di gnuplot in uso esaminando
	il bundle <fncref targ="$sysinfo"/>.
      </para>
      <para>
	I colori esadecimali possono essere passati come scalari o
	come stringhe. Una stringa di colore può essere un numero
	esadecimale tra virgolette (ad esempio "0x191970"), ma gnuplot
	riconosce alcuni colori <quote>abbreviati</quote> (in
	inglese). Ad esempio, <quote>violet</quote> equivale a
	<quote>0xee82ee</quote> e <quote>brown</quote> a
	<quote>0xa52a2a</quote>. È possibile accedere all'elenco
	completo dei nomi dei colori riconosciuti da gnuplot eseguendo
	il comando <quote><lit>show colornames</lit></quote> in
	gnuplot stesso, oppure nella console di gretl digitando:
      </para>
      <code>
	eval readfile("@gretldir/data/gnuplot/gpcolors.txt")
      </code>
      <para>
	Per ottenere un risultato esteticamente gradevole, la funzione
	<fncref targ="rgbmix"/> risulta spesso utile.
      </para>
      <subhead>Controllo dell'output</subhead>
      <para>
	In modalità interattiva il risultato è mostrato
	immediatamente.  In modalità <quote>batch</quote>, quando
	viene eseguito uno script, per default viene scritto un file
	di comandi gnuplot nella directory di lavoro, chiamato
	<filename>gpttmpN.plt</filename>, a partire da N =
	<lit>01</lit>; il grafico vero e proprio può essere generato
	usando il programma <program>gnuplot</program> (su MS Windows:
	<program>wgnuplot</program>).  Alternativamente, usando
	l'opzione <opt>output=</opt><repl>filename</repl>, è possibile
	controllare il nome del file utilizzato e contemporaneamente
	specificare un particolare formato di output usando
	l'estensione del nome del file, come segue:
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>.eps</lit>: Encapsulated PostScript
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.pdf</lit>: PDF
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.png</lit>: PNG (Portable Network Graphics)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.emf</lit>: EMF (Microsoft's Enhanced MetaFile)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.html</lit>: HTML canvas
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.svg</lit>: SVG (Scalable Vector Graphics)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.fig</lit>: Xfig (programma di grafica *nix)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.tex</lit>: pict2e (per uso con &latex;)
	  </para>
	</li>
	<li>
	  <para>
	    <lit>.tikz</lit>: TiKZ (per uso con &latex;).
	  </para>
	</li>
      </ilist>
       <para>
	Se come nome del file si indica
	<quote><lit>display</lit></quote>, il grafico è visualizzato
	su schermo come nella modalità interattiva.  Se si indica un
	nome del file con un'estensione diversa da quelle appena
	citate viene prodotto un file di comandi gnuplot.
      </para>
      <para>
	Un modo alternativo di ridirigere l'output è dato dall'opzione
	<opt>outbuf=</opt><repl>nomestringa</repl>, che salva i
	comandi gnuplot nella stringa specificata, che fa da <quote>buffer</quote>.
	Si noti che le opzioni <opt>output</opt> e <opt>outbuf</opt>
	sono incompatibili.
      </para>
      <subhead>Specificare un font</subhead>
      <para>
	L'opzione <opt>font</opt> può essere utilizzata per
	specificare un particolare tipo di font per il grafico. Il
	parametro <repl>fontspec</repl> dovrebbe corrispondere al nome
	di un carattere, ed opzionalmente dovrebbe essere seguito
	dalla dimensione dello stesso in punti (separati dal nome con
	una virgola od uno spazio, il tutto messo dentro le doppie
	virgolette "").  Di seguito un esempio:
      </para>
      <code>
	--font="serif,12"
      </code>
      <para>
	Nota: i font disponibili per gnuplot variano da piattaforma a
	piattaforma, quindi se si intende scrivere un comando di
	<lit>plot</lit> trasferibile allora è consigliabile optare per
	font generici come <lit>sans</lit> oppure <lit>serif</lit>.
      </para>
      <subhead>Aggiungere comandi gnuplot</subhead>
      <para>
	È disponibile un'ulteriore opzione per questo comando: dopo la
	specificazione delle variabili e le eventuali opzioni, è
	possibile aggiungere direttamente dei comandi gnuplot per
	modificare l'aspetto visivo del grafico (ad esempio,
	impostando il titolo e o gli intervalli degli assi). Questi
	comandi aggiuntivi vanno inclusi tra parentesi graffe e ogni
	comando va separato con un punto e virgola; è possibile usare
	una barra rovesciata (<lit>\</lit>) per continuare un gruppo
	di comandi gnuplot sulla riga successiva. Ecco un esempio
	della sintassi:
      </para>
      <code>
	{ set title 'Titolo personalizzato'; set yrange [0:1000]; }
      </code>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Grafico</menu-path>
      <other-access>Menù pop-up nella finestra principale, pulsante
      grafico sulla barra degli strumenti</other-access>
    </gui-access>

  </command>

  <command name="graphing" section="Graphs" context="gui"
	   label="Grafici">

    <description>
      <para>
	Gretl richiama un programma separato, gnuplot, per generare i
	grafici. Gnuplot è un programma di grafica molto completo, con
	una miriade di opzioni; gretl fornisce l'accesso, attraverso
	un'interfaccia grafica, a una parte di queste opzioni,
	cercando di scegliere dei valori, ma è possibile anche
	controllare l'aspetto di un grafico in tutti i suoi dettagli,
	se si vuole.
      </para>
      <para>
	Mentre un grafico viene visualizzato, facendo clic sulla
	finestra del grafico si aprirà un menù pop-up con le seguenti
	opzioni:
      </para>
      <ilist>
	<li>
	  <para>
	    Salva come PNG: salva in formato Portable Network Graphics
	  </para>
	</li>
	<li>
	  <para>
	    Salva come postscript: salva il grafico in formato encapsulated
	    postscript (EPS)
	  </para>
	</li>
	<li>
	  <para>
	    Salva alla sessione come icona: il grafico apparirà
	    sotto forma di icona quando si seleziona <quote>Visualizza
	    Icone</quote> dal menù Sessione
	  </para>
	</li>
	<li>
	  <para>
	    Ingrandisci: permette di selezionare un'area
	    all'interno del grafico per visualizzarla da vicino
	  </para>
	</li>
	<li>
	  <para>
	    Copia negli appunti: permette di copiare il grafico per
	    poi incollarlo in altri programmi
	  </para>
	</li>
	<li>
	  <para>
	    Modifica: apre una finestra che permette di modificare
	    vari dettagli dell'aspetto del grafico
	  </para>
	</li>
	<li>
	  <para>
	    Chiudi: chiude la finestra del grafico
	  </para>
	</li>
      </ilist>

      <para>
	Se si conosce gnuplot e si desidera un controllo sull'aspetto del
	grafico più preciso di quello fornito dalla finestra di modifica
	del grafico (opzione <quote>Modifica</quote>), ci sono due
	possibilità:
      </para>

      <ilist>
	<li>
	  <para>
	    Una volta salvato il grafico come icona di sessione,
	    facendo clic col tasto destro sull'icona si apre un altro
	    menù pop-up. Una delle opzioni disponibili è
	    <quote>Comandi per modificare il grafico</quote>, che apre
	    una finestra di modifica con i comandi di gnuplot. È
	    possibile modificare questi comandi e salvarli per il
	    futuro, oppure inviarli direttamente a gnuplot (usando
	    l'icona "esegui" della finestra di modifica dei comandi).
	  </para>
	</li>
      </ilist>

      <para>
	Per saperne di più su gnuplot, si veda <url>http://www.gnuplot.info</url>
      </para>
    </description>

  </command>

  <command name="graphpg" section="Graphs" label="Pagina dei grafici">

    <usage>
      <altforms>
	<altform><lit>graphpg add</lit></altform>
	<altform><lit>graphpg fontscale </lit><repl>value</repl></altform>
	<altform><lit>graphpg show</lit></altform>
	<altform><lit>graphpg free</lit></altform>
	<altform><lit>graphpg --output=</lit><repl>filename</repl></altform>
      </altforms>
    </usage>

    <description>
      <para>
	La <quote>pagina dei grafici</quote> funzionerà solo se
	si è installato il sistema di composizione &latex; e si è
	in grado di generare e visualizzare file in formato postscript.
      </para>
      <para>
	Nella finestra della sessione, è possibile trascinare fino
	a otto grafici sull'icona della pagina dei grafici. Facendo doppio
	clic sull'icona della pagina dei grafici (o facendo clic col tasto
	destro e selezionando <quote>Mostra</quote>), la pagina contenente
	i grafici selezionati verrà composta e aperta con il proprio
	visualizzatore di file postscript, da cui sarà possibile stamparla.
      </para>
      <para>
	Per pulire la pagina dei grafici, fare clic col tasto destro
	sull'icona e selezionare <quote>Pulisci</quote>.
      </para>
      <para>
	Su sistemi diversi da MS Windows, può essere necessario modificare
	l'impostazione del programma per visualizzare il postscript, che si
	trova nella sezione <quote>Programmi</quote> della finestra di dialogo
	delle Preferenze di gretl (nel menù Strumenti della finestra principale).
      </para>
      <para>
	È anche possibile operare sulla pagina del grafico via script,
	oppure usando la console (nel programma GUI). Sono disponibili
	i comandi seguenti:
      </para>
      <para>
	Per aggiungere un grafico alla pagina dei grafici, digitate il comando
	<lit>graphpg add</lit> dopo aver salvato un grafico con un
	nome, come in
      </para>
      <code>
	grf1 &lt;- gnuplot Y X
	graphpg add
      </code>
      <para>
	Per aprire la pagina dei grafici: <lit>graphpg show</lit>.
      </para>
      <para>
	Per svuotare la pagina dei grafici: <lit>graphpg free</lit>.
      </para>
      <para>
	Per modificare la dimensione del font usato nella pagina dei grafici usate
	<lit>graphpg fontscale</lit> <repl>scale</repl>, dove
	<repl>scale</repl> è un moltiplicatore (con un valore di default pari a 1.0).
	Per rendere il fonto più grande del 50 per cento, dunque,
	è possibile scrivere
      </para>
      <code>
	graphpg fontscale 1.5
      </code>
      <para>
	Per stampare su un file la pagina dei grafici usate l'opzione
	<opt>output=</opt> seguita dal nome di un file; questo nome deve avere
	il suffisso <quote><lit>.pdf</lit></quote>,
	<quote><lit>.ps</lit></quote> o
	<quote><lit>.eps</lit></quote>. Per esempio:
      </para>
      <code>
	graphpg --output="myfile.pdf"
      </code>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo.
      </para>
      <para>
	In questo contesto l'output usa linee colorate di default; per usare
	linee punteggiate o tratteggiate al posto dei colori è possibile aggiungere
	l'opzione <opt>monochrome</opt>.
      </para>
    </description>

  </command>

  <command name="gretl_edit" section="Utilities" context="gui"
    label="gretl_edit">

    <description>
      <para>
	gretl_edit è una variante leggera del client grafico di
	gretl. Essa comprende un editor per gli script (anche più
	d'uno, via dei tab) e la possibilità di eseguirli e
	visualizzare il loro output. Molte delle caratteristiche
	dell'interfaccia standard di gretl sono assenti, ma questa
	variante può rivelarsi utile grazie al principio che, a volte,
	<quote>piccolo è bello</quote>.
      </para>
      <para>
	Il contesto per cui gretl_edit è progettato è più o meno il
	seguente: mettiamo di star lavoando su del codice
	relativamente complesso, usando questa sequenza di operazioni.
      </para>
      <code>
	scrivo del codice
	lo eseguo, guardo i risultati, controlle se ci sono errori
	correggo il codice
	lo rieseguo di nuovo...
      </code>
      <para>
	Se questo descrive ciò che fate, almeno a volte, date
	un'occhiata a gretl_edit. Se no, potete tranquillamente
	ignorarne l'esistenza.
      </para>
      <para>
	Si noti che gretl_edit è <quote>privo di
	stato</quote>. Contrariamente all'applicazione principale, non
	ci sono modelli, serie, matrici, bundle eccetera. L'unica cosa
	che c'è in memoria è lo script, o gli script, editati. Nel
	contesto descritto sopra, è tutto quel che serve: ogni volta
	che uno script viene eseguito, riparte <quote>da zero</quote>,
	per così dire. Quindi, se lo script usa un dataset, deve
	includere un comando per aprirlo.
      </para>
      <para>
	Ovviamente, gretl_edit gestisce hansl, il linguaggio di
	gretl. Tuttovia, può anche gestire linguaggi coperti da gretl
	attraverso il comando <quote>foreign</quote>: R, Octave,
	Julia, Ox, Stata. In questi casi, l'editor non ha tutte le
	potenzialità che in hansl: la colorazione della sintassi è
	prevista, ma non l'indentazione automatica o
	l'autocompletamento.
      </para>
    </description>
  </command>

  <command name="gridplot" section="Graphs" context="cli">
    <usage>
      <arguments>
        <argument>plotspecs</argument>
      </arguments>
      <options>
	<option>
	  <flag>--fontsize</flag>
	  <optparm>fs</optparm>
	  <effect>dimensione del font in punti [10]</effect>
	</option>
	<option>
	  <flag>--width</flag>
	  <optparm>w</optparm>
	  <effect>larghezza in pixel [800]</effect>
	</option>
	<option>
	  <flag>--height</flag>
	  <optparm>h</optparm>
	  <effect>altezza in pixel [600]</effect>
	</option>
	<option>
	  <flag>--rows</flag>
	  <optparm>r</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--cols</flag>
	  <optparm>c</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--layout</flag>
	  <optparm>lmat</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--output</flag>
	  <optparm>destination</optparm>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--outbuf</flag>
	  <optparm>alternative destination</optparm>
	  <effect>vedi sotto</effect>
	</option>
      </options>
      <examples>
        <example>gridplot myspecs --rows=3 --output=display</example>
        <example>gridplot myspecs --layout=lmat --output=composite.pdf</example>
      </examples>
    </usage>
    <description>
      <para>
	Questo comando prende due o più specifiche per grafici e le
	dispone in una griglia. L'unico argomento richiesto,
	<repl>plotspecs</repl>, è un array di stringhe, ciascuna delle
	quali specifica un grafico. Il comando complementare <cmdref
	targ="gpbuild"/> offre un modo semplice per creare un array di
	questo tipo.
      </para>
      <subhead>Specifica della griglia</subhead>
      <para>
	La forma della griglia può essere impostata da una delle tre
	opzioni (reciprocamente incompatibili) <opt>rows</opt>,
	<opt>cols</opt> e <opt>layout</opt>. Se nessuna opzione viene
	fornita, il numero di righe viene impostato sulla radice
	quadrata del numero di grafici (la dimensione dell'array di
	input), arrotondato per eccesso all'intero più vicino se
	necessario. Quindi il numero di colonne viene impostato sul
	numero di grafici diviso per il numero di righe, nuovamente
	arrotondato se necessario. I grafici vengono posizionati nella
	griglia per riga, nell'ordine in cui sono disposti. Se viene
	fornita l'opzione <opt>rows</opt>, questa prende il posto
	dell'impostazione automatica, ma il numero di colonne viene
	impostato automaticamente come descritto sopra. Se invece
	viene fornita l'opzione<opt>cols</opt>, il numero di righe
	viene impostato automaticamente.
      </para>
      <para>
	L'opzione <opt>layout</opt>, che richiede come parametro una
	matrice, offre un'alternativa più flessibile. La matrice
	specifica il layout della griglia in questo modo: gli elementi
	0 richiedono celle vuote nella griglia e gli elementi interi
	da 1 a <math>n</math> si riferiscono ai singoli grafici nel
	loro ordine nell'array. Quindi, ad esempio,
      </para>
      <code>
	matrix m = {1,0,0; 2,3,0; 4,5,6}
	gridplot ... --layout=m ...
      </code>
      <para>
	imposta sei grafici in un triangolo basso su una griglia <by
	r="3" c="3"/>. Con questa opzione alcuni grafici possono
	essere omessi o ripetuti.
      </para>
      <subhead>Opzioni di output</subhead>
      <para>
	L'opzione <opt>output</opt> può essere utilizzata per
	specificare <lit>display</lit> (mostrare immediatamente il
	grafico) o il nome di un file di output. In alternativa
	<opt>outbuf</opt> può essere utilizzato per indirizzare
	l'output, sotto forma di buffer di comandi gnuplot, a una
	stringa con nome. In assenza di queste opzioni l'output è un
	file di comandi gnuplot denominato automaticamente. Vedi
	<cmdref targ="gnuplot"/> per maggiori dettagli.
      </para>
    </description>
  </command>

  <command name="gpbuild" section="Graphs" context="cli">
    <usage>
      <arguments>
	<argument>plotspecs</argument>
      </arguments>
      <examples>
        <example>gpbuild MyPlots</example>
      </examples>
    </usage>
    <description>
      <para>
	Questo comando avvia un blocco in cui qualsiasi chiamata a
	comandi o funzioni che producono grafici viene trattata in
	modo speciale, al fine di produrre un array di stringhe di
	specifiche della trama da utilizzare con <cmdref
	targ="gridplot"/>: l'argomento <repl>plotspecs</repl> indica
	il nome di questo array. Tale blocco viene terminato dal
	comando <quote><lit>end gpbuild</lit></quote>
      </para>
      <subhead>Due restrizioni</subhead>
      <para>
	All'interno di un blocco <lit>gpbuild</lit> solo i comandi che
	producono grafici ricevono un trattamento speciale; tutti gli
	altri comandi vengono eseguiti normalmente. Ci sono solo due
	restrizioni di cui tener conto. 
      </para>
      <ilist>
	<li>
	  <para>
	    Innanzitutto, tali comandi <emphasis>non</emphasis> devono
	    includere una specifica di output in questo contesto
	    poiché ciò entrerebbe in conflitto con la ridirezione
	    automatica dell'output all'array
	    <repl>plotspecs</repl>. Fa eccezione a questa regola
	    l'opzione <lit>--output=display</lit> (molto usata come
	    default nei pacchetti di funzioni che producono grafici);
	    questa direttiva non dà luogo a un errore, ma viene
	    semplicemente ignorata in favore del trattamento
	    automatico.
	  </para>
	</li>
	<li>
	  <para>
	    In secondo luogo, i grafici che invocano la direttiva
	    <quote><lit>multiplot</lit></quote> di gnuplot non sono
	    compatibili con <lit>gpbuild</lit>. Questo perché
	    <lit>gridplot</lit> utilizza <lit>multiplot</lit>
	    internamente e questi costrutti non possono essere
	    annidati.
	  </para>
	</li>
      </ilist>
      <subhead>Alternativa manuale</subhead>
      <para>
	È possibile preparare un array di grafici per uso con
	<lit>gridplot</lit> senza per forza usare un blocco
	<lit>gpbuild</lit>, come nell'esempio seguente:
      </para>
      <code>
	open data4-10
	strings MyPlots = array(3)
	gnuplot ENROLL CATHOL --outbuf=MyPlots[1]
	gnuplot ENROLL INCOME --outbuf=MyPlots[2]
	gnuplot ENROLL COLLEGE --outbuf=MyPlots[3]
      </code>
      <para>
	Il codice sopra è essenmzialmente equivalente a
      </para>
      <code>
	open data4-10
	gpbuild MyPlots
	   gnuplot ENROLL CATHOL
	   gnuplot ENROLL INCOME
	   gnuplot ENROLL COLLEGE
	end gpbuild
      </code>
    </description>
  </command>
  
  <command name="3-D" section="Graphs" context="gui"
	   label="Grafici tridimensionali">

    <description>
      <para>
	Se il bottone <quote>Rendi il grafico interattivo</quote> è
	disponibili e selezionato quest'ultimo consentirà di manipolare
	il grafico 3-D con il mouse (ruotandolo, espandendolo e rimpicciolendolo
	lungo gli assi).
      </para>
      <para>
	Nella composizione di un grafico 3D, si noti che l'asse Z
	sarà l'asse verticale, quindi se si ha una variabile dipendente
	che si pensa possa essere influenzata da due variabili indipendenti,
	è meglio mettere la variabile dipendente sull'asse Z e le altre
	due variabili sugli assi X e Y.
      </para>
      <para>
	A differenza di molti altri grafici di gretl, i grafici 3D
	interattivi sono controllati da gnuplot invece che da gretl,
	quindi il menu di modifica dei grafici in questo caso non è
	disponibile. Per vedere il codice gnuplot che produce il
	grafico, togliere la spunta alla casella "Rendi il grafico
	interattivo". A quel punto il grafico può essere salvato come
	icona, e aprendo la finestra delle icone si potrà usare il
	pulsante destro sull'icona del grafico per vedere i comandi.
      </para>
    </description>
  </command>

  <command name="gui-funcs" section="Programming"
	   label="Special functions" context="gui">
    <description>
      <para>
	Questo comando permette di specificare se ad alcune delle
	funzioni di un pacchetto devono essere attribuiti alcuni
	compiti specifici, e se sì a quali. Si noti che a una data
	funzione può essere attribuito al massimo uno dei compiti
	seguenti, e che per poter essere candidata a uno di questi
	compiti la funzione deve soddisfare alcuni criteri.
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>bundle-print</lit>: stampa l'output sulla base del contenuto
	    di un bundle di risultati generati dal vostro pacchetto. Criteri:
	    questa funzione deve avere come primo parametro un puntatore
	    del bundle. Se presente, il secondo parametro deve assumere valori
	    interi, ed è necessario che ne sia specificato uno di default.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>bundle-plot</lit>: produce uno o più grafici usando un bundle
	    generato dal vostro pacchetto. Criteri: come per
	  <lit>bundle-print</lit>.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>bundle-test</lit>: calcola qualche test statistico
	    usando un bundle generato dal vostro pacchetto. Criteri:
	  come per <lit>bundle-print</lit>.
	  </para>
	</li>
	<li>
	  <para>
	    <lit>gui-main</lit>: l'interfaccia pubblica che per default dovrebbe
	    essere offerta agli utenti in modalità GUI. Questa opzione è utile
	    solo se il pacchetto può offrire più di un'interfaccia pubblica.
	    </para>
	    </li>
	    <li>
	      <para>
		<lit>gui-precheck</lit>: funzione di controllo che restituisce 0 se
		le funzionalità del vostro pacchetto possono essere applicate
		al contesto corrente, e un valore diverso da 0 in caso contrario.
		Questa opzione serve per i pacchetti che svolgono qualche operazione
		a partire da un modello, in modo da evitare i tipi di modelli
		non gestibili dal pacchetto.
	    </para>
	    </li>
	    </ilist>
	    <para>
	      In aggiunta alcune funzioni possono essere marcate con
	      l'opzione <quote>no-print</quote>. Solitamente, quando
	      una funzione è richiamata attraverso l'interfaccia
	      grafica gretl apre un finestra la quale mostra il suo
	      successivo output; selezionando questa opzione si dice a
	      gretl di non farlo. In conclusione nessun output di
	      testo verrà prodotto da gretl se l'opzione
	      <quote>no-print</quote> è stata selezionata.
	  </para>
	  <para>
	    Infine, la funzione <lit>gui-main</lit> (se presente) può
	    essere contrassegnata come <quote>menu-only</quote>. Così
	    facendo si dice a gretl che la funzione in questione è
	    specificamente progettata ad essere chiamata
	    dall'interfaccia grafica del menu al quale è allegata, e
	    che non dovrebbe essere presentata all'utente in
	    nessun'altra forma.
	  </para>
    </description>
  </command>

  <command name="gui-htest" section="Tests" context="gui"
	   label="Calcolatore per le statistiche test">
    
    <description>
      <para>
	Il calcolatore dei test di Gretl calcola statistiche test e
	p-value per molti tipi di test di ipotesi su una o due
	popolazioni.  Per utilizzarlo, occorre indicare le statistiche
	campionarie derivate da uno o due campioni, a seconda del test
	scelto. Queste possono essere indicate esplicitamente in forma
	numerica, oppure, se si ha un file di dati aperto, è possibile
	far calcolare a gretl le statistiche test per una o più
	variabili selezionate dal dataset (nel caso delle medie e
	varianze, ma non nel caso delle proporzioni).
      </para>
      <para>
	Per eseguire un test indicando una variabile del dataset,
	occorre per prima cosa attivare questa opzione selezionando la
	casella <quote>Usa variabile dal dataset</quote>, e poi
	scegliere la variabile nella lista.  Appena si sceglie una
	variabile, i valori delle statistiche rilevanti sono
	automaticamente inseriti nelle caselle sottostanti.
      </para>
      <para>
	Si noti che nel caso di due campioni i test sono di tipo non
	appaiato. Se, ad esempio, si vuole eseguire un test
	<emphasis>appaiato</emphasis> per verificare se la differenza
	delle medie di due variabili è zero, basta creare una nuova
	serie come differenza delle due esistenti, quindi eseguire un
	semplice test della media su quella nuova serie.
      </para>
      <para>
	Oltre che selezionare semplicemente una variabile, è possibile
	specificare un sotto-campione. Ad esempio, si ipotizzi di avere
	dei dati sui salari in una variabile chiamata <lit>wage</lit> e
	una variabile dummy chiamata <lit>gender</lit>, pari a 1 per i
	maschi e 0 per le femmine (o viceversa). Quindi, nel test per la
	differenza fra le medie, è possibile selezionare <lit>wage</lit>
	in entrambi i campi, ma aggiungendo nel campo superiore
	<lit>(gender==0)</lit> e nel campo inferiore
	<lit>(gender==1)</lit> si otterrà un test per la differenza tra
	il reddito medio degli uomini e delle donne. Quando si specifica
	un vincolo che identifica un sotto-campione, occorre premere il
	tasto Invio perché le statistiche campionarie siano calcolate.
      </para>
      <para>
	Il vincolo che definisce il sotto-campione deve essere indicato tra
	parentesi e in generale prende la forma "variabile operatore
	valore", come in
      </para>
      <code>
	var2 op val
      </code>
      <para>
	dove <lit>var2</lit> è il nome di una variabile nel dataset
	attuale, <lit>val</lit> è un valore numerico e <lit>val</lit>
	è un operatore di confronto, da scegliere tra
      </para>
      <code>
	==  !=   &lt;  &gt;  &lt;  &gt;
      </code>
      <para>
	(rispettivamente: uguale, diverso, minore, maggiore, minore o
	uguale, maggiore o uguale). Gli spazi prima e dopo
	l'operatore sono opzionali.
      </para>
    </description>
  </command>

  <command name="gui-htest-np" section="Tests" context="gui"
           label="Test non parametrici">
    
    <description>
      <para>
        Tre tipologie di test non parametrici sono disponibili
        tramite questa finestra di dialogo: test delle differenze
        tra gruppi, per la casualità e per la correlazione (o il rango).
      </para>
      <subhead>Test delle differenze</subhead>
      <para>
        Nella finestra <quote>Test delle differenze</quote> è possibile svolgere
        dei test non parametrici per la differenza tra due popolazioni o gruppi,
        ed è possibile scegliere vari tipi specifici di test:
      </para>
      <ilist>
        <li>
          <para>
            <emphasis>Test del segno</emphasis>: si basa sul fatto che per due campioni
            <math>x</math> e <math>y</math> estratti casualmente dalla
            stessa distribuzione, la probabilità che valga
            <math>x</math><sub>i</sub> &gt;
            <math>y</math><sub>i</sub> per ogni osservazione
            <math>i</math> dovrebbe valere 0.5. La statistica test è
            <math>w</math>, ossia il numero di osservazioni per cui vale
            <math>x</math><sub>i</sub> &gt;
            <math>y</math><sub>i</sub>. Sotto l'ipotesi nulla, questa
            grandezza si distribuisce come una binomiale con parametri
            (<math>n</math>, 0.5), dove <math>n</math> è il numero di
            osservazioni.
          </para>
        </li>
        <li>
          <para>
            <emphasis>Test rank sum di Wilcoxon</emphasis>: questo test
            procede ordinando le osservazioni estratte da entrambi i
            campioni dalla più piccola alla più grande, e quindi
            calcolando la somma dei ranghi delle osservazioni da uno dei
            campioni. I due campioni non devono necessariamente avere la
            stessa dimensione: se sono diversi, viene usato il campione
            più piccolo per calcolare la somma dei ranghi. Sotto
            l'ipotesi nulla che i campioni siano estratti da popolazioni
            con la stessa mediana, la distribuzione di probabilità della
            somma dei ranghi può essere calcolata per ogni valore
            dell'ampiezza dei due campioni, mentre per campioni
            abbastanza ampi essa approssima la distribuzione normale.
          </para>
        </li>
        <li>
          <para>
            <emphasis>Test signed rank di Wilcoxon</emphasis>: questo
            test è valido per "coppie di campioni", come possono
            essere ad esempio i valori di una variabile in un gruppo
            di individui prima e dopo un certo trattamento. Il test
            procede calcolando le differenze tra le coppie di
            osservazioni <math>x</math><sub>i</sub> &minus;
            <math>y</math><sub>i</sub>, ordinando queste differenze
            per valore assoluto e assegnando ad ogni coppia un valore
            di rango con segno, in cui il segno rispecchia il segno
            della differenza. Quindi viene calcolato
            <math>W</math><sub>+</sub>, la somma di tutti i ranghi con
            segno positivo. Come avviene per il test rank-sum, questa
            statistica ha una distribuzione precisa nell'ipotesi nulla
            che la differenza mediana sia zero, distribuzione che
            converte alla normale nel caso di campioni abbastanza
            ampi.
          </para>
        </li>
      </ilist>
      <subhead>Casualità</subhead>
      <para>
	Nella finestra <quote>Test delle successioni</quote> è
	possibile eseguire un test per la casualità di una certa
	variabile, basato sul numero di successioni di valori
	consecutivi positivi o negativi.  Con l'opzione <quote>Usa la
	differenza prima</quote>, la variabile viene differenziata
	prima dell'analisi, quindi le successioni sono interpretabili
	come sequenze di incrementi o decrementi consecutivi nel
	valore della variabile. La statistica test è basata su
	un'approssimazione normale alla distribuzione del numero di
	sequenze sotto l'ipotesi nulla di casualità.
      </para>
      <subhead>Correlazione</subhead>
      <para>
	Nella finestra <quote>Correlazione</quote> si ha a disposione il test per il
	rango della correlazione rho di Spearman e tau di Kendall.
      </para>
    </description>
  </command>

  <command name="hccme" section="Estimation" context="gui"
           label="Errori standard robusti">

    <description>
      <para>
	Sono disponibili vari modi di calcolare gli errori standard
	robusti in presenza di eteroschedasticità (e, nel caso dello
	stimatore HAC, di autocorrelazione).
</para>
<para>
  HC0 produce gli <quote>errori standard originali di
  White</quote>; HC1, HC2, HC3 e HC3a sono varianti che si ritiene
      producano risultati migliori (più affidabili). Per i dettagli
      sugli stimatori, si veda <cite key="mackinnon-white85">MacKinnon
      e White (Journal of Econometrics, 1985)</cite> o <cite
      key="davidson-mackinnon04">Davidson e MacKinnon, Econometric
      Theory and Methods (Oxford, 2004)</cite>. Le sigle usate sono
      quelle proposte da Davidson e MacKinnon. La variante
      <quote>HC3a</quote> è il <quote>jackknife</quote> descritto da
      MacKinnon e White (1985); HC3 è una sua vicina approssimazione.
    </para>
    <para>
      Se si usa lo stimatore HAC per serie storiche, è possibile calibrare
      la lunghezza dei ritardi usando il comando <cmd>set</cmd>. Si veda il
      manuale di gretl o i file di aiuto per i dettagli.
    </para>
    <para>
      Quando si stima un  modello OLS su dati panel, lo stimatore robusto
      predefinito per la matrice di covarianza è quello dato da Arellano.
      L'alternativa è lo stimatore PCSE (Panel Corrected Standard Errors) di
      Beck e Katz, che tiene conto dell'eteroschedasticità, ma non
      dell'autocorrelazione.
    </para>
    <para>
      Per i modelli GARCH sono disponibili due stimatori robusti della
      matrice di covarianza: QML è lo stimatore di quasi massima verosimiglianza,
      e BW è lo stimatore di Bollerslev-Wooldridge.
    </para>
    <para>
      Di default gretl utilizza la distribuzione <math>t</math> di
      Student quando calcola i p-value basati su errori standard
      robusti, in un contesto di stimatori dei minimi
      quadrati. L'opzione denomionata <quote>Usa la distribuzione
      normale per p-value robusti</quote> può essere utilizzata in
      alternativa al metodo predefinito.
    </para>
  </description>

</command>

<command name="heckit" section="Estimation" context="cli"
         label="Modello di selezione di Heckman">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
      <argument separated="true">equazione di selezione</argument>
    </arguments>
    <options>
      <option>
        <flag>--quiet</flag>
        <effect>non mostra i risultati</effect>
      </option>
      <option>
        <flag>--two-step</flag>
        <effect>esegue la stima in due passi</effect>
      </option>
      <option>
        <flag>--vcv</flag>
        <effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
        <flag>--opg</flag>
        <effect>errori standard OPG</effect>
      </option>
      <option>
        <flag>--robust</flag>
        <effect>errori standard QML</effect>
      </option>
      <option>
        <flag>--cluster</flag>
        <optparm>clustvar</optparm>
        <effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>mostra risultati aggiuntivi</effect>
      </option>
    </options>
    <examples>
      <example>heckit y 0 x1 x2 ; ys 0 x3 x4</example>
      <demos>
        <demo>heckit.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Modello di selezione di tipo Heckman. Nella specificazione, la lista che
      precede il punto e virgola rappresenta l'equazione principale, mentre la
      seconda lista rappresenta l'equazione di selezione. La variabile
      dipendente nell'equazione di selezione (<lit>ys</lit>
      nell'esempio visto sopra) deve essere una variabile binaria.
    </para>

    <para>
      Per impostazione predefinita, i parametri sono stimati per massima
      verosimiglianza. La matrice di covarianza dei parametri è calcolata
      usando l'inversa negativa dell'Hessiana. Se si vuole usare la procedura
      di stima in due passi, basta usare l'opzione <opt>two-step</opt>.
      In questo caso, la matrice di covarianza dei parametri dell'equazione
      principale è corretta nel modo descritto da <cite key="heckman79">Heckman (1979)</cite>.
    </para>

  </description>

  <gui-access>
    <menu-path>/Modello/Variabile dipendente limitata/Heckit</menu-path>
  </gui-access>

</command>

<command name="help" section="Utilities" label="Aiuto sui comandi" context="cli">

  <usage>
    <altforms>
      <altform><lit>help</lit></altform>
      <altform><lit>help functions</lit></altform>
      <altform><lit>help</lit> <repl>comando</repl></altform>
      <altform><lit>help</lit> <repl>funzione</repl></altform>
    </altforms>
    <options>
      <option>
        <flag>--func</flag>
        <effect>sceglie l'aiuto sulle funzioni</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Se non vengono indicati argomenti, mostra un elenco dei comandi disponibili.
      Indicando l'argomento <lit quote="true">functions</lit>, mostra un
      elenco delle funzioni disponibili (si veda <cmdref targ="genr"/>).
    </para>
    <para>
      <cmd>help</cmd> <repl>comando</repl> descrive il <repl>comando</repl>
      (ad es.  <cmd>help smpl</cmd>). <lit>help</lit> <repl>funzione</repl>
      descrive la <repl>funzione</repl> (&eg; <lit>help ldet</lit>).
      Alcune funzioni hanno lo stesso nome dei comandi relativi (&eg;
      <lit>diff</lit>): in questo caso verrà mostrato l'aiuto relativo al
      comando, a meno che non si usi l'opzione <opt>func</opt>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Aiuto</menu-path>
  </gui-access>

</command>

<command name="hfplot" section="Graphs"
         label="Crea un grafico MIDAS" context="cli">

  <usage>
    <arguments>
      <argument>hflist</argument>
      <argument optional="true" separated="true">lflist</argument>
    </arguments>
    <options>
      <option>
	<flag>--with-lines</flag>
	<effect>crea grafico lineare</effect>
      </option>
      <option>
	<flag>--time-series</flag>
	<effect>tempo in ascissa</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>filename</optparm>
	<effect>manda l'output al file specificato</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Consente di creare un grafico di una serie ad alta frequenza,
      anche assieme ad una o più serie osservate alla frequenza base
      del dataset.  Il primo argomento dev'essere una <cmdref
      targ="MIDAS_list"/>; gli argomenti aggiuntivi opzionali
      <repl>lflist</repl>, separati da un punto e virgola, devono
      essere normali serie a bassa frequenza.
    </para>
    <para>
      Per ulteriori dettagli sull'effetto dell'opzione <opt>output</opt>,
      consultare lo help per il comando <cmdref targ="gnuplot"/>.
    </para>
  </description>

</command>

<command name="hsk" section="Estimation"
         label="Stime corrette per l'eteroschedasticità">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--no-squares</flag>
	<effect>si veda sotto</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa nulla</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Questo comando è utile in presenza di eteroschedasticità sotto forma di
      una funzione incognita dei regressori, che può essere approssimata da
      una relazione quadratica. In questo contesto, offre la possibilità di
      avere errori standard consistenti e stime dei parametri più efficienti,
      rispetto alla stima OLS.
    </para>
    <para>
      La procedura richiede: (a) la stima OLS del modello, (b) una regressione
      ausiliaria per generare la stima della varianza dell'errore e (c) la
      stima con minimi quadrati ponderati, usando come peso il reciproco della
      varianza stimata.
    </para>
    <para>
      Nella regressione ausiliaria (b) il logaritmo dei quadrati dei residui
      dalla prima regressione OLS viene regredito sui regressori originali e
      sui loro quadrati (o solamente sui regressori originali se l'opzione <opt>no-squares</opt>
      è data). La trasformazione logaritmica viene effettuata per
      assicurarsi che le varianze stimate siano non negative. Indicando con
      <math>u</math><sup>*</sup> i valori stimati da questa regressione, la
      serie dei pesi per la regressione con minimi quadrati ponderati è data
      da 1/exp(<math>u</math><sup>*</sup>).
    </para>
    <para context="gui">
      Nella regressione ausiliaria (b) il logaritmo dei quadrati dei
      residui dalla prima regressione OLS viene regredito sui
      regressori originali e sui loro quadrati (di default), o
      solamente sui regressori originali qualora la casella
      <quote>include squares</quote> sia stata deselezionata.  La
      trasformazione logaritmica viene effettuata per assicurarsi
      che le varianze stimate siano non negative. Indicando con
      <math>u</math><sup>*</sup> i valori stimati da questa
      regressione, la serie dei pesi per la regressione con minimi
      quadrati ponderati è data da
      1/exp(<math>u</math><sup>*</sup>).
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Altri modelli lineari/HSK - WLS corretti per eteroschedasticità</menu-path>
  </gui-access>

</command>

<command name="hurst" section="Statistics"
         label="Esponente di Hurst">

  <usage>
    <arguments>
      <argument>nome-variabile</argument>
    </arguments>
    <options>
      <option>
	<flag>--plot</flag>
	<optparm>tipologia o nome del file</optparm>
	<effect>si veda sotto</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Calcola l'esponente di Hurst (una misura di persistenza, o di memoria
      lunga) per una serie storica con almeno 128 osservazioni.
    </para>

    <para>
      L'esponente di Hurst è discusso da <cite key="mandelbrot83">Mandelbrot (1983)</cite>.
      In termini teorici è l'esponente <math>H</math> nella relazione
      <equation status="display"
		tex="\[\mathrm{RS}(x) = an^H\]"
		ascii="RS(x) = an^H"
		graphic="hurst"/>dove RS è l'<quote>intervallo riscalato</quote>
      della variabile <math>x</math> in un campione dell'ampiezza
      <math>n</math>, mentre <math>a</math> è una
      costante. L'intervallo riscalato è l'intervallo (valore massimo
      meno valore minimo) del valore cumulato, o somma parziale, di
      <math>x</math> sul periodo del campione (dopo aver sottratto la
      media campionaria), diviso per lo scarto quadratico medio campionario.
    </para>

    <para>
      Come punto di riferimento, se <math>x</math> è un rumore bianco
      (media zero, persistenza zero) l'intervallo dei suoi valori cumulati
      (che forma una passeggiata casuale), scalato per lo scarto quadratico medio,
      cresce come la radice quadrata dell'ampiezza campionaria, ossia ha un
      esponente di Hurst atteso pari a 0.5. Valori dell'esponente sensibilmente
      maggiori di 0.5 indicano persistenza della serie, mentre valori minori di
      0.5 indicano anti-persistenza (autocorrelazione negativa). In teoria
      l'esponente deve essere compreso tra 0 e 1, ma in campioni finiti è
      possibile ottenere delle stime per l'esponente maggiori di 1.
    </para>

    <para>
      In gretl, l'esponente è stimato usando il sotto-campionamento binario:
      si inizia dall'intero intervallo dei dati, quindi si usano le due metà
      dell'intervallo, poi i quattro quarti, e così via. Per ampiezze campionarie
      minori dell'intervallo dei dati complessivo il valore RS è la
      media presa sui vari campioni. L'esponente è quindi stimato come il
      coefficiente di pendenza della regressione del logaritmo di RS sul
      logaritmo dell'ampiezza del campione.
    </para>
    <para>
      Di default, viene mostrato un grafico dell'intervallo
      riscalato se il programma è in modalità interattiva. Questo
      comportamento può essere calibrato attraverso l'opzione
      <opt>plot</opt>. I parametri accettabili dall'opzione sono
      <lit>none</lit>, per non mostrare il grafico,
      <lit>display</lit>, per mostrare il grafico anche in batch
      mode, o un nome di file. L'effetto di fornire un nome di file
      è reperibile alla descrizione del comando <cmdref
      targ="gnuplot"/>, sotto l'opzione <opt>output</opt>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Variabile/Esponente di Hurst</menu-path>
  </gui-access>

</command>

<command name="if" section="Programming" label="Strutture di controllo" context="cli">

  <description>
    <para>
      Struttura di controllo per l'esecuzione dei comandi. Sono supportate le
      tre forme seguenti:
    </para>
    <code>
      # forma semplice
      if condition
      commands
      endif

      # a due rami
      if condition
      commands1
      else
      commands2
      endif

      # a tre o più rami
      if condition1
      commands1
      elif condition2
      commands2
      else
      commands3
      endif
    </code>
    <para>
      La <repl quote="true">condizione</repl> deve essere un'espressione
      Booleana, per la cui sintassi si veda <cmdref targ="genr"/>.
      Può essere incluso più di un blocco <cmd>elif</cmd>.
      Inoltre, i blocchi <lit>if</lit> &hellip; <lit>endif</lit>
      possono essere nidificati.
    </para>

  </description>

</command>

<command name="include" section="Programming" label="Include definizioni di
                                                     funzioni" context="cli">

  <usage>
    <arguments>
<argument>filename</argument>
</arguments>
<options>
  <option>
<flag>--force</flag>
<effect>forza una rilettura dal file</effect>
</option>
</options>
<examples>
<example>include myfile.inp</example>
<example>include sols.gfn</example>
</examples>
</usage>

<description>
  <para>
    Da usare in uno script di comandi, principalmente per includere
    definizioni di funzioni. Il comando <repl>filename</repl> dovrebbe
    includere l'estensione <lit>inp</lit> (un script di testo semplice)
    oppure l'estensione <lit>gfn</lit> (una pacchetto di funzioni gretl).
    I comandi del <repl>filename</repl> vengono eseguiti e il controllo viene
    restituito allo script principale.
</para>
<para>
  L'opzione <opt>force</opt> è specifica dei file di tipo
  <lit>gfn</lit>: quest'ultima ha come effetto quello di forzare
  gretl a rileggere il pacchetto di funzioni anche se quest'ultimo
  è già stato caricato in memoria.  (In risposta a questo comando,
  gli script di testo semplici <lit>inp</lit> sono sempre
  ricaricati.)
</para>
<para>
  Si veda anche il comando <cmdref targ="run"/>.
</para>
</description>

</command>


<command name="info" section="Dataset" label="Informazioni sul dataset" context="cli">
    <usage>
      <altforms>
	<altform><lit>info</lit></altform>
	<altform><lit>info --to-file=</lit><repl>filename</repl></altform>
	<altform><lit>info --from-file=</lit><repl>filename</repl></altform>
      </altforms>
    </usage>
  <description>
    <para>
      Nel suo utilizzo base, mostra le informazioni aggiuntive
      contenute nel file di dati attuale. Altrimenti, scrive queste
      informazioni su file (con l'opzione <opt>to-file</opt>), o legge
      i metadati da un file specificato e li allega al set di dati
      corrente (con <opt>from-file</opt>): in questo caso il testo
      deve essere  UTF-8 valido.
    </para>
  </description>

  <gui-access>
    <menu-path>/Dati/Visualizza descrizione</menu-path>
  </gui-access>

</command>

<command name="intreg" section="Estimation" label="Modello di regressione per intervalli">

  <usage>
    <arguments>
      <argument>var-min</argument>
      <argument>var-max</argument>
      <argument>var-indip</argument>
    </arguments>
    <options>
      <option>
        <flag>--quiet</flag>
        <effect>non mostra i risultati</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
        <flag>--robust</flag>
        <effect>errori standard robusti</effect>
      </option>
      <option>
        <flag>--opg</flag>
        <effect>vedi sotto</effect>
      </option>
      <option>
        <flag>--cluster</flag>
        <optparm>clustvar</optparm>
        <effect>vedi <cmdref targ="logit"/> per la spiegazione</effect>
      </option>
    </options>
    <examples>
      <example>intreg lo hi const x1 x2</example>
      <demos>
        <demo>wtp.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Stima un modello di regressione per intervallo. Questo modello
      è adatto al caso in cui la variabile dipendente è osservata in
      modo imperfetto per alcune osservazioni (o anche tutte). In
      altre parole, si ipotizza che il processo generatore dei dati
      sia
      <equation status="display" tex="\[y^*_t = x_t
                                      \beta+\epsilon_t\]" ascii="y* = x b + u"/>
      ma che solo
      <equation status="inline" tex="\[m_t \le y_t \le M_t\]"
                ascii="m &lt;= y* &lt;= M"/>
      sia osservato (l'intervallo può
      essere limitato a destra o a sinistra). Si noti che per alcune
      osservazioni <math>m</math> può essere uguale a
      <math>M</math>. Le variabili <repl>var-min</repl> e
      <repl>var-max</repl> devono contenere valori <lit>NA</lit> nel
      caso di osservazioni non limitate a sinistra o a destra.
    </para>

    <para context="gui">
      Nella finestra di specificazione del modello, <repl>var-min</repl> e
      <repl>var-max</repl> sono identificate come la variabile limite
      inferiore e la variabile limite superiore.
    </para>

    <para>
      Il modello è stimato per massima verosimiglianza, ipotizzando la
      normalità del termine di disturbo.
    </para>

    <para context="cli">
      Per impostazione predefinita, gli errori standard sono
      calcolati usando l'inversa dell'Hessiana. Se si usa l'opzione
      <opt>robust</opt>, vengono calcolati invece gli errori
      standard QML o Huber&ndash;White. In questo caso la matrice di
      covarianza stimata è un <quote>sandwich</quote> dell'inversa
      dell'Hessiana stimata e del prodotto esterno del gradiente. In
      alternativa, l'opzione <opt>opg</opt> produce una matrice
      varianze-covarianze basata sul prodotto esterno dei gradienti.
    </para>
    <para context="gui">
      Per impostazione predefinita, gli errori standard sono
      calcolati usando l'inversa dell'Hessiana. Se si abilita la
      casella "Errori standard robusti", vengono calcolati invece
      gli errori standard QML o Huber&ndash;White. In questo caso la
      matrice di covarianza stimata è un <quote>sandwich</quote>
      dell'inversa dell'Hessiana stimata e del prodotto esterno del
      gradiente.
    </para>

  </description>

  <gui-access>
    <menu-path>/Modello/Modelli non lineari/Regressione per intervalli</menu-path>
  </gui-access>

</command>


<command name="irfboot" section="Graphs" context="gui"
         label="Bootstrap impulso-risposta">

  <description>
    <para>
      Se si sceglie l'intervallo di confidenza bootstrap nella
      visualizzazione delle funzioni di impulso-risposta, gretl
      calcola un intervallo di confidenza al 95 per cento per le
      risposte usando il metodo bootstrap. Si effettua un
      campionamento (con reimmissione) dai residui del VAR (o VECM)
      originale, viene costruito un dataset artificiale usando le
      stime originali dei parametri e i residui ri-campionati, viene
      ri-stimato il sistema e vengono ri-calcolate le funzioni di
      impulso-risposta.  Questa procedura viene ripetuta 999 volte e
      vengono mostrati i quantili &alpha;/2 e 1 &minus; &alpha;/2 per le risposte,
      insieme alle stime puntuali.  L'opzione bootstrap al momento
      non è disponibile per il VECM vincolati.
    </para>
    <para>
      Questo comando permette anche il riordinamento delle variabili per la
      scomposizione di Cholesky della matrice di covarianza degli errori
      delle diverse equazioni. Di default l'ordine adottato è quello con
      il quale le variabili vengono elencate nella specificazione del modello,
      ma è possibile usare le frecce verso l'alto e verso il basso per spostare
      una variabile selezionata.
    </para>
    <para>
      In riferimento alla scala delle risposte di impulso: lo
      <quote>shock</quote> è porporzionato alla deviazione standard
      delle innovazioni stimate nella variabile sorgente, e la
      risposta è data in qualunque sia l'unità di misura
      <quote>naturale</quote> della variabile obiettivo.
    </para>
  </description>

</command>

<command name="johansen" section="Tests" label="Test di cointegrazione di Johansen">

  <usage>
    <arguments>
      <argument>ordine</argument>
      <argument>lista-y</argument>
      <argblock optional="true" separated="true">
        <argument>lista-x</argument>
      </argblock>
      <argblock optional="true" separated="true">
        <argument>lista-rx</argument>
      </argblock>
    </arguments>
    <options>
      <option>
        <flag>--nc</flag>
        <effect>senza costante</effect>
      </option>
      <option>
        <flag>--rc</flag>
        <effect>costante vincolata</effect>
      </option>
      <option>
        <flag>--uc</flag>
        <effect>costante non vincolata</effect>
      </option>
      <option>
        <flag>--crt</flag>
        <effect>costante e trend vincolato</effect>
      </option>
      <option>
        <flag>--ct</flag>
        <effect>costante e trend non vincolato</effect>
      </option>
      <option>
        <flag>--seasonals</flag>
        <effect>include dummy stagionali centrate</effect>
      </option>
      <option>
        <flag>--asy</flag>
        <effect>registra i p-value asintotici</effect>
      </option>
      <option>
        <flag>--silent</flag>
        <effect>non mostra nulla</effect>
      </option>
      <option>
        <flag>--quiet</flag>
        <effect>mostra solo i test</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>mostra i dettagli delle regressioni ausiliarie</effect>
      </option>
    </options>
    <examples>
      <example>johansen 2 y x</example>
      <example>johansen 4 y x1 x2 --verbose</example>
      <example>johansen 3 y x1 x2 --rc</example>
      <demos>
        <demo>hamilton.inp</demo>
        <demo>denmark.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para context="cli">
      Esegue il test di Johansen per la cointegrazione tra le
      variabili della <repl>lista-y</repl> per l'ordine specificato
      di ritardi. Per dettagli, si veda <guideref targ="chap:vecm"/>
      oppure <cite key="hamilton94">Hamilton (1994)</cite>, capitolo
      20. I valori critici sono calcolati con l'approssimazione
      gamma di J. Doornik <cite key="doornik98" p="true">(Doornik,
      1998)</cite>. Per il test traccia, vengono formiti due set di
      valori critici: asintotici e aggiustati per l'ampiezza
      campionaria.  Di default, l'accessore <fncref targ="$pvalue"/>
      riporta la variante aggiustata, ma i valori asintotici possono
      essere ottenuti usando l'opzione <opt>asy</opt>.
    </para>
    <para context="gui">
      Esegue il test di Johansen per la cointegrazione tra le variabili
      elencate per l'ordine specificato di ritardi. I valori critici
      sono calcolati con l'approssimazione gamma di J. Doornik (Doornik,
      1998). Per i dettagli su questo test, si veda Hamilton, <book>Time
      Series Analysis</book> (1994), Cap. 20. Per il test traccia,
      vengono formiti due set di valori critici: asintotici e
      aggiustati per l'ampiezza campionaria.
    </para>
    <para context="cli">
      L'inclusione di trend deterministici nel modello è controllata
      dalle opzioni del comando. Se non si indica alcuna opzione,
      viene inclusa una <quote>costante non vincolata</quote>, che
      permette la presenza di un'intercetta diversa da zero nelle
      relazioni di cointegrazione e di un trend nei livelli delle
      variabili endogene. Nella letteratura originata dal lavoro di
      Johansen (si veda ad esempio il suo libro del 1995), si fa
      riferimento a questo come al <quote>caso 3</quote>.  Le prime
      quattro opzioni mostrate sopra, che sono mutualmente esclusive,
      producono rispettivamente i casi 1, 2, 4 e 5. Il significato di
      questi casi e i criteri per scegliere tra di essi sono spiegati
      nel<guideref targ="chap:vecm"/>.
    </para>
    <para context="gui">
      L'inclusione di termini deterministici nel modello è controllata
      dai pulsanti delle opzioni. L'opzione predefinita è di includere
      una <quote>costante non vincolata</quote>, che permette la
      presenza di un'intercetta diversa da zero nelle relazioni di
      cointegrazione e di un trend nei livelli delle variabili
      endogene. Nella letteratura originata dal lavoro di Johansen (si
      veda ad esempio il suo libro del 1995), si fa riferimento a
      questo come al <quote>caso 3</quote>.  Le prime quattro opzioni
      mostrate sopra, che sono mutualmente esclusive, producono
      rispettivamente i casi 1, 2, 4 e 5. Il significato di questi
      casi e i criteri per scegliere tra di essi sono spiegati
      nel<guideref targ="chap:vecm"/>.
    </para>
    <para context="cli">
      Le liste opzionali <repl>lista-x</repl> e
      <repl>lista-rx</repl> permettono di controllare per specifiche
      variabili esogene che entrano nel sistema in modo non
      vincolato (<repl>lista-x</repl>) o vincolate allo spazio di
      cointegrazione (<repl>lista-rx</repl>). Queste liste vanno
      separate tra di loro e dalla <repl>lista-y</repl> usando il
      carattere punto e virgola.
    </para>
    <para context="gui">
      È possibile controllare per le variabili esogene aggiungendole
      nel campo inferiore. Per impostazione predefinita, le
      variabili vengono aggiunte al modello in forma non vincolata
      (indicata da una lettera <lit>U</lit> vicino al nome della
      variabile). Se si vuole che una certa variabile esogena sia
      vincolata allo spazio di cointegrazione, basta fare clic col
      tasto destro e selezionare <quote>Vincolata</quote> dal menu
      pop-up. Il simbolo vicino alla variabile diventerà una V.
    </para>
    <para context="cli">
      L'opzione <opt>seasonals</opt>, che può accompagnare una qualsiasi
      delle altre opzioni, specifica l'inclusione di un gruppo di variabili
      dummy stagionali centrate. Questa opzione è disponibile solo per dati
      trimestrali o mensili.
    </para>
    <para context="gui">
      Se i dati sono trimestrali o mensili, è presente anche una casella che
      permette di includere un gruppo di variabili dummy stagionali centrate.
      In tutti i casi, la casella <quote>Mostra dettagli</quote> permette di
      vedere il risultato delle regressioni ausiliarie che sono il punto di
      partenza per la procedura di stima di massima verosimiglianza di
      Johansen.
    </para>
    <para context="notex">
      La tabella seguente fornisce un esempio di interpretazione dei
      risultati del test nel caso di 3 variabili. <lit>H0</lit> denota
      l'ipotesi nulla, <lit>H1</lit> l'ipotesi alternativa e <lit>c</lit>
      il numero delle relazioni di cointegrazione.
    </para>
    <code context="notex">
      Rango    Test traccia       Test Lmax
      H0     H1          H0     H1
      ---------------------------------------
      0      c = 0  c = 3       c = 0  c = 1
      1      c = 1  c = 3       c = 1  c = 2
      2      c = 2  c = 3       c = 2  c = 3
      ---------------------------------------
    </code>

    <para context="tex">
      La tabella seguente fornisce un esempio di interpretazione dei
      risultati del test nel caso di 3 variabili. $H_0$ denota
      l'ipotesi nulla, $H_1$ l'ipotesi alternativa e $c$
      il numero delle relazioni di cointegrazione.

      \begin{center}
      \begin{tabular}{cllll}
      &amp; \multicolumn{2}{c}{Test traccia} &amp;
      \multicolumn{2}{c}{Test $\lambda$-max} \\
      Rango &amp;  \multicolumn{1}{c}{$H_0$} &amp;
      \multicolumn{1}{c}{$H_1$} &amp;
      \multicolumn{1}{c}{$H_0$} &amp;
      \multicolumn{1}{c}{$H_1$} \\ [4pt]
      0 &amp; $c$ = 0 &amp; $c$ = 3 &amp; $c$ = 0 &amp; $c$ = 1 \\
      1 &amp; $c$ = 1 &amp; $c$ = 3 &amp; $c$ = 1 &amp; $c$ = 2 \\
      2 &amp; $c$ = 2 &amp; $c$ = 3 &amp; $c$ = 2 &amp; $c$ = 3
      \end{tabular}
      \end{center}
    </para>

    <para>
      Si veda anche il comando <cmdref targ="vecm"/>.
    </para>

  </description>

  <gui-access>
    <menu-path>/Modello/Serie storiche/Test di cointegrazione/Johansen</menu-path>
  </gui-access>

</command>

<command name="join" section="Dataset" label="Manage data sources"
         context="cli">

  <usage>
    <arguments>
      <argument>filename</argument>
      <argument>varname</argument>
    </arguments>
    <options>
      <option>
        <flag>--data</flag>
        <optparm>column-name</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--filter</flag>
        <optparm>expression</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--ikey</flag>
        <optparm>inner-key</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--okey</flag>
        <optparm>outer-key</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--aggr</flag>
        <optparm>method</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--tkey</flag>
        <optparm>nome-colonna,stringa-formato</optparm>
        <effect>v. oltre</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>visualizza dettagli sul comando</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Questo comando importa una o più serie dal file di origine
      <repl>filename</repl> (che deve essere un file di dati
      testuale delimitato o un file di dati nativo di gretl)
      assegnandoli alla variabile <repl>varname</repl>. Per maggiori
      dettagli, si veda <guideref targ="chap:join"/>; in questa sede
      ci limitiamo a ricordare brevemente le opzioni disponibili.
      Vedi anche <cmdref targ="append"/> per alcune semplici
      operazioni di unione di dataset.
    </para>
    <para>
      L'opzione <opt>data</opt> può essere usata per specificare
      l'intestazione della colonna nel file di origine se quest'ultima
      è diversa dal nome con il quale dovrebbero essere chiamati i dati
      in gretl.
    </para>
    <para>
      L'opzione <opt>filter</opt> può essere usata per specificare un criterio
      da seguire per filtrare i dati di origine (in altre parole,
      per selezionare un sottoinsieme di osservazioni).
    </para>
    <para>
      Le opzioni <opt>ikey</opt> e <opt>okey</opt> possono essere utilizzate
      per specificare una relazione fra le osservazioni nel dataset corrente
      e quelle nel file di origine (per esempio, gli individui possono essere
      assegnati alla famiglia di appartenenza).
    </para>
    <para>
      L'opzione <opt>aggr</opt> viene usata quando la relazione fra
      osservazioni nel dataset corrente e nel file di origine non è
      biunivoca.
    </para>
    <para>
      L'opzione <opt>tkey</opt> è applicabile solo quando il dataset
      corrente ha una struttura di serie storiche. Viene usato per
      specificare il nome di una colonna contenente le date da
      accoppiare al dataset e/o il formato in cui le date sono
      rappresentate in quella colonna.
    </para>
    <subhead>Come importare più di una serie alla volta</subhead>
    <para>
      Il comando <cmd>join</cmd> può essere usato per importare più
      di una serie alla volta. Questo si ha quando (a) l'argomento
      <repl>varname</repl> è una lista di nomi separati da spazi,
      anziché una stringa semplice, oppure (b) quando è il nome di
      un array di stringhe, gli elementi del quale saranno i nomi
      delle serie da importare.
    </para>
    <para>
      Va detto che questo metodo ha alcune limitazioni: l'opzione
      <opt>data</opt> non è disponibile, e bisogna accettare i nomi
      delle variabili così come sono nel dataset
      <repl>filename</repl>. Le altre opzioni verranno applicate
      uniformemente a tutte le serie così importate.
    </para>
  </description>
</command>

<command name="join" section="Dataset" label="Aggiungi dati con controlli"
         context="gui">
  <description>
    <para>
      Questa finestra di dialogo permette di usare un buon
      sottoinsieme delle funzionalità del comando <lit>join</lit>, per
      una piena discussione del quale si rimanda alla guida utente
      (<guideref targ="chap:join"/>).
    </para>
    <para>
      Sulla sinistra viene visualizzata una lista di serie presenti
      nel dataset corrente. Una di esse può essere selezionata ed
      usata come una delle <quote>chiavi interne</quote>. Le chiavi
      servono a stabilire una corrispondenza fra le righe del dataset
      attuale e quello dal quale si vogliono importare i dati.
    </para>
    <para>
      Sulla destra, viene visualizzata una lista di serie presenti nel
      file selezionato. Coi bottoni freccia si sceglie da essa il nome
      della serie da importare, e (se necessario) il nome delle serie
      corrispondenti alle chiavi <quote>interne</quote>, da usare come
      <quote>chiavi esterne</quote>. (Di default, si assume che le
      chiavi interna ed esterna si chiamino allo stesso modo.) In
      questa finestra c'è anche una voce "<quote>fittizia</quote>",
      <lit>$obsmajor</lit>. Questa serie non può essere importata, ma può
      essere utilizzata come chiave; vedi <fncref targ="$obsmajor"/>.
    </para>
    <para>
      Nel pannello di mezzo, vengono specificati, volendo, parametri
      aggiuntivi per l'operazione di <quote>join</quote>:
    </para>
    <ilist>
      <li>
        <para>
          Un nuovo nome per la serie importata.  (Di default,si
          mantiene lo stesso nome del file esterno).
        </para>
      </li>
      <li>
        <para>
          Un'espressione filtro. Essa verrà calcolata per ogni riga
          del dataset esterno, e verranno importate solo le righe
          corrispondenti a valori non-zero.
        </para>
      </li>
      <li>
        <para>
          Un metodo di aggregazione. Questo non va specificato, a meno
          che l'accoppiamento fra chiavi interne ed esterne produca
          più di una riga per osservazioni interne.
        </para>
      </li>
    </ilist>
    <subhead>Dati in serie storiche</subhead>
    <para>
      Se il dataset corrente è di serie storiche, è probabile che
      anche lo siano anche i dati da aggiungere. In tal caso gretl
      potrebbe essere in grado di capire il da farsi senza l'aiuto
      delle chiavi specificate dall'utente. Ciò è segnalato dalla
      stringa segnaposto <quote>auto-detect</quote> nelle caselle di
      immissione della chiave interna. Sebbene non vi sia alcuna
      garanzia che il risultato sia quello voluto, può valer la pena
      provare prima di ricorrere a un approccio più complicato.
    </para>
  </description>
</command>

<command name="kalman" section="Utilities"
         label="State space modeling" context="gui">
  <description>
    <para>
      Questa interfaccia grafica offre una piccola parte delle
      funzionalità di gretl per i modelli in spazio degli stati.
    </para>
    <para>
      Chi fosse interessato ad approfondire può consultare il capitolo
      intitolato <quote>State Space Modeling</quote> del<guideref
      targ="chap:kalman"/> (in inglese). La guida contiene dettagli su
      modelli più generali, come quelli com matrici di sistema
      variabili nel tempo, disturbi correlati fra le equazioni di
      misura e di transizione, e molto altro. La guida contiene anche
      script di esempio scaricabili che illustrano, fra le altre cose,
      come usare il filtro di Kalman di gretl alla stima di massima
      verosimiglianza.
    </para>
  </description>
</command>

<command name="kdplot" section="Graphs" label="Kernel density plot">
  <usage>
    <arguments>
      <argument>y</argument>
    </arguments>
    <options>
      <option>
        <flag>--alt</flag>
        <effect>usa il kernel di Epanechnikov</effect>
      </option>
      <option>
        <flag>--scale</flag>
        <optparm>s</optparm>
        <effect>fattore di scala per l'ampiezza di banda</effect>
      </option>
      <option>
        <flag>--output</flag>
        <optparm>nome file</optparm>
        <effect>salva il grafico nel file specificato</effect>
      </option>
    </options>
  </usage>
  <description>
    <para>
      Produce una stima della densità del kernel per la serie
      <argname>y</argname>. Di default, il kernel è gaussiano, ma se
      con l'opzione <opt>alt</opt> viene usato il kernel di
      Epanechnikov. L'opzione <opt>scale</opt>, il cui valore predefinito è
      1.0, serve a controllare quanto sia liscio il risultato
      (valori più alti producono un risultato più liscio). 
    </para>
    <para context="cli">
      L'opzione <opt>output</opt> ha l'effetto di salvare il output
      nel file specificato; usando <quote>display</quote> l'output
      andrà sullo schermo. Vedi il comando <cmdref targ="gnuplot"/>
      per maggiori dettagli su questa opzione.  command for more
      detail on this option.
    </para>
    <para>
      Vedi anche, per un'opzione più flessibile che consente di
      salvare il risultato in una matrice, la funzione <fncref
      targ="kdensity"/>.
    </para>
  </description>
  <gui-access>
    <menu-path>/Variabile/Grafico densità stimata</menu-path>
  </gui-access>
</command>



<command name="kpss" section="Tests" label="Test KPSS di stazionarietà">
  <usage>
    <arguments>
      <argument>ordine</argument>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
        <flag>--trend</flag>
        <effect>include un trend</effect>
      </option>
      <option>
        <flag>--seasonals</flag>
        <effect>include dummy stagionali</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>mostra i risultati della regressione</effect>
      </option>
      <option>
        <flag>--quiet</flag>
        <effect>non mostra i risultati</effect>
      </option>
      <option>
        <flag>--difference</flag>
        <effect>usa la differenza prima della variabile</effect>
      </option>
    </options>
    <examples>
      <example>kpss 8 y</example>
      <example>kpss 4 x1 --trend</example>
    </examples>
  </usage>

  <description>

    <para context="gui">
      Calcola il test KPSS (Kwiatkowski, Phillips, Schmidt e Shin,
      1992) per la stazionarietà di una variabile (o della sua
      differenza prima, se si usa l'opzione di
      differenziazione). L'ipotesi nulla è che la variabile in
      questione sia stazionaria, attorno a un valore fisso o, se è
      stata selezionata l'opzione <lit>includi un trend</lit>,
      attorno a un trend deterministico lineare.
    </para>

    <para context="cli">
      Si veda il paragrafo in fondo per l'uso di questo test su dati
      panel.
    </para>

    <para context="cli">
      Calcola il test KPSS <cite key="KPSS92" p="true">(Kwiatkowski
      et al, Journal of Econometrics, 1992)</cite> per la
      stazionarietà di ognuna delle variabili specificate (o della
      loro differenza prima, se si usa l'opzione
      <opt>difference</opt>. L'ipotesi nulla è che la variabile in
      questione sia stazionaria, attorno a un valore fisso o, se è
      stata usata l'opzione <opt>trend</opt>, attorno a un trend
      deterministico lineare.
    </para>

    <para context="gui">
      L'argomento ordine determina la dimensione della finestra usata per
      il livellamento di Bartlett.  Se si usa l'opzione <lit>Mostra i risultati
      della regressione</lit>, vengono mostrati anche i risultati della
      regressione ausiliaria, insieme alla varianza stimata della componente
      random walk della variabile.
    </para>
    <para context="cli">> L'argomento <repl>order</repl> determina
    l'ampiezza della finestra usata per il livellamento di
    Bartlett. Se viene dato un valore negativo questo è considerato
    come un segnale per l'utilizzo in automatico di una finestra di
    riferimento di ampiezza 4(<math>T</math>/100)<sup>0.25</sup>,
    dove <math>T</math> è l'ampiezza del campione.
    </para>
    <para context="cli">
      Se si sceglie l'opzione <opt>verbose</opt> il risultato
      della regressione ausiliaria verrà stampato insieme alla
      varianza stimata della componente di random walk della
      variabile
    </para>
    <para>
      Il valori critici riportati per questa statistica test sono
      basati sulle superfici di risposta stimate secondo il metodo
      descritto da <cite key="sephton95">Sephton (Economics Letters,
      1995)</cite>, che per piccoli campioni sono più accurate di
      quelle fornite nell'articolo originale di KPSS. Quando la
      statistica test si trova fra i valori critici al 10 e all'1
      per cento viene mostrato un p-value ottenuto per
      interpolazione lineare, che non dovrebbe essere accettato in
      maniera acritica. Vedi anche la funzione <fncref
      targ="kpsscrit"/> per ottenere questi valori critici come
      codice.
    </para>

    <subhead context="cli">Dati panel</subhead>

    <para context="cli">
      Quando il comando <lit>kpss</lit> viene usato con dati panel
      per calcolare un test panel di radice unitaria, le opzioni
      applicabili e i risultati mostrati sono leggermente
      diversi. Mentre nel caso di serie storiche regolari potete
      fornire una lista di variabili da testare, con dati panel il
      comando può testare solo una variabile alla volta. L'opzione
      <opt>verbose</opt>, inoltre, ha un significato diverso:
      produce un breve resoconto del test per ciascuna singola serie
      storica (di default viene mostrato solo il risultato
      complessivo).
    </para>

      <para context="cli">
	Se possibile, viene calcolato il test complessivo (ipotesi
	nulla: la variabile in questione è stazionaria per tutte le
	unità panel) usando il metodo di <cite key="choi01">Choi
	(Journal of International Money and Finance,
	2001)</cite>. Questo calcolo non è sempre immediato perchè,
	mentre il test di Choi è basato sui p-value dei test sulle
	singole serie, attualmente non esiste un modo per calcolare i
	p-value della statistica test KPSS; dobbiamo perciò basarci su
	qualche valore critico.
      </para>

      <para context="cli">
	Se per una data variabile la statistica test cade fra i valori
	critici al 10 e all'1 per cento siamo in grado di interpolare
	un p-value. Ma se il test cade a sinistra del valore critico
	al 10 per cento, o supera quello all'1 per cento, non
	riusciamo a compiere l'interpolazione e tutto ciò che possiamo
	al limite fare è apporre un limite al test globale di Choi. Se
	le singole statistiche test si trovano a sinistra del valore
	critico al 10 per cento per alcune unità, ma superano quello
	all'1 per cento per altre, non è possibile neppure il calcolo
	del limite superiore del test globale.
      </para>
      </description>

      <gui-access>
      <menu-path>/Variabile/Test di radice unitaria/Test KPSS</menu-path>
      </gui-access>
      </command>

      <command name="labels" section="Dataset" label="Mostra etichette delle variabili" context="cli">

	<usage>
	  <altforms>
<altform><lit>labels [</lit> <repl>varlist</repl> <lit>]</lit></altform>
<altform><lit>labels --to-file=</lit><repl>filename</repl></altform>
<altform><lit>labels --from-file=</lit><repl>filename</repl></altform>
<altform><lit>labels --delete</lit></altform>
</altforms>
<examples>
  <demos>
    <demo>oprobit.inp</demo>
  </demos>
</examples>
</usage>

<description>
  <para>
    Nella sua prima forma mostra le etichette informative (se
    presenti) per le variabili in <repl>varlist</repl>, oppure per
    tutte le variabili nel dataset se <repl>varlist</repl> non è
    specificata.
</para>
<para>
  Con l'opzione <opt>to-file</opt>, scrive nel file indicato le
  etichette di tutte le variabili nel dataset, una per linea. Se
  non sono presenti etichette viene emesso un messaggio
  d'errore; se alcune variabili hanno etichette e altre no, per
  le seconde viene mostrata una linea vuota. Il file di output
  verrà scritto nella directory corrispondente al valore
corrente di <cmdref targ="workdir"/>, a meno che il <repl>nome di file</repl>
contenga un percorso completo.
</para>
<para>
  Con l'opzione <opt>from-file</opt>, legge il file specificato (che deve
  essere di testo) e assegna le etichette alle variabili nel dataset, leggendo
  un'etichetta per linea e interpretando linee vuote come etichette vuote.
</para>
<para>
  L'opzione <opt>delete</opt> da quello che vi attendete:
  rimuove dal dataset tutte le etichette di variabili.
</para>
</description>
<gui-access>
  <menu-path>/Dati/Etichette delle variabili</menu-path>
</gui-access>
</command>

<command name="lad" section="Estimation"
	 label="Stima con minime deviazioni assolute">

  <usage>
    <arguments>
<argument>variabile-dipendente</argument>
<argument>variabili-indipendenti</argument>
</arguments>
<options>
  <option>
<flag>--vcv</flag>
<effect>mostra la matrice di covarianza</effect>
</option>
<option>
<flag>--no-vcv</flag>
<effect>non calcolare la matrice di covarianza</effect>
</option>
<option>
<flag>--quiet</flag>
<effect>non stampa nulla</effect>
</option>
</options>
</usage>

<description>
  <para>
    Calcola una regressione che minimizza la somma delle
    deviazioni assolute dei valori stimati dai valori effettivi
    della variabile dipendente. Le stime dei coefficienti sono
    derivate usando l'algoritmo del simplesso di
    Barrodale&ndash;Roberts; viene mostrato un messaggio di
    avvertimento se la soluzione non è unica.
</para>
<para>
  Gli errori standard sono derivati usando la procedura
  bootstrap con 500 estrazioni. La matrice di covarianza per le
  stime dei parametri, mostrata se si usa l'opzione
  <opt>vcv</opt>, si basa sulla stessa procedura. Questa è
  un'operazione computazionalmente piuttosto onerosa, per cui se
  sono richieste le sole stime puntuali, essa può essere omessa
  attraverso l'opzione <opt>no-vcv</opt>; in questo caso, gli
  errori standard non saranno disponibili.
</para>
<para>
  Si noti che questo stimatore può richiedere molto tempo di
  calcolo per campioni grandi o modelli con molte variabili
  esplicative; in questi casi, consigliamo di usare il comando
  <cmdref targ="quantreg"/>. I due comandi sono di fatto
  equivalenti, a parte il fatto che quantreg usa l'algoritmo di
  Frisch&ndash;Newton (più efficiente) e fornisce errori
  standard analitici anziché via bootstrap.
</para>
<code>
  lad y const X
  quantreg 0.5 y const X
</code>
</description>

<gui-access>
  <menu-path>/Modello/Stima robusta/LAD - Minime deviazioni assolute</menu-path>
</gui-access>

</command>

<command name="lags" section="Transformations" label="Crea ritardi" context="cli">

  <usage>
    <arguments>
      <argument optional="true" separated="true">ordine</argument>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--bylag</flag>
	<effect>ordina i termini per ritardo</effect>
      </option>
    </options>
    <examples>
      <example>lags x y</example>
      <example>lags 12 ; x y</example>
      <example>lags 4 ; x1 x2 x3 --bylag</example>
      <demos>
	<demo>sw_ch12.inp</demo>
	<demo>sw_ch14.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Crea delle nuove variabili le quali sono i valori ritardati di ognuna delle
      variabili nella <repl>lista-variabili</repl>. Il numero dei ritardi può
      essere indicato dal primo parametro opzionale, altrimenti sarà pari
      alla periodicità del dataset.  Ad esempio, se la periodicità è 4
      (trimestrale), il comando <cmd>lags x y</cmd> crea
    </para>
    <code>
      x_1 = x(t-1)
      x_2 = x(t-2)
      x_3 = x(t-3)
      x_4 = x(t-4)
    </code>
    <para>
      Il numero dei ritardi creati può essere indicato come primo parametro
      opzionale (se presente, deve essere seguito da un punto e virgola).
    </para>
    <para>
      L'opzione <opt>bylag</opt> ha senso solo se la
      <repl>lista-variabili</repl> contiene più di una serie di
      variabili con ordine massimo di ritardo maggiore di 1. Da
      impostazione predefinita, i termini ritardati vengono aggiunti
      al dataset come variabili: si inizia con tutti i ritardi della
      prima serie, poi si passa quelli della seconda, poi della
      terza e così via. Tuttavia, se l'opzione <opt>bylag</opt> è
      data il riordino viene fatto per ritardi: si inizia con il
      primo ritardo di tutte le variabili, poi si passa al secondo e
      così via.
    </para>
    <para>
       Questo comando è anche disponibile sotto forma di funzione: si
       veda <fncref targ="lags"/>.
    </para>

  </description>

  <gui-access>
    <menu-path>/Aggiungi/Ritardi delle variabili selezionate</menu-path>
  </gui-access>

</command>

<command name="lags-dialog" section="Estimation" context="gui"
	 label="Finestra di selezione dei ritardi">

  <description>
    <para>
      In questa finestra di dialogo è possibile selezionare l'ordine dei
      ritardi per le variabili indipendenti in un modello di serie storiche, e
      in alcuni casi anche per la variabile dipendente (ma si noti che
      l'ordine di ritardi comune per modelli vettoriali come i VAR e i VECM è
      gestito separatamente attraverso un selettore nella finestra di dialogo
      principale del modello).
    </para>
    <para>
      I selettori sulla sinistra permettono di selezionare un intervallo di
      ritardi consecutivi per ogni variabile. Per specificare ritardi non
      consecutivi, occorre selezionare la casella vicino al campo intitolato
      <quote>ritardi specifici</quote>. In questo modo si attiva il campo,
      all'interno del quale è possibile inserire una lista di ritardi separati
      da spazi.
    </para>
    <para>
      La riga denominata <quote>predefinito</quote> offre un modo veloce per
      impostare una specificazione di ritardi comune a tutte le variabili
      indipendenti: i valori inseriti in questa riga vengono copiati in tutte
      le righe successive (tranne quella della variabile dipendente, se
      esiste).
    </para>
    <para>
      La variabile dipendente è trattata in modo speciale: il ritardo di
      ordine zero indica che la variabile apparirà nel modello a sinistra del
      segno uguale, mentre ulteriori ordini di ritardo saranno aggiunti a
      destra dell'uguale, insieme alle variabili indipendenti.
    </para>

    <para>
      I valori selezionati in questa finestra di dialogo vengono ricordati per
      l'intera durata della sessione di lavoro con un certo dataset.
    </para>

  </description>

</command>

<command name="ldiff" section="Transformations" label="Differenze logaritmiche" context="cli">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Calcola la differenza prima del logaritmo naturale di ogni
      variabile della <repl>lista-variabili</repl> e la salva in una
      nuova variabile con il prefisso <lit>ld_</lit>. Così, <cmd>ldiff
      x y</cmd> crea le nuove variabili
    </para>
    <code>
      ld_x = log(x) - log(x(-1))
      ld_y = log(y) - log(y(-1))
    </code>
  </description>

  <gui-access>
    <menu-path>/Aggiungi/Differenze logaritmiche</menu-path>
  </gui-access>

</command>

<command name="leverage" section="Tests" label="Osservazioni influenti">

  <usage>
    <options>
      <option>
	<flag>--save</flag>
	<effect>salva le variabili risultato</effect>
      </option>
      <option>
	<flag>--overwrite</flag>
	<effect>sovrascrive le serie eventualmente già esistenti</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
      <option>
	<flag>--plot</flag>
	<optparm>mode-or-filename</optparm>
	<effect>si veda oltre</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>leverage.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Deve seguire immediatamente un comando <cmd>ols</cmd>. Calcola
      il <quote>leverage</quote> (<math>h</math>, compreso tra 0 e 1)
      di ogni osservazione nel campione su cui è stato stimato il
      precedente modello. Mostra il residuo (<math>u</math>) per ogni
      osservazione assieme al leverage corrispondente e a una misura
      della sua influenza sulla stima: <math>uh</math>/(1 &minus;
      <math>h</math>). I <quote>punti di leverage</quote> per cui il
      valore di <math>h</math> supera 2<math>k</math>/<math>n</math>
      (dove <math>k</math> è il numero dei parametri stimati e
      <math>n</math> è l'ampiezza del campione) sono indicati con un
      asterisco. Per i dettagli sui concetti di leverage e influenza,
      si veda <cite key="davidson-mackinnon93">Davidson e MacKinnon
      (1993)</cite>, capitolo 2.
    </para>
    <para context="tex">
      Vengono mostrati anche i valori DFFITS: questi sono i
      <quote>residui studentizzati</quote> (ossia i residui divisi
      per i propri errori standard) moltiplicati per $\sqrt{h/(1 -
      h)}$. Essi forniscono una misura della differenza di
      <emphasis>fit</emphasis> a seconda che quell'osservazione sia o no inclusa
      nel campione. Per una discussione dei residui studentizzati e dei
      valori DFFITS si veda Maddala,<cite
      key="maddala92">Introduction to Econometrics</cite>, cap. 12,
      oppure <cite key="belsley-etal80">Belsley, Kuh e Welsch
      (1980)</cite>. Per ulteriori dettagli sui residui
      studentizzati si veda la sezione <emphasis>Matrice
      risltato</emphasis> più avanti.
    </para>
    <para context="notex">
      Vengono mostrati anche i valori DFFITS: questi sono i
      <quote>residui studentizzati</quote> (ossia i residui divisi
      per i propri errori standard) moltiplicati per la radice
      quadrata di <math>h</math>(1 &minus; <math>h</math>). Essi
      forniscono una misura della differenza di
      <emphasis>fit</emphasis> a seconda che quell'osservazione sia
      o no inclusa nel campione. Per una discussione dei residui
      studentizzati e dei valori DFFITS si veda Maddala,<cite
      key="maddala92">Introduction to Econometrics</cite>, cap. 12,
      oppure <cite key="belsley-etal80">Belsley, Kuh e Welsch
      (1980)</cite>. Per ulteriori dettagli sui residui
      studentizzati si veda la sezione <emphasis>Matrice
      risultato</emphasis> più avanti.
    </para>
    <para context="cli">
      Se si usa l'opzione <opt>save</opt>, il leverage, il valore di
      influenza e il valore DFFITS vengono aggiunti al dataset in
      uso. In questo contesto, l'opzione <opt>quiet</opt> evita che
      i risultati vengano stampati. I nomi di default delle serie
      prodotte sono rispettivamente <lit>lever</lit>,
      <lit>influ</lit> e <lit>dffits</lit>.  Se però serie con
      questo nome già esistono, entra in gioco l'opzione
      <opt>overwrite</opt>: se essa viene specificata, le serie
      preesistenti vengono sovrascritte. Se no, i nomi delle serie
      prodotte sarano ritoccati per assicurarne l'unicità; in tal
      caso, occuperanno i tre numeri di serie più alti nel dataset.
    </para>
    <para context="gui">
      L'icona "+" in cima alla finestra del test di leverage apre
      una finestra di dialogo che permette di salvare nel dataset in
    uso una o più delle variabili del test.</para>
    <para context="tex">
      Dopo l'esecuzione l'accessore <fncref targ="$test"/> restituisce
      il criterio di validazione incrociata, definito come \[
      \sum_{i=1}^n (y_i - \hat{y}_{-i})^2 \] dove $\hat{y}_{-i}$ è
      l'errore di previsione per la $i$-esima osservazione, dopo che
      quest'ultima è stata esclusa dal campione. Di conseguenza, il
      criterio è la somma dei quadrati degli errori di previsione
      nella quale per prevedere la $i$-esima osservazione vengono
      usate tutte le altre $n-1$ osservazioni (il cosiddetto stimatore
      <emphasis>leave-one-out</emphasis>). Per una discussione più
      approfondita del criterio di validazione incrociata, v. Davidson
      e MacKinnon's <book>Econometric Theory and Methods</book>,
      pag. 685--686, e i riferimenti bibliografici ivi citati.
    </para>
    <para context="notex">
      Dopo l'esecuzione, l'accessore <fncref targ="$test"/>
      restituisce il criterio di validazione incrociata, definito come
      la somma dei quadrati degli scarti fra la variabile dipendente e
      il suo valore previsto, calcolato a partire da un campione dal
      quale quell'osservazione è stata esclusa.  (Questo stimatore è
      chiamato <emphasis>leave-one-out</emphasis>).  Per una
      discussione più approfondita del criterio di validazione
      incrociata, v. Davidson e MacKinnon's <book>Econometric Theory
      and Methods</book>, pag. 685&ndash;686, e i riferimenti
      bibliografici ivi citati.
    </para>
    <para context="cli">
      Per impostazione predefinita, se questo comando viene invocato
      verrà mostrata una versione interattiva del grafico del leverage
      e dei valori d'influenza. Questo può essere aggiustato tramite
      l'opzione <opt>plot</opt>. I parametri accettabili per
      quest'opzione sono <lit>none</lit> per sopprimere il grafico,
      <lit>display</lit> per mostrare il grafico anche in modalità
      script, oppure il nome del file.  L'effetto di dare un nome di
      file al comando è descritto all'interno dell'opzione
      <opt>output</opt> del comando <cmdref targ="gnuplot"/>.
    </para>
    <subhead context="cli">Matrice risultato</subhead>
    <para context="cli">
      Oltre all'opzione <opt>save</opt> descritta sopra, i risultati
      di questo comando possono essere salvati sotto forma di una
      matrice a tre colonne usando l'accessore <fncref
      targ="$result"/>. Le prime due colonne contengono i valori di
      leverage e di influenza (come con <opt>save</opt>) ma la terza
      colonna contiene i residui studentizzati anziché i valori
      DFFITS. I residui sono <quote>studentizzati
      esternamente</quote>, ovvero residui <quote>jackknife</quote>:
      l'errore standard nel divisore dell'osservazione <math>i</math>
      usa la somma dei quadrati dei residui calcolata omettendo
      l'osservazione stessa. Questa grandezza può essere interpretata
      come un test <math>t</math> per l'ipotesi di azzeramento del
      coefficiente di una dummy pari a 0 ovunque tranne che per
      l'osservazione <math>i</math>. Per una discussione più ampia dei
      residui studentizzati si veda <cite
      key="chatterjee-hadi86">Chatterjee and Hadi (1986)</cite>.
      </para>
      <para>
	I valori DFFITS possono essere ottenuti dalla matrice <lit>$result</lit>
	come segue:
      </para>
      <code>
	R = $result
	dffits = R[,3] .* sqrt(R[,1] ./ (1-R[,1]))
      </code>
      <para>
	Oppure, usando le serie:
      </para>
      <code>
	series h = $result[,1]  # leverage
	series sr = $result[,3] # Studentized residual
	series dffits = sr * sqrt(h/(1-h))
      </code>
    </description>

<gui-access>
  <menu-path>Finestra del modello, /Test/LEVERAGE - Osservazioni influenti</menu-path>
</gui-access>

</command>

<command name="levinlin" section="Tests" label="Levin-Lin-Chu test">

  <usage>
    <arguments>
      <argument>order</argument>
      <argument>series</argument>
    </arguments>
    <options>
      <option>
	<flag>--nc</flag>
	<effect>test senza costante</effect>
      </option>
      <option>
	<flag>--ct</flag>
	<effect>con costante e trend</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>stampa i risultati per unità</effect>
      </option>
    </options>
    <examples>
      <example>levinlin 0 y</example>
      <example>levinlin 2 y --ct</example>
      <example>levinlin {2,2,3,3,4,4} y</example>
    </examples>
  </usage>

  <description>
    <para>
      Calcola il test di radice unitaria per dati panel di <cite
      key="LLC2002">Levin, Lin e Chu (2002)</cite>. L'ipotesi
      nulla che tutte le singole serie storiche contengano una
      radica unitaria, mentre l'alternativa è che nessuna delle
      serie storiche ne contenga una.  (In altre parole, si assume
      un coefficiente AR(1) comune a tutte le serie, anche se altre
      proprietà statistiche delle serie possono variare da un'unità
      di osservazione all'altra.)
</para>
<para context="cli">
  Di default le regressioni dei test ADF contengono una
  costante; per eliminarla usate l'opzione <opt>nc</opt>; per
  aggiungere un trend lineare usate l'opzione <opt>ct</opt>.
  (Vedi il comando <cmdref targ="adf"/> per una spiegazione delle
  regressioni ADF.)
</para>
<para context="cli">
  Il valore (non negativo) <repl>order</repl> del numero di
  ritardi della variabile dipendente da usare nel test può
  essere indicato in due modi diversi. Se si fornisce uno
  scalare, questo viene applicato a tutte le serie nel panel. In
  alternativa è possibile fornire una matrice che contiene un
  particolare ordine di ritardo per ogni serie. La matrice deve
  essere un vettore con numero di elementi pari a quello delle
  unità di osservazione nel sottoinsieme corrente del campione,
  e può essere indicata per nome o costruita usando parentesi
  graffe come illustrato nell'ultimo degli esempi precedenti.
</para>
<para context="cli">
  Con l'opzione <opt>verbose</opt>, vengono stampate per ogni
  unità nel panel le seguenti statistiche: <lit>delta</lit>, il
  coefficiente sul livello ritardato in ognuna delle regressioni
  ADF; <lit>s2e</lit>, la varianza stimata delle innovazioni; e
  <lit>s2y</lit>, la varianza di lungo periodo stimata per la
  serie in differenze.
</para>
<para>
  Si noti che test di radice unitaria in panel pèossono anche
  essere condiotti mediante i comandi <cmdref targ="adf"/> e
  <cmdref targ="kpss"/>.
</para>

</description>

<gui-access>
  <menu-path>/Variable/Unit root tests/Levin-Lin-Chu test</menu-path>
</gui-access>

</command>

<command name="loess" section="Estimation" label="Loess" context="gui">
  <description>
    <para>
      Stima una regressione polinomiale locally-weighted e produce
      una serie che contiene i valori previsti della variabile
      dipendente in corrispondenza di tutti i valori non-missing
      della variabile indipendente.  Il metodo applicato è quello
      descritto da <cite key="cleveland79">William Cleveland
      (1979)</cite>.
    </para>
    <para>
      I parametri vi permettono di specificare l'ordine del polinomio
      nella variabile indipendente e la percentuale di punti osservati
      da utilizzare in ciascuna regressione locale (l'ampiezza di banda).
      Valori più elevati di quest'ultima generano un risultato più liscio.
    </para>
    <para>
      Se viene selezionata l'opzione dei pesi robusti la procedura
      di regressione locale è ripetuta due volte, modificando i pesi
      sulla base dei residui ottenuti all'iterazione precedente in modo
      da assegnare un'influenza minore alle osservazioni anomale.
    </para>
  </description>
</command>

<command name="logistic" section="Estimation" label="Regressione logistica">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--ymax</flag>
	<optparm>value</optparm>
	<effect>specifica il massimo della variabile dipendente</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>utilizza errori standard robusti</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>si veda <cmdref targ="logit"/> per una ulteriore spiegazione</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di varianza-covarianza</effect>
      </option>
      <option>
	<flag>--fixed-effects</flag>
	<effect>si veda oltre</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra nulla</effect>
      </option>
    </options>
    <examples>
      <example>logistic y const x</example>
      <example>logistic y const x --ymax=50</example>
    </examples>
  </usage>

  <description>
    <para>
      Regressione logistica: esegue una regressione OLS usando la
      trasformazione logistica sulla variabile dipendente:
      <equation status="display"
		tex="\[\log\left(\frac{y}{y^*-y}\right)\]"
		ascii="log(y/(y* - y))"
		graphic="logistic1"/>
    </para>
    <para context="cli">
      La variabile dipendente dev'essere strettamente positiva.  Se è
      una frazione decimale, compresa tra 0 e 1, il valore
      predefinito per <math>y</math><sup>*</sup> (il massimo
      asintotico della variabile dipendente) è 1. Se la variabile
      dipendente è una percentuale, compresa tra 0 e 100, il valore
      predefinito di <math>y</math><sup>*</sup> è 100.
    </para>
    <para context="cli">
      È possibile indicare un valore diverso per il massimo, usando
      l'opzione <opt>ymax</opt>. Il valore fornito deve essere
      maggiore di tutti i valori osservati della variabile
      dipendente.
    </para>
    <para context="gui">
      Nella finestra di dialogo del comando, è possibile specificare
      un valore diverso per il massimo. Il valore fornito deve essere
      maggiore di tutti i valori osservati della variabile
      dipendente.
    </para>
    <para>
      I valori stimati e i residui della regressione sono
      trasformati automaticamente usando l'inversa della
      trasformazione logistica:
      <equation status="display"
		tex="\[y=\frac{y^*}{1+e^{-x}}\]"
		ascii="y = y* / (1 + exp(-x))"
		graphic="logistic2"/>
      dove <math>x</math> rappresenta un valore stimato oppure un
      residuo della regressione OLS, usando la variabile dipendente
      trasformata. I valori riportati sono dunque confrontabili con
      la variabile dipendente originale. Il bisogno dell'approssimazione
      sorge dal fatto che la trasformazione inversa è una di natura
      non-lineare e quindi quest'ultima non conserva un valore atteso.
    </para>
    <para>
      L'opzione <opt>fixed-effects</opt> è utilizzabile solo se il dataset
      assume una forma panel. In questo caso si sottrae la media del gruppo
      dalla trasformazione logistica della variabile dipendente e si procede
      alla classica stima ad effetti fissi.
    </para>
    <para>
      Si noti che se la variabile dipendente è binaria, occorre
      usare il comando <cmdref targ="logit"/> invece di questo comando.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Modelli non lineari/Logistico</menu-path>
  </gui-access>

</command>

<command name="logit" section="Estimation"
	 label="Regressione logit">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>errori standard clusterizzati</effect>
      </option>
      <option>
	<flag>--multinomial</flag>
	<effect>stima un logit multinomiale</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
      <option>
	<flag>--p-values</flag>
	<effect>mostra i p-value invece delle pendenze</effect>
      </option>
      <option>
	<flag>--estrella</flag>
	<effect>usa una versione alternativa dello pseudo-R-quadro</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>keane.inp</demo>
	<demo>oprobit.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Se la variabile dipendente è binaria (i suoi valori sono 0 o
      1), esegue una stima di massima verosimiglianza dei
      coefficienti per le <repl>variabili-indipendenti</repl> con il
      metodo di Newton&ndash;Raphson. Visto che il modello
      è nonlineare, le pendenze dipendono dai valori delle variabili
      indipendenti: per impostazione predefinita, al posto dei
      p-value vengono mostrate le pendenze rispetto ad ognuna delle
      variabili indipendenti, calcolate in corrispondenza della
      media della variabile. Questo comportamento può essere
      soppresso usando l'opzione <opt>p-values</opt>.  La
      statistica chi-quadro testa l'ipotesi nulla che tutti i
      coefficienti tranne la costante siano pari a zero.
    </para>
    <para context="cli">
      In modalità predefinita, gli errori standard sono calcolati
      con l'inversa negativa dell'Hessiana.  Se si usa l'opzione
      <opt>robust</opt>, verranno calcolati gli errori standard QML
      o quelli di Huber&ndash;White. In questo caso, la matrice di
      covarianza stimata è un <quote>sandwich</quote> dell'inversa
      dell'Hessiana stimata e del prodotto esterno del gradiente.
      Per i dettagli, si veda il cap. 10 di <cite
      key="davidson-mackinnon04">Davidson e MacKinnon
      (2004)</cite>. Ma se viene usata l'opzione <opt>cluster</opt>,
      verranno prodotti errori standard
      <quote>cluster-robusti</quote>; vedi <guideref
      targ="chap:robust_vcv"/> per maggiori dettagli.
    </para>
    <para context="cli">
      Per default, la statistica pseudo-R-quadro riportata è quella
      suggerita da <cite key="mcfadden74">McFadden (1974)</cite>, ma
      nel caso binario è anche disponibile, tramite l'opzione
      <opt>estrella</opt>, la variante propugnata da <cite
      key="estrella98">Estrella (1998)</cite>. Si può argomentare che
      questa variante riproduce in modo più vicino le proprietà
      dell'indice <math>R</math><sup>2</sup> nel contesto della stima
      OLS.
      </para>
      <para context="cli">
	Quando la variabile dipendente è binaria, i coefficienti
	rappresentano i logaritmi degli <i>odds ratio</i> (il rapporto
	fra la probabilità che <math>y</math> = 1 e quella che
	<math>y</math> = 0). In questo caso il bundle
	<lit>$model</lit> prodotto dopo la stima comprende una matrice
	chiamata <lit>oddsratios</lit>; essa ha quattro colonne che
	contengono, per tutti i regressori, l'esponenziale dei
	coefficienti (gli <i>odds ratio</i>), i loro errori standard
	calcolati col delta method e gli estremi di un intervallo di
	confidenza al 95 percento. Si noti che l'intervallo di
	confidenza è ottenuto come l'esponenziale di quello per il
	coefficiente originale.
      </para>
      <para context="gui">
      In modalità predefinita, gli errori standard sono calcolati con
      l'inversa negativa dell'Hessiana.  Se si seleziona la casella
      "Errori standard robusti", verranno calcolati gli errori
      standard QML o quelli di Huber&ndash;White. In questo caso, la
      matrice di covarianza stimata è un <quote>sandwich</quote>
      dell'inversa dell'Hessiana stimata e del prodotto esterno del
      gradiente.  Per i dettagli, si veda Davidson e MacKinnon 2004,
      cap. 10.
    </para>
    <para>
      Se la variabile dipendente non è binaria, ma è discreta, si
      ottengono stime logit ordinali. Tuttavia, se viene fornita
      l'opzione <opt>multinomial</opt>, la variabile dipendente è
      interpretata come non ordinale, e vengono prodotte stime Logit
      Multinomiali. (In ambo i casi, verrà dato un errore se la
      dipendente non è discreta.) Nel caso multinomiale, l'accessore
      <fncref targ="$allprobs"/> sarà disponibile dopo la stima; esso
      conterrà una matrice con le probabilità stimate dei possibili
      valori della dipendente per ogni osservazione (osservazioni per
      riga, esiti per colonna).
    </para>
    <para>
      Per condurre un'analisi delle proporzioni (dove la variabile
      dipendente è la proporzione dei casi che hanno una certa
      caratteristica in ogni osservazione, invece che una variabile
      binaria che indica se la caratteristica è presente o no), non
      bisogna usare il comando <cmd>logit</cmd>, ma occorre
      costruire la variabile logit come
    </para>
    <code>
      genr lgt_p = log(p/(1 - p))
    </code>
    <para>
      e usare questa come variabile dipendente in una regressione OLS.
      Si veda <cite key="ramanathan02">Ramanathan (2002)</cite>, capitolo 12.
    </para>
</description>

<gui-access>
  <menu-path>/Modello/Modelli non lineari/Logit</menu-path>
</gui-access>

</command>

<command name="logs" section="Transformations" label="Crea logaritmi" context="cli">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Calcola il logaritmo naturale di ognuna delle variabili
      della <repl>lista-variabili</repl> e lo salva in una nuova
      variabile col prefisso <lit>l_</lit>, ossia una
      <quote>elle</quote> seguita da un trattino basso. Ad esempio
      <cmd>logs x y</cmd> crea le nuove variabili <lit>l_x</lit> =
      ln(<lit>x</lit>) e <lit>l_y</lit> = ln(<lit>y</lit>).
    </para>
  </description>

  <gui-access>
    <menu-path>/Aggiungi/Logaritmi delle variabili selezionate</menu-path>
  </gui-access>

</command>

<command name="loop" section="Programming"
	 label="Apre un ciclo di comandi" context="cli">

  <usage>
    <arguments>
      <argument>controllo</argument>
    </arguments>
    <options>
      <option>
	<flag>--progressive</flag>
	<effect>abilita modalità speciali di alcuni comandi</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>mostra i dettagli dei comandi genr</effect>
      </option>
        <option>
          <flag>--decr</flag>
          <effect>vedi sotto</effect>
        </option>
    </options>
    <examples>
      <example>loop 1000</example>
      <example>loop i=1..10</example>
      <example>loop while essdiff &gt; .00001</example>
      <example>loop for (r=-.99; r&lt;=.99; r+=.01)</example>
      <example>loop foreach i xlist</example>
      <demos>
	<demo>armaloop.inp</demo>
	<demo>keane.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Questo comando apre una modalità speciale, in cui il programma accetta
      comandi da eseguire più volte.  Si esce dalla modalità loop con
      l'istruzione <cmd>endloop</cmd>: solo a questo punto i comandi indicati
      vengono eseguiti.
    </para>
    <para>
      Il parametro <repl quote="true">controllo</repl> deve assumere uno dei
      cinque valori mostrati negli esempi: un numero di volte per cui ripetere
      i comandi all'interno del loop; <quote><lit>while</lit></quote> seguito
      da una condizione booleana; un intervallo di valori interi per una variabile
      indice; <quote><lit>for</lit></quote> seguito da tre espressioni tra parentesi,
      separate da punti e virgola (in modo simile all'istruzione <lit>for</lit> nel
      linguaggio di programmazione C); infine, <quote><lit>foreach</lit></quote>
      seguito da una variabile indice e una lista.
    </para>
      <para>
        L'opzione <opt>decr</opt> è specifica della forma di ciclo
        <quote>intervallo di valori interi</quote>. Per default,
        l'indice viene incrementato di 1 a ogni iterazione e, se il
        valore iniziale è inferiore al valore finale, il ciclo non
        verrà eseguito. Quando viene specificato <opt>decr</opt>,
        l'indice viene invece decrementato di 1 a ogni iterazione.
      </para>
    <para>
      Si veda <guideref targ="chap:looping"/> per altri dettagli ed esempi,
      oltre che per la spiegazione dell'opzione <opt>progressive</opt> (che
      è destinata ad essere usata nelle simulazioni Monte Carlo) e per
      l'elenco dei comandi di gretl che possono essere usati all'interno di un
      loop.
    </para>
    <para>
      Per impostazione predefinita, l'esecuzione dei comandi procede
      con un output ridotto rispetto dentro un loop, rispetto ad
      altri contesti. Per avere più informazioni su quel che succede
      dentro il loop, si può usare l'opzione <opt>verbose</opt>.
    </para>
  </description>

</command>

<command name="mahal" section="Statistics" label="Distanze di Mahalanobis">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra nulla</effect>
      </option>
      <option>
        <flag>--save</flag>
        <effect>salva le distanze nel dataset</effect>
      </option>
      <option>
        <flag>--vcv</flag>
        <effect>mostra la matrice di covarianza</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Calcola la distanza di Mahalanobis di ogni osservazione dal
      centroide, usando le serie in <repl>varlist</repl>.
      La distanza di Mahalanobis è la distanza tra due punti in uno spazio
      <math>k</math>-dimensionale, scalata rispetto alla variazione
      statistica in ogni dimensione dello spazio. Ad esempio, se
      <math>p</math> e <math>q</math> sono due osservazioni su
      un insieme di <math>k</math> variabili con matrice di covarianza
      <math>C</math>, la distanza di Mahalanobis tra le due osservazioni
      è data da
      <equation status="display"
		tex="\[\sqrt{(p-q)^{\prime}C^{-1}(p-q)}\]"
		ascii="sqrt((p - q)' * C-inversa * (p - q))"
		graphic="mahal"/> dove
      <equation status="inline" tex="$(p-q)$" ascii="(p - q)" graphic="mahal2"/> è un
      vettore a <math>k</math> dimensioni. Se la matrice di covarianza è
      la matrice identità, la distanza di Mahalanobis corrisponde alla distanza
      Euclidea.
    </para>
    <para>
      Lo spazio in cui vengono calcolate le distanze è definito dalle
      variabili selezionate; per ogni osservazione nell'intervallo
      attuale viene calcolata la distanza tra l'osservazione e il
      centroide delle variabili selezionate. La distanza è la
      controparte multidimensionale di uno <math>z</math>-score
      standard e può essere usata per giudicare se una certa
      osservazione <quote>appartiene</quote> a un gruppo di altre
      osservazioni.
    </para>
    <para context="cli">
      Se si usa l'opzione <opt>vcv</opt>, vengono mostrate la matrice
      di covarianza e la sua inversa. Se si usa l'opzione
      <opt>save</opt>, le distanze vengono salvate nel dataset con il
      nome <lit>mdist</lit> (o <lit>mdist1</lit>, <lit>mdist2</lit> e
      così via, se esiste già una variabile con quel nome).
    </para>
    <para context="gui">
      Se il numero delle variabili selezionate è minore o uguale a 4,
      vengono mostrate la matrice di covarianza e la sua inversa.
      Facendo clic sul pulsante "+" in cima alla finestra che mostra
      le distanze è possibile aggiungerle al dataset come nuova
      variabile.
    </para>
  </description>

  <gui-access>
    <menu-path>/Visualizza/Distanze di Mahalanobis</menu-path>
  </gui-access>
</command>

<command name="mailer" section="Utilities" context="gui"
	 label="Invia un file via email">

  <description>
    <para>
      Consente di inviare da dentro gretl un dataset o uno script
      come allegato ad una email, questo tramite l'utilizzo del SMTP
      (Protocollo di Trasfermento Mail Semplificato). Sotto
      spieghiamo come capire le due etichette (<quote>Mail
      setup</quote> e <quote>Message</quote>) presenti nella
      finestra di dialogo della mail.  Inoltre sotto verranno
      fornite informazioni circa i requisti necessari della
      password.
    </para>
    <subhead>Etichetta: Mail setup</subhead>
    <ilist>
      <li>
	<para>
	  SMTP server: il server con il quale la vostra mail
	  dovrebbe venire inviata. Coloro che usano gmail dovrebbero
	  già trovare funzionante l'impostazione predefinita
	  <lit>smpts://smtp.gmail.com:465</lit>; altrimenti, il
	  campo andrà riempito a mano.  Si noti che la stringa dovrà
	  per forza iniziare con <lit>smtp://</lit> oppure
	  <lit>smtps://</lit>.  Subito di seguito al nome del server
	  potrebbe rivelarsi necessaria l'aggiunta dei "due punti"
	  seguiti dal numero della porta di ingresso come nell'
	  esempio <quote><lit>:465</lit></quote> mostra sopra.
	  Altri valori possibili per la porta SMTP sono 25 e 587.
</para>
</li>
<li>
  <para>
    Mail username: è il nome utente che vi identifica nel
    server della vostra posta elettronica. Quest'ultimo è con
    ogni probabilità identico a quello del vostro indirizzo di
    posta.
</para>
</li>
<li>
  <para>
    Mail password: molto probabilmente il vostro server SMTP potrebbe
    richiedervi una password, se questo non fosse il caso allora potete
    cliccare su <quote>La password non è richiesta</quote>.
</para>
</li>
</ilist>
<para>
  Il vostro server ed informazioni verranno ricordate da una
  sessione di gretl all'altra, lasciandovi così solo il l'onere
  di effettuare l'ingresso una volta sola. Per quanto riguarda
  la password potete scegliere se conservarla oppure no; vedi
  oltre la sezione <emphasis>Email password</emphasis> per
  maggiori informazioni a riguardo.
</para>
<para>
  Cliccando <lit>OK</lit> nell'etichetta di Mail setup verrete
  reindirizzati alla finestra di testo (a meno che non manchino
  delle informazioni).
</para>
<subhead>Finestra di testo</subhead>
<ilist>
  <li>
    <para>
      A: inserire l'indirizzo mail del destinatario. Dovrete
      scriverlo a mano poiché gretl non ha accesso alla vostra
      rubrica. Tuttavia, una volta inserito l'indirizzo
      quest'ultimo verrà ricordato e potrà essere selezionato
      successivamente tramite una tendina a cascata. Gretl
      memorizza sino a 10 indirizzi.
</para>
</li>
<li>
  <para>
    DA: inserire il vostro indirizzo email. Questo verrà
    ricordato per tutte le successive sessioni di gretl.
  </para>
</li>
<li>
  <para>
    SOGGETTO: questo campo verrà riempito in automatico ma
    potrà venire successivamente modificato se lo si desidera.
</para>
</li>
<li>
  <para>
    NOTA: anche questo campo viene riempito in automatico, e
    se serve può essere modificato.
</para>
</li>
</ilist>
<para>
  Cliccando <lit>OK</lit> nella finestra di messaggio il
  messaggio sarà inviato (a meno che non siano richieste
  ulteriori informazioni mancanti).
</para>
<subhead>Email password</subhead>
<para>
  Se la password è richiesta per l'invio della mail allora
  potrete scegliere di salvarla in gretl; in questo caso verrà
  salvata in formato offuscato in una directory che sarà privata
  solo per voi all'interno del vostro pc (nessun collegamento o
  server internet è richiesto). In ogni caso, non ci assumiamo
  responsabilità riguardo alla sicurezza dei vostri dati.
</para>
<para>
  Gli utenti gmail che usano un'autenticazione a 2-step pongano
  attenzione a questo: la vostra password "standard" non
  funzionerà in questo caso ed avrete bisogno di una <quote>App
  password</quote> per l'utilizzo in gretl.  Per maggiori
  informazioni consultate il sito:
  <url>https://support.google.com/accounts/answer/185833</url>.
</para>
</description>

</command>

<command name="makepkg" section="Programming" context="cli"
	 label="Make function package">

  <usage>
    <arguments>
      <argument>filename</argument>
    </arguments>
    <options>
      <option>
	<flag>--index</flag>
	<effect>crea un file ausiliario di indicizzazione</effect>
      </option>
      <option>
	<flag>--translations</flag>
	<effect>crea un file ausiliario di stringhe</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>lavora silenziosamente</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Permette la creazione di un <quote>function package</quote> da
      linea di comando. Il nome di file indica il nome del pacchetto
      da creare e deve avere estensione <lit>.gfn</lit>. Si veda
      <guideref targ="chap:functions"/> per dettagli.
    </para>
    <subhead>Modalità gfn</subhead>
    <para>
      Crea un file gfn. Si assume che sia accessibile un file di
      specificazione del pacchetto, con lo stesso nome di
      <repl>filename</repl> ma con estensione <lit>.spec</lit>;
      devono anche esistere tutti gli eventuali file ausiliatri in
      esso menzionati. Infine, si assume che tutte le funzioni da
      inserire nel pacchetto siano presenti in memoria.
    </para>
    <subhead>Modalità zip</subhead>
    <para>
      Scrive un pacchetto di tipo zip (gfn più materiale extra). Se
      viene trovato un file gfn con lo stesso nome di
      <repl>filename</repl>, gretl cercherà due file corrispondenti
      con estensione <lit>inp</lit> e
      <lit>spec</lit>: se vengono trovati entrambi e almeno uno di
      essi è più recente del file gfn, allora quest'ultimo viene
      ricreato, altrimenti viene usato quello esistente. Se il file
      non esiste, gretl creerà il file gfn come prima cosa.
    </para>
    <subhead>Opzioni gfn</subhead>
    <para>
      Le opzioni consentono la scrittura di file ausiliari per l'uso
      con gli <quote>addon</quote> di gretl. Il file indice è un
      breve documento XML contenente alcune informazioni base sul
      pacchetto; ha lo stesso nome del pacchetto stesso ed
      estensione <lit>.xml</lit>. Il file di traduzione contiene le
      stringhe da tradurre del pacchetto, in formato C; per il
      pacchetto <lit>pippo</lit> questo file in questione dovrà chiamarsi
      <lit>pippo-i18n.c</lit>. Questi file non vengono prodotti se si opera
      tramite la modalità zip con l'utilizzo di un file gfn preesistente.
    </para>
    <para>
      Per maggiori dettagli, consultare <mnu targ="Pkgbook">Guida ai
      pacchetti</mnu>.
    </para>

  </description>

  <gui-access>
    <menu-path>/File/Pacchetti di funzioni/Nuovo pacchetto</menu-path>
  </gui-access>

</command>

<command name="maps" section="Utilities" label="Drawing maps" context="gui">
  <description>
    <para>
      Questa finestra di dialogo permette di creare una mappa sulla
      base di dati geografici pre-caricati (un file GeoJSON o uno
      shapefile ESRI). Le opzioni sono le seguenti:.
    </para>
    <ilist>
      <li>
	<para>
	  serie da plottare: questa è l'eventuale serie in base alla
	  quale la mappa verrà colorata. senza un
	  <quote>contenuto</quote> verranno mostrati solo i
	  confini. Se il dataset attualmente aperto contiene una o
	  più serie che sembrano adatte allo scopo (sulla base di
	  semplici regole euristiche), queste verranno mostrate nel
	  selettore a tendina.
	</para>
      </li>
      <li>
	<para>
	  paletta: questo elemento permette di scegliere fra diverse
	  tavolozze di colori, cosicché è rilevante solo se è stata
	  selezionata una serie contenuto.
	</para>
      </li>
      <li>
	<para>
	  Scala logaritmica: Se esite una serie contenuto, va rappresentata
	  in scala logaritmica? Di default, no.
	</para>
      </li>
      <li>
	<para>
	  disegna il bordo: si vuole disegnare un bordo rettangolare intorno
	  alla mappa? Di default, sì, ma lo si può rimuovere.
	</para>
      </li>
	<li>
	  <para>
	    Spessore dei confini: controlla la larghezza del bordo o
	    del contorno disegnato attorno alle distinte aree nella
	    mappa (ad esempio, paesi o regioni). Se il tuo grafico
	    include un a serie da plottare, la larghezza può essere
	    ridotta a zero così da eliminare tali bordi.
	  </para>
	</li>
      <li>
	<para>
	  altezza in pixel: questo parametro controlla l'altezza
	  dell'immagine. Data quest'ultima, la larghezza viene
	  calcolata in base all'ampiezza in longitudine della mappa.
	</para>
      </li>
    </ilist>
    <para>
      Si noti che si usando la funzione <fncref targ="geoplot"/> da
      script ci sono <i>molte</i> più possibilità per personalizzare
      l'aspetto e il contenuto della mappa.
    </para>
  </description>
</command>

<command name="markers" section="Dataset" label="Aggiunta di marcatori" context="cli">

  <usage>
    <altforms>
      <altform><lit>markers --to-file=</lit><repl>nomefile</repl></altform>
      <altform><lit>markers --from-file=</lit><repl>nomefile</repl></altform>
      <altform><lit>markers --to-array=</lit><repl>nome</repl></altform>
      <altform><lit>markers --from-array=</lit><repl>nome</repl></altform>
      <altform><lit>markers --from-series=</lit><repl>nome</repl></altform>
      <altform><lit>markers --delete</lit></altform>
    </altforms>
  </usage>

  <description>
    <para>
      Le opzioni <opt>to-file</opt> e <opt>to-array</opt> fanno sì che
      si possano salvare le stringhe marcatrici delle osservazioni
      presenti nel dataset corrente, in un file o un array di
      stringhe. Se il dataset non contiene stringhe viene emesso un
      messaggio d'errore. Se l'output è un file, esso verrà scritto
      nella directory corrispondente al valore corrente di <cmdref
      targ="workdir"/>, a meno che il nome di file contenga un
      percorso completo; le stringhe saranno una per riga. Quando
      l'output è un array, se <repl>nome</repl> è un array già
      esistente, verrà sovrascritto; altrimenti ne verrà creato uno
      nuovo.
    </para>
    <para>
      Con l'opzione <opt>from-file</opt>, il comando legge dal file
      specificato (che deve essere in formato testo UTF-8) e assegna
      alle righe del dataset i marcatori di osservazione, leggendone
      uno per riga. In generale il file dovrebbe contenere tanti
      marcatori quante sono le osservazioni nel dataset, ma se
      quest'ultimo è un panel il numero di marcatori nel file potrebbe
      anche essere pari al numero di unità in cross-section (nel qual
      caso i marcatori sono ripetuti a ogni data). L'opzione
      <opt>from-array</opt> funziona in modo analogo, leggendo da un
      array di stringhe.
    </para>
      <para>
	L'opzione <opt>from-series</opt> permette di creare i
	marcatori in modo molto semplice copiando i valori di una
	serie con valori stringa. Se la serie non contiene stringhe,
	verrà generato un errore.
      </para>
    <para>
      L'opzione <opt>delete</opt> fa quello che ci si aspetta:
      cancella le stringhe marcatrici delle osservazioni dal dataset.
    </para>
  </description>
</command>

<command name="meantest" section="Tests" label="Differenza delle medie">

  <usage>
      <altforms>
        <altform><lit>meantest</lit> <repl>x</repl> <repl>y</repl> </altform>
        <altform><lit>meantest</lit> <repl>x</repl> <lit>--split-by=</lit><repl>dummy</repl></altform>
      </altforms>
    <options>
      <option>
	<flag>--unequal-vars</flag>
	<effect>assume varianze diverse</effect>
      </option>
        <option>
	  <flag>--paired</flag>
	  <effect>effettua un test appaiato</effect>
        </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non mostra l'output</effect>
        </option>
        <option>
	  <flag>--robust</flag>
	  <effect>solo per serie temporali</effect>
        </option>
    </options>
      <examples>
        <example>meantest x y</example>
        <example>meantest x y --unequal-vars</example>
        <example>meantest x y --paired</example>
        <example>meantest x --split-by=d</example>
      </examples>
  </usage>

  <description>
    <para context="cli">
      L'utilizzo principale di questo comando è nel calcolare la
      statistica <math>t</math> per l'ipotesi nulla che le medie della
      popolazione siano uguali per le variabili <repl>var1</repl> e
      <repl>var2</repl>, mostrando il suo p-value. I risultati possono
      essere salvati utilizzando gli accessori <fncref
      targ="$test"/> e <fncref targ="$pvalue"/>, nel qual caso è
      possibile utilizzare l'opzione <opt>quiet</opt> per omettere la
      stampa.
    </para>
    <para context="cli">
      Nella sua forma alternativa, con l'opzione <opt>split-by</opt>,
      i campioni le cui medie vengono testate per l'uguaglianza sono
      due sottoinsiemi della serie <repl>x</repl>, per i quali la
      serie <repl>dummy</repl> assume rispettivamente i valori 0 e 1.
      </para>
    <para>
      Per default, si assume che le varianze delle due variabili siano
     uguali, mentre usando l'opzione <opt>unequal-vars</opt>, si
     assume che esse siano diverse; in questo caso i gradi di libertà
     per la statistica test saranno approssimati per <cite
     key="satter46">Satterthwaite (1946)</cite>.
    </para>
    <subhead context="cli">Test appaiato</subhead>
    <para context="cli">
      Nel caso principale (e solo in esso) può essere fornita
      l'opzione <opt>paired</opt>, per testare l'ipotesi nulla che la
      media della differenza fra le due serie sia zero. Altrimenti, il
      test sarà calcolato senza assumere che le serie possano essere
      accoppiate.
    </para>
    <subhead context="cli">Test robusto</subhead>
    <para context="cli">
      Con dati in serie storiche, e solo nel caso principale, può
      essere fornita l'opzione <opt>robust</opt> per condurre un test
      di uguaglianza delle medie di <repl>x</repl> e <repl>y</repl>
      che è robusto rispetto alla correlazione seriale.
    </para>
    <para context="gui"> Calcola la statistica t per l'ipotesi nulla
    che le medie della popolazione siano uguali per due variabili
    selezionate, mostrando il suo p-value. Il comando può essere
    eseguito con o senza l'ipotesi che le varianze delle due variabili
    siano uguali.  In quest'ultimo caso i gradi di libertà per la
    statistica test verranno approssimato per <cite
    key="satter46">Satterthwaite (1946)</cite>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Modelli bivariati/Differenza delle medie</menu-path>
  </gui-access>

</command>

<command name="MIDAS_list" section="Dataset" label="lista MIDAS"
	 context="gui">
  <description>
    <para>
      Una lista MIDAS (MIDAS = Mixed Data Sampling) è una lista in
      cui le serie, prese congiuntamente, contengono una serie
      storica osservata a frequenza più alta di quella del dataset
      <quote>ospite</quote>. Per esempio, questa lista può
      rappresentare una serie mensile nel contesto di un dataset
      trimestrale od annuale, o una serie giornaliera nel contesto
      di un dataset mensile.
    </para>
    <para>
      Questa lista deve avere <math>m</math> elementi, dove
      <math>m</math> è il numero di sottoperiodi ad alta frequenza:
      ogni serie contiene i valori per un dato sottoperiodo. Nel
      caso mensile/trimestrale, ciò fa sì che la lista abbia tre
      elementi: uno contenente i valori per il primo mese del
      trimestre, un altro per il secondo mese e l'ultimo i valori
      per il terzo mese.
    </para>
    <para> Questi elementi devono essere in un certo ordine, ossia
    <emphasis>prima il più recente</emphasis>. Usando di nuovo
    l'esempio mensile/trimestrale, l'ordine deve essere mese 3, mese
    2, mese 1. Per controintuitivo che possa sembrare questo è
    l'ordine richiesto per formare liste di ritardi, cosa molto comune
    nei modelli MIDAS.  </para> <para> Per una guida sul come creare
    un dataset che contenga liste midas, consultare
  </para>
  <para>
    <url>http://gretl.sourceforge.net/midas/midas_gretl.pdf</url>
  </para>
  </description>
</command>

    <command name="MIDAS_parm" section="Estimation"
	     label="iperprametri MIDAS" context="gui">
      <description>
	<para>
	  In questa finestra di dialogo viene selezionato il tipo di
	  parametrizzazione per un insieme di termini ad alta frequenza,
	  insieme al relativo intervallo di ritardi. Le
	  parametrizzazioni disponibili sono:
	</para>
	<ilist>
	  <li>
	    <para>
	      U-MIDAS o <quote>MIDAS non vincolato</quote>: a ogni
	      ritardo corrisponde un coefficiente.
	    </para>
	  </li>
	  <li>
	    <para>
	      Almon esponenziale normalizzato: richiede almeno un
	      parametro e di solito ne usa due.
	    </para>
	  </li>
	  <li>
	    <para>
	      Beta normalizzato con zero finale; richiede due parametri.
	    </para>
	  </li>
	  <li>
	    <para>
	      Beta normalizzato senza zero finale; richiede tre parametri.
	    </para>
	  </li>
	  <li>
	    <para>
	      Polinomio di Almon; richiede almeno un parametro.
	    </para>
	  </li>
	  <li>
	    <para>
	      Beta normalizzato, un parametro: questa è una variante
	      della parametrizzazione Beta normalizzata con zero finale,
	      in cui il primo parametro è fisso a 1.0. Il secondo è
	      stimato sotto la restrizione che sia almeno pari a 1.0.
	    </para>
	  </li>
	</ilist>
      </description>
    </command>

    <command name="midasreg" section="Estimation" label="MIDAS regression">
      <usage>
	<arguments>
          <argument>depvar</argument>
          <argument>indepvars</argument>
	  <argument separated="true">MIDAS-terms</argument>
	</arguments>
	<options>
          <option>
	    <flag>--vcv</flag>
	    <effect>stampa la matrice di covarianze</effect>
          </option>
          <option>
	    <flag>--robust</flag>
	    <effect>errori standard robusti</effect>
          </option>
          <option>
	    <flag>--quiet</flag>
	    <effect>non stampa i risultati</effect>
          </option>
          <option>
	    <flag>--levenberg</flag>
	    <effect>vedi sotto</effect>
          </option>
	</options>
	<examples>
          <example>midasreg y 0 y(-1) ; mds(X, 1, 9, 1, theta)</example>
	  <example>midasreg y 0 y(-1) ; mds(X, 1, 9, 0)</example>
	  <example>midasreg y 0 y(-1) ; mdsl(XL, 2, theta)</example>
	  <demos>
	    <demo>gdp_midas.inp</demo>
	  </demos>
	</examples>
      </usage>

      <description>
	<para>
	  Stima coi minimi quadrati (lineari o meno, a seconda della
	  specificazione) un modello MIDAS (Mixed Data Sampling), ossia
	  un modello in cui una o più delle variabili esplicative sono
	  osservate a frequenza più alta della dipendente; per una buona
	  introduzione all'argomento si veda <cite
	  key="armesto10">Armesto, Engemann e Owyang (2010)</cite>.
	</para>
	<para context="cli">
	  Le variabili in <repl>indepvars</repl> devono essere alla
	  stessa frequenza della dipendente. Questa lista normalmente
	  contiene anche <lit>const</lit> o <lit>0</lit> (intercetta) e,
	  di solito, uno o più ritardi della variabile dipendente. I
	  termini ad alta frequenza vengono forniti dopo un punto e
	  virgola; ognuno di essi sotto forma di numeri separati da
	  virgole fra parentesi, col prefisso <lit>mds</lit> oppure
	  <lit>mdsl</lit>.
	</para>
	<para context="gui">
	  Le variabili in <repl>Regressori</repl> devono essere alla
	  stessa frequenza della dipendente, e sono selezionati dalla
	  lista in alto a sinistra. I modelli MIDAS normalmente
	  contengono anche <lit>const</lit> o <lit>0</lit> (intercetta)
	  e, di solito, uno o più ritardi della variabile dipendente
	  (scelti col bottone <quote>ordine AR</quote>, il cui default è
	  1). Per aggiungere termini MIDAS ad alta frequenza,
	  selezionarne dalla lista in basso a sinistra e cliccare sulla
	  freccia verde (o sul pulsante destro del mouse).
	</para>
	<para context="gui">
	  Quando si aggiunge un termine MIDAS, si apre una finestra per
	  la selezione dei ritardi, il tipo di parametrizzazione e (per
	  i tipi che non hanno un numero fisso di parametri) il numero
	  di iper-parametri. Per riattivare questa finestra e rivedere la
	  specificazione, basta cliccare col pulsante destro su un
	  termine MIDAS sulla destra.
	</para>
	<para context="cli">
	  <lit>mds</lit>: questa variante richiede 5 argomenti, come
	  segue: il nome di una <cmdref targ="MIDAS_list"/>, due interi
	  col minimo e massimo ritardo ad alta frequenza, un intero fra
	  0 e 4, che specifica il tipo di parametrizzazione da usare, e
	  il nome di un vettore contenente i valori iniziali dei
	  parametri. L'esempio qui sotto usa i ritardi da 3 a 11 della
	  serie ad alta frequenza contenuta nella lista <lit>X</lit>,
	  usando la parametrizzazione di tipo 1 (Almon esponenziale,
	  vedi sotto) con inizializzazione <lit>theta</lit>.
	</para>
	<code context="cli">
	  mds(X, 3, 11, 1, theta)
	</code>
	<para context="cli">
	  <lit>mdsl</lit>: in gnere richiede 3 argomenti: il nome di
	  una lista di ritardi MIDAS, un intero per il tipo di
	  parametrizzazione e il nome di un vettore di valori
	  iniziali. In questo caso i ritardi minimo e massimo sono
	  impliciti nell'argomento lista iniziale. Nell'esempio
	  seguente <lit>Xlags</lit> deve essere una lista che contiene
	  già i ritardi necessari; essa può essere costruita tramite
	  la funzione <fncref targ="hflags"/> function.
	</para>
	<code context="cli">
	  mdsl(XLags, 1, theta)
	</code>
	<para context="cli">
	  I tipi di parametrizzazione sono disponibili come segue; nel
	  contesto <lit>mds</lit> e <lit>mdsl</lit> le specificazioni
	  in questione dovrebbero essere date in forma di codice numerio o
	  di stringhe virgolettate esposte dopo i numeri.
	</para>
	<para context="cli">
	  0 o <lit>"umidas"</lit>: <quote>MIDAS non vincolato</quote> o U-MIDAS (un
	  coefficiente per ritardo)
	</para>
	<para context="cli">
	  1 o <lit>"nealmon"</lit>: Almon esponenziale normalizzato; necessita di almeno un
	  parametro, di solito due
	</para>
	<para context="cli">
	  2 o <lit>"beta0"</lit>: beta normalizzato con zero finale; richiede due parametri
	</para>
	<para context="cli">
	  3 o <lit>"betan"</lit>: beta normalizzato senza zero finale; richiede tre parametri
	</para>
	<para context="cli">
	  4 o <lit>"almonp"</lit>: polinomio di Almon non normalizzato; richiede almeno un
	  parametro
	</para>
	<para context="cli">
	  Quando la parametrizzazione è U-MIDAS, l'argomento di
	  inzializzazione non è necessario con <lit>mds</lit> or
	  <lit>mdsl</lit>. In altri casi, si può richiedere
	  un'inizializzazione automatica sostituendo una di queste due
	  forme col nome di un vettore di parametri iniziali:
	</para>
	<ilist context="cli">
	  <li>
	    <para>
	      La parola chiave <lit>null</lit>: accettabile solo se la
	      parameterizzazione scelta ha un numero fisso di termini (i
	      casi beta, 2 o 3). È accettata anche nel caso di Almon
	      esponenziale, implicando come valori predifiniti 2 parametri.
	    </para>
	  </li>
	  <li>
	    <para>
	      Un intero col numero di parametri richiesto.
	    </para>
	  </li>
	</ilist>
	<para context="cli">
	  Il metodo di stima usato da questo comando dipende dalla
	  specificazione dei termini ad alta frequenza. Nel caso U-MIDAS
	  il metodo è l'OLS; in tutti gli altri casi si usano i minimi
	  quadrati non lineari (NLS). Quando si specificano le
	  parametrizzazioni Almon esponenziale normalizzata oppure beta
	  normalizzata, il metodo NLS di default è una combinazione di
	  BFGS vincolato e OLS, ma per forzare l'uso dell'algoritmo di
	  Levenberg&ndash;Marquardt si può usare l'opzione
	  <opt>levenberg</opt>.
	</para>
	<para context="gui">
	  Il metodo di stima usato da questo comando dipende dalla
	  specificazione dei termini ad alta frequenza. Nel caso U-MIDAS
	  il metodo è l'OLS; in tutti gli altri casi si usano i minimi
	  quadrati non lineari (NLS). Quando si specificano le
	  parametrizzazioni Almon esponenziale normalizzata oppure beta
	  normalizzata, il metodo NLS di default è una combinazione di
	  BFGS vincolato e OLS, a meno che non si selezioni la casella
	  <quote>Usa Levenberg-Marquardt per NLS</quote>.
	</para>
      </description>

      <gui-access>
	<menu-path>/Model/Time series/MIDAS</menu-path>
      </gui-access>
    </command>

    <command name="missing" section="Dataset" context="gui"
	     label="Valori dati mancanti">

      <description>
	<para>
	  Imposta un valore numerico che sarà interpretato come
	  <quote>mancante</quote> o <quote>non disponibile</quote>, per
	  una serie particolare (nel menù Variabile) o globalmente per
	  l'intero dataset (nel menù Campione).
	</para>
	<para>
	  Gretl ha un codice interno per i valori mancanti, che non
	  sempre può coincidere con quello usato dai dati importati. Ad
	  esempio, se una serie usa il valore -1 col significato di
	  <quote>non disponibile</quote>, è possibile selezionare
	  <quote>Imposta codice valori mancanti</quote> nel menù
	  Variabile e immettere il valore <quote>-1</quote> (senza le
	  virgolette); gretl interpreterà quindi i valori -1 come osservazioni
	  mancanti.</para>
	</description>
      </command>

  <command name="mdhelp" section="Programming" label="Markdown help"
    context="gui">

    <description>
      <para>
	In qusta finestra editor si possono inserire elementi markdown
	come segue. Nota bene: per <quote>immediatamente</quote>
	intendiamo "senza spazi in mezzo".
      </para>
      <ilist>
	<li>
	  <para>
	    Grassetto: Metti due asterischi (<lit>**</lit>)
	    immediatamente prima e dopo il testo.
	  </para>
	</li>
	<li>
	  <para>
	    Corsivo: Mettin un asterisco singolo immediatamente prima
	    e dopo il testo.
	  </para>
	</li>
	<li>
	  <para>
	    Spaziatura fissa: Metti un apostrofo rovesciato
	    (<lit>`</lit>) immediatamente prima e dopo il testo.
	  </para>
	</li>
	<li>
	  <para>
	    Intestazione di livello 1: Metti un cancelletto (<lit>#</lit>)
	    prima dell'intestazione, e lascia una linea vuota sotto.
	  </para>
	</li>
	<li>
	  <para>
	    Intestazione di livello 2: Metti due cancelletti prima
	    dell'intestazione, e lascia una linea vuota sotto.
	  </para>
	</li>
	<li>
	  <para>
	    Blocco di codice: Lascia una linea vuota, e poi metti tre
	    apostrofi rovesciti successivi (<lit>```</lit>) sulla
	    linea appena prima del codice, e altri tre appena sotto.
	  </para>
	</li>
	<li>
	  <para>
	    Elenco puntato: Lascia una linea vuota prima dell'elenco e
	    aggiungi un trattino e uno spazio (<quote><lit>- </lit></quote>)
	    prima di ogni elemento. Per ogni elemento, vai a capo.
	  </para>
	</li>
	<li>
	  <para>
	    Elenco numerato: Lascia una linea vuota prima dell'elenco
	    e aggiungi il numero, un punto e uno spazio (ad esempio,
	    <quote><lit>1. </lit></quote>) prima di ogni elemento. Per
	    ogni elemento, vai a capo.
	  </para>
	</li>
      </ilist>
      <para>
	L'icona con l'occhio produce un'anterprima del testo di
	help. Si noti che se il testo non contiene elementi markdown
	l'<quote>anteprima</quote> potrebbe non avere un bell'aspetto.
      </para>
    </description>
  </command>

  <command name="menu-attach" section="Programming"
	       label="Menu attachment" context="gui">
	<description>
	  <para>
	    Questa finestra di dialogo permette di specificare a quale
	    menu attaccare il pacchetto. A tal fine, bisogna riempire i
	    tre campi previsti.
	  </para>
	  <subhead>1. Etichetta</subhead>
	  <para>
	    Una breve stringa, che apparirà nel menu.
	  </para>
	  <subhead>2. Finestra</subhead>
	  <para>
	    Selezionare <quote>finestra del modello</quote> per un
	    pacchetto che fa qualcosa con un modello stimato da gretl, e
	    deve apparire nella barra del menu di un modello. In tutti gli
	    altri casi, selezionare <quote>finestra principale</quote>.
	  </para>
	  <subhead>3. Albero del menu</subhead>
	  <para>
	    Selezionare la posizione nell'albero del menu (per la finestra
	    principale o per la finestra del modello, come da scelta
	    sopra) dove il pacchetto deve apparire.
	  </para>
	  <subhead>Elementi opzionali</subhead>
	  <para>
	    In aggiunta è consentito utilizzare il pulsante <quote>GUI
	    testo guida</quote> per aggiungere o modificare un testo guida
	    GUI specifico, per visualizzare quando un pacchetto viene
	    chiamato dal menu. Inoltre, se si vuole richiamare il
	    pacchetto prescelto dalla finestra del modello è possibile
	    specificare un determinato tipo di modello (identificato dal
	    suo comando gretl) come requisito.
	  </para>
	</description>
      </command>

  <command name="mle" section="Estimation"
	   label="Stima di massima verosimiglianza">

    <usage>
      <arguments>
        <argument>funzione di log-verosimiglianza</argument>
        <argument optional="true">derivate</argument>
      </arguments>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampa il modello stimato</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--hessian</flag>
	  <effect>calcola la matrice di covarianza a partire dall'Hessiana</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>matrice di covarianza QML</effect>
	</option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>errori standard clusterizzati</effect>
        </option>
	<option>
	  <flag>--verbose</flag>
	  <effect>stampa i dettagli delle iterazioni</effect>
	</option>
	<option>
	  <flag>--no-gradient-check</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--auxiliary</flag>
	  <effect>vedi sotto</effect>
	</option>
	<option>
	  <flag>--lbfgs</flag>
	  <effect>usa L-BFGS-B anziché il BFGS standard</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>weibull.inp</demo>
	  <demo>biprobit_via_ghk.inp</demo>
	  <demo>frontier.inp</demo>
	  <demo>keane.inp</demo>
	</demos>
      </examples>
    </usage>

    <description context="gui">
      <para>
	Esegue la stima di massima verosimiglianza (ML, Maximum
	Likelihood) usando l'algoritmo BFGS (Broyden, Fletcher,
	Goldfarb, Shanno) o il metodo di Newton.  Occorre
	specificare la funzione di log-verosimiglianza, e se
	possibile è consigliabile indicare anche espressioni per le
	derivate di questa funzione, rispetto ad ognuno dei
	parametri.
      </para>
      <para>
	Questo messaggio di aiuto presuppone l'utilizzo dell'algoritmo
	di massimizzazione BFGS; per maggiori informazioni circa l'uso
	dell'algoritmo di Newton si consulti <guideref targ="chap:mle"/>.
      </para>
      <para>
	Esempio: si supponga di avere una serie <lit>X</lit> con
	valori 0 o 1 e di voler ottenere la stima di massima
	verosimiglianza della probabilità <lit>p</lit> che
	<lit>X</lit> valga 1 (è facile dimostrare che la stima ML di
	<lit>p</lit> corrisponderà alla proporzione dei valori 1 nel
	campione).
      </para>
      <para>
	Per prima cosa, occorre creare lo scalare <lit>p</lit> e
	assegnargli un valore iniziale usando il comando
	<cmd>genr</cmd> o i comandi del menù.  È possibile scrivere
	delle istruzioni <quote>genr</quote> appropriate nella
	finestra di specificazione del comando di stima, prima di
	indicare la specificazione della funzione di
	log-verosimiglianza.
      </para>
      <para>
	Si scrivano i seguenti comandi nella finestra del comando:
      </para>
      <code>
	loglik = X*log(p) + (1-X)*log(1-p)
	deriv p = X/p - (1-X)/(1-p)
      </code>
      <para>
	La prima riga specifica la funzione di log-verosimiglianza, mentre
	la seconda indica la derivata della funzione rispetto a p. Se non si
	indicano righe "deriv", viene calcolata un'approssimazione numerica
	delle derivate.
      </para>
      <para>
	Se non si era dichiarato in precedenza il parametro p, sarebbe stato
	necessario premettere alle righe precedenti la riga:
      </para>
      <code>
	scalar p = 0.5
      </code>
      <para>
	Per impostazione predefinita, gli errori standard sono basati
	sul prodotto esterno del gradiente (OPG). Se si richiedono errori
	standard robusti, viene usato uno stimatore QML (ossia, un
	sandwich dell'inversa negativa dell'Hessiana e della matrice
	di covarianza del gradiente).  L'Hessiana è approssimata
	numericamente.
      </para>
      <para>
	Per maggiori informazioni a riguardo della <cmd>massima
	verosimiglianza (mle)</cmd>, consultare <guideref
	targ="chap:mle"/>.
      </para>
    </description>

    <description context="cli">
      <para>
	Esegue la stima di massima verosimiglianza (ML, Maximum
	Likelihood) usando a scelta o l'algoritmo BFGS (Broyden,
	Fletcher, Goldfarb, Shanno) o quello di Newton.  Occorre
	specificare la funzione di log-verosimiglianza e dichiarare i
	valori iniziali per i parametri della funzione Se possibile è
	consigliabile indicare anche le espressioni per le derivate di
	questa funzione, rispetto ad ognuno dei parametri; se non si
	indicano le derivate analitiche, verrà calcolata
	un'approssimazione numerica.
      </para>
      <para>
	Questo messaggio di aiuto presuppone l'utilizzo dell'algoritmo
	di massimizzazione BFGS, per maggiori informazioni circa l'uso
	dell'algoritmo di Newton si consulti <guideref targ="chap:mle"/>.
      </para>
      <para>
	Esempio: si supponga di avere una serie <lit>X</lit> con
	valori 0 o 1 e di voler ottenere la stima di massima
	verosimiglianza della probabilità <lit>p</lit> che
	<lit>X</lit> valga 1 (è semplice intuire che la stima ML di
	<lit>p</lit> corrisponderà alla proporzione dei valori 1 nel
	campione).
      </para>
      <para>
	Occorre per prima cosa aggiungere <lit>p</lit> al dataset e
	assegnargli un valore iniziale; ad esempio,
      </para>
      <code>
	scalar p = 0.5
      </code>
      <para>
	Quindi costruiamo il blocco di comandi per la stima di massima
	verosimiglianza:
      </para>
      <code>
	mle loglik = X*log(p) + (1-X)*log(1-p)
	deriv p = X/p - (1-X)/(1-p)
	end mle
      </code>
      <para>
	La prima riga specifica la funzione di log-verosimiglianza:
	inizia con la parola chiave <lit>mle</lit>, quindi contiene la
	variabile dipendente e una specificazione per la
	log-verosimiglianza usando la stessa sintassi del comando
	<cmd>genr</cmd>. La riga seguente (che è opzionale), inizia
	con la parola chiave <lit>deriv</lit> e fornisce la derivata
	della funzione di log-verosimiglianza rispetto al parametro
	<lit>p</lit>. Se non vengono indicate derivate, occorre
	includere una dichiarazione che identifica i parametri liberi
	(separati da spazi) utilizzando la parola chiave
	<lit>params</lit>; questi parametri liberi possono essere sia
	scalari, che vettori, che una qualsiasi combinazione dei
	due. Ad esempio si sarebbe potuto scrivere:
      </para>
      <code>
	mle loglik = X*log(p) + (1-X)*log(1-p)
	params p
	end mle
      </code>
      <para>
	e in questo caso la derivata verrebbe calcolata numericamente.
      </para>
      <para>
	Si noti che eventuali opzioni vanno indicate nella riga finale del blocco
	MLE. Ad esempio:
      </para>
      <code>
	mle loglik = X*log(p) + (1-X)*log(1-p)
	  params p
	end mle --quiet
      </code>
      <subhead>Matrice di covarianza ed errori standard</subhead>
      <para>
	Se la funzione di log-verosimiglianza restituisce una
	variabile o un vettore per ogni valore delle osservazioni
	allora gli errori standard sono, per impostazione predefinita,
	basati sul prodotto esterno del gradiente (OPG), mentre se
	l'opzione <opt>hessian</opt> è fornita allora quest'ultimi
	saranno ottenuti sulla base dell'inversa negativa della
	matrice hessiana, la quale verrà approssimata numericamente.
	Se l'opzione <opt>robust</opt> è data allora verrà utilizzato
	uno stimatore di quasi-massima verosimiglianza (QML), ossia
	uno stimatore ottenuto dal sandwich dell'inversa negativa
	della matrice hessiana e del prodotto esterno del gradiente
	(OPG). In ogni caso, se la funzione di log-verosimiglianza
	restituisce semplicemente un valore scalare il metodo OPG non
	risulta disponibile (come anche lo stimatore QML), e gli
	errori standard sono necessariamente calcolati usando
	l'hessiana numerica.
      </para>
      <para>
	Nel caso in cui si volesse solo il parametro primario delle
	stime è possibile dare l'opzione <opt>auxiliary</opt>, la
	quale sopprime il calcolo della matrice di covarianza e degli
	errori standard; questo permetterà di risparmiare alcuni cicli
	della CPU, salvando anche un po' di memoria.
      </para>
      <subhead>Controllo delle derivate analitiche</subhead>
      <para>
	Se si forniscono le derivate analitiche della funzione di
	log-verosimiglianza, di default gretl esegue un controllo
	numerico circa la loro attendibilità. Occasionalmente, questo
	controllo potrebbe produrre dei falsi positivi, ovvero casi in
	cui derivate calcolate correttamente vengono segnalate come
	errate e di cui la stima viene quindi negata.  Per impedire
	che ciò accada, o per aggiungere un poco di velocità in più al
	processo, è possibile dare l'opzione
	<opt>no-gradient-check</opt>.  Ovviamente questo andrebbe
	fatto solo nel caso in cui si è assolutamente sicuri che il
	gradiente dato in specifica è corretto.
      </para>
      <subhead>Nomi dei parametri</subhead>
      <para>
	Quando si stima un modello non lineare spesso risulta
	conveniente nominare i parametri in maniera concisa. Nella
	stampa dei risultati, comunque, risulta desiderabile che le
	etichette data siano le più informative e sintetiche
	possibili. Questo risultato pyò venire ottenuto aggiungendo la
	parola chiave <lit>param_names</lit> all'interno del blocco di
	comando. Per un modello con <math>k</math> parametri
	l'argomento successivo a questa parola chiave può essere sia
	una stringa di testo, messa tra virgolette, contenente
	<math>k</math> nomi separati da uno spazio, sia il nome di una
	stringa di variabili avente al suo interno tutti i
	<math>k</math> nomi.
      </para>
      <para>
	Per maggiori informazioni circa la massima verosimiglianza
	(<cmd>mle</cmd>) raccomandiamo di consultare <guideref
	targ="chap:mle"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Massima verosimiglianza</menu-path>
    </gui-access>

  </command>

  <command name="modeltab" section="Utilities"
	   label="Tabella modelli">

    <usage>
      <altforms>
	<altform><lit>modeltab add</lit></altform>
	<altform><lit>modeltab show</lit></altform>
	<altform><lit>modeltab free</lit></altform>
	<altform><lit>modeltab --output=</lit><repl>nomefile</repl></altform>
	<altform><lit>modeltab --options=</lit><repl>bundle</repl></altform>
      </altforms>
    </usage>

    <description context="gui">
      <para>
	Nella ricerca econometrica, è comune stimare vari modelli per
	la stessa variabile dipendente, che differiscono tra loro per
	le variabili indipendenti o per il tipo di stimatore usato. In
	questa situazione è comodo poter rappresentare i risultati
	delle regressioni sotto forma di una tabella dove ogni colonna
	contiene i risultati (stime dei coefficienti e errori
	standard) per un dato modello e ogni riga contiene le stime
	per una certa variabile nei differenti modelli.
      </para>
      <para>
	Gretl dà la possibilità di costruire una tabella simile (e
	di esportarla in testo semplice, &latex; o RTF - Rich Text Format).
	Ecco come fare:
      </para>
      <nlist>
	<li>
	  <para>
	    Stimare un modello che si vuole includere nella
            tabella e selezionare, nel menù File della finestra di
            visualizzazione del modello, <quote>Salva alla sessione come
            icona</quote> o <quote>Salva come icona e chiudi</quote>.
          </para>
	</li>
	<li>
          <para>
            Ripetere il punto 1 per gli alri modelli da
            includere nella tabella (fino a un massimo di sei modelli).
          </para>
	</li>
	<li>
          <para>
            Completata la stima dei modelli, aprire l'icona della
            sessione di gretl (selezionando <quote>Visualizza
            Icone</quote> nel menù Sessione della finestra
            principale di gretl, o facendo clic su <quote>Finestra
            icone</quote> sulla barra degli strumenti di gretl).
	  </para>
	</li>
	<li>
	  <para>
	    La finestra delle icone contiene un'icona chiamata
	    <quote>Tabella Modelli</quote>. Per aggiungere alla
	    tabella modelli il modello che deve apparire nella
	    colonna più a sinistra della tabella, basta trascinare
	    l'icona del modello sull'icona della <quote>Tabella
	    Modelli</quote>, oppure fare clic col tasto destro
	    sull'icona del modello e selezionare <quote>Aggiungi
	    alla tabella modelli</quote> dal menù pop-up.
	  </para>
	</li>
	<li>
	  <para>
	    Ripetere il punto 4 per gli altri modelli da aggiungere alla tabella.
	    Il secondo modello scelto apparirà nella seconda colonna da sinistra
	    della tabella, e così via.
	  </para>
	</li>
	<li>
	  <para>
	    Ultimata la composizione della tabella, è possibile
	    visualizzarla facendo doppio clic sulla sua icona. Per copiare
	    la tabella negli appunti in uno dei formati supportati, basta
	    fare clic sul menù Modifica della finestra in cui appare la
	    tabella.
	  </para>
	</li>
	<li>
	  <para>
	    Se l'ordinamento dei modelli nella tabella non è
	    quello voluto, fare clic col tasto destro sull'icona della
	    tabella modelli e selezionare <quote>Pulisci</quote>, quindi
	    tornare al punto 4.
	  </para>
	</li>
      </nlist>
    </description>

    <description context="cli">
      <para>
	Manipola la <quote>tabella modelli</quote> di gretl. Si veda
	<guideref targ="chap:modes"/> per i dettagli. Le opzioni
	hanno i seguenti effetti: <cmd>add</cmd> aggiunge l'ultimo
	modello stimato alla tabella modelli, se possibile;
	<cmd>show</cmd> mostra la tabella modelli in una finestra;
	<cmd>free</cmd> pulisce la tabella.
      </para>
      <para>
	Per stampare la tabella del modello, si usi l'opzione
	<opt>output=</opt> seguita dal nome di un file. Se
	quest'ultimo ha il suffisso <quote><lit>.tex</lit></quote>,
	l'output sarà in formato &tex;; se il suffisso è
	<quote><lit>.rtf</lit></quote> l'output sarà RTF; in caso
	contrario sarà in formato di testo. Nel caso di output in
	formato &tex; per default verrà prodotto un
	<quote>frammento</quote> pronto per essere inserito in un
	documento; se invece si preferisce ottenere un documento
	completo, usate l'opzione <opt>complete</opt>; per esempio,
      </para>
      <code>
	modeltab --output="myfile.tex" --complete
      </code>
      <para>
	L'opzione <opt>options=</opt>, che richiede il nome di un
	bundle gretl, può essere utilizzato per controllare alcuni
	aspetti della formattazione della tabella del modello. Vengono
	riconosciute le seguenti chiavi:
      </para>
      <ilist>
	<li>
	  <para>
	    <lit>colheads</lit>: intero da 1 a 4, seleziona tra i
	    quattro stili di intestazione di colonna supportati:
	    numerazione araba, numerazione romana, alfabetico o
	    utilizzando i nomi con cui sono stati salvati i
	    modelli. Il valore predefinito è 1 (numerazione araba).
          </para>
       </li>
       <li>
	 <para>
	   <lit>tstats</lit>: booleano, sostituisce o meno gli errori
	   standard con le statistiche t (default 0).
         </para>
       </li>
       <li>
	 <para>
	   <lit>pvalues</lit>: booleano, include o meno i 
	   <math>P</math>-vaue (default 0).
         </para>
       </li>
       <li>
	 <para>
	   <lit>asterisks</lit>: booleano, mostra o meno gli
	   asterischi del livello di significatività (default 1).
         </para>
       </li>
       <li>
	 <para>
	   <lit>digits</lit>: intero da 2 a 6, seleziona il numero di
	   cifre significative visualizzate (default 4).
         </para>
       </li>
       <li>
	 <para>
	   <lit>decplaces</lit>: intero da 2 a 6, seleziona il numero
	   di cifre decimali visualizzate.
        </para>
      </li>
      </ilist>
      <para>
	Si noti che le ultime due chiavi si escludono a
	vicenda, poiché offrono modi alternativi per specificare la
	precisione con cui vengono visualizzati i valori numerici: in
	termini di cifre significative o cifre decimali. Il valore
	predefinito è 4 cifre significative.
      </para>
      <para>
	Un bundle di opzioni può essere fornito tramite un comando
	autonomo (come nell'ultimo degli esempi sopra) oppure può
	essere combinato con l'azione <lit>show</lit> o l'opzione
	<opt>output</opt>. Ad esempio, il seguente script crea una
	semplice tabella di modelli e la visualizza, con i
	<math>P</math>-value visualizzati invece degli asterischi:
       </para>
      <code>
	open data9-7
	ols 1 0 2 3 4
	modeltab add
	ols 1 0 2 3
	modeltab add
	bundle myopts = _(pvalues=1, asterisks=0)
	modeltab show --options=myopts
      </code>
    </description>

    <gui-access>
      <menu-path>Finestra delle icone, Icona Tabella Modelli</menu-path>
    </gui-access>

  </command>

  <command name="modprint" section="Printing"
	   label="Stampa un modello definito dall'utente" context="cli">

    <usage>
      <arguments>
	<argument>matcoeff</argument>
	<argument>nomi</argument>
	<argument optional="true">stat</argument>
      </arguments>
      <options>
	<option>
	  <flag>--output</flag>
	  <optparm>filename</optparm>
	  <effect>invia l'output al file specificato</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Stampa la tabella dei coefficienti e le statistiche aggiuntive
	opzionali per un modello stimato <quote>a mano</quote>. Utile
	principalmente per le funzioni definite dall'utente.
      </para>
      <para>
	L'argomento <repl>matcoeff</repl> deve essere una matrice
	<math>k</math> per 2 che contiene i <math>k</math>
	coefficienti stimati nella prima colonna ed i <math>k</math>
	relativi errori standard associati nella seconda. L'argomento
	<repl>nomi</repl> deve fornire almeno <math>k</math> etichette
	per i coefficienti. Può avere la forma di una stringa fissa
	(fra virgolette doppie) o di una variabile di tipo stringa,
	nel qual caso le etichette vanno separate con spazi oppure
	virgole. Alternativamente, si può usare allo scopo un array di
	stringhe.
      </para>
      <para>
	L'argomento opzionale <repl>stat</repl> è un vettore che
	contiene <math>p</math> statistiche aggiuntive da stampare
	sotto la tabella dei coefficienti. Se si usa questo argomento,
	<repl>nomi</repl> deve contenere <math>k + p</math> stringhe
	di cui le ultime <math>p</math> sono relative alle statistiche
	aggiuntive.
      </para>
      <para>
	Per inviare l'output ad un file, usate l'opzione
	<opt>output=</opt> seguita dal nome di un file. Se
	quest'ultimo ha il suffisso <quote><lit>.tex</lit></quote>,
	l'output sarà in formato &tex;; se il suffisso è
	<quote><lit>.rtf</lit></quote> l'output sarà RTF; in caso
	contrario sarà in formato di testo. Nel caso di output in
	formato &tex; per default verrà prodotto un
	<quote>frammento</quote> pronto per essere inserito in un
	documento; se invece si preferisce ottenere un documento
	completo, usate l'opzione <opt>complete</opt>.
      </para>
      <para>
	Il file di output verrà scritto nella directory corrispondente
	al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
	di file contenga un percorso completo.
      </para>
    </description>

  </command>

  <command name="modtest" section="Tests" label="Test LM">

    <usage>
      <arguments>
	<argument optional="true">ordine</argument>
      </arguments>
      <options>
	<option>
	  <flag>--normality</flag>
	  <effect>normalità dei residui</effect>
	</option>
	<option>
	  <flag>--logs</flag>
	  <effect>non linearità, logaritmi</effect>
	</option>
	<option>
	  <flag>--squares</flag>
	  <effect>non linearità, quadrati</effect>
	</option>
	<option>
	  <flag>--autocorr</flag>
	  <effect>autocorrelazione</effect>
	</option>
	<option>
	  <flag>--arch</flag>
	  <effect>ARCH</effect>
	</option>
	<option>
	  <flag>--white</flag>
	  <effect>test di White per l'eteroschedasticità</effect>
	</option>
	<option>
	  <flag>--white-nocross</flag>
	  <effect>test di White per l'eteroschedasticità cono solo i quadrati</effect>
	</option>
	<option>
	  <flag>--breusch-pagan</flag>
	  <effect>test per l'eteroschedasticità di Breusch&ndash;Pagan</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>stima robusta della varianza per Breusch&ndash;Pagan</effect>
	</option>
	<option>
	  <flag>--panel</flag>
	  <effect>eteroschedasticità, a gruppi</effect>
	</option>
	<option>
	  <flag>--comfac</flag>
	  <effect>restrizione a fattor comune, solo per modelli AR1</effect>
	</option>
	<option>
	  <flag>--xdepend</flag>
	  <effect>dipendenza cross-section, solo per dati panel</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i dettagli</effect>
	</option>
	<option>
	  <flag>--silent</flag>
	  <effect>non mostra i risultati</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>credscore.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Deve seguire immediatamente un comando di stima. La
	discussione che segue è relativa all'esecuzione del comando
	dopo la stima di un modello ad equazione singola; si veda
	<guideref targ="chap:var"/> per una descrizione di come
	funziona <cmd>modtest</cmd> dopo la stima di un VAR
      </para>
      <para>
	A seconda dell'opzione usata, il comando esegue uno dei test
	seguenti: test di Doornik&ndash;Hansen per la normalità del
	termine di errore; test dei moltiplicatori di Lagrange per la
	non-linearità (logaritmi o quadrati); test di White (con o
	senza i prodotti incrociati) o test di Breusch&ndash;Pagan per
	l'eteroschedasticità (<cite key="breusch-pagan79">Breusch e
	Pagan, 1979</cite>), test LMF per la correlazione seriale (si
	veda <cite key="kiviet86" p="true">(Kiviet, 1986)</cite>);
	test per il modello ARCH (Autoregressive Conditional
	Heteroskedasticity, si veda anche il comando <cmd>arch</cmd>);
	o restrizione a fattore comune, (solo modelli AR1); o un test
	per la dipendenza tra unità cross-sectio in caso di modelli
	con dati panel. Ad eccezione dei test sulla normalità, a
	fattor comune e sulla dipendenza cross-section, la maggior
	parte dei test risultano disponibili solo in caso di stima
	OLS; per ulteriori dettagli circa lo stimatore TSLS (two-stage
	least squares) si veda oltre.
      </para>
      <para>
	L'argomento opzionale <lit>ordine</lit> è rilevante solo nel
	caso si scelga l'opzione <opt>autocorr</opt> o l'opzione
	<opt>arch</opt>.  Per impostazione predefinita, questi test
	sono eseguiti usando un ordine di ritardo pari alla
	periodicità dei dati, ma è possibile anche impostare un ordine
	di ritardo specifico.
      </para>
      <para>
	L'opzione <opt>robust</opt> ha effetto solo se viene scelto il
	test di Breusch&ndash;Pagan; l'effetto è quello di usare lo
	stimatore robusto per la varianza proposto da <cite
	key="koenker81">Koenker (1981)</cite>, rendendo il test meno
	sensibile all'ipotesi di normalità.
      </para>
      <para>
	L'opzione <opt>panel</opt> è disponibile solo se il modello
	viene stimato su dati panel: in questo caso viene eseguito un
	test per eteroschedasticità a gruppi (ossia per una varianza
	dell'errore diversa fra le unità cross section).
      </para>
      <para>
	L'opzione <opt>comfac</opt> è disponibile solo quando il
	modello è stimato usando un metodo AR(1), come quello di
	Hildreth&ndash;Lu. La regressione ausiliaria ha la struttura
	di un modello dinamico relativamente poco vincolato ed è usata
	per verificare il vincolo di fattori comuni implicito nella
	specificazione AR(1).
      </para>
      <para>
	L'opzione <opt>xdepend</opt> è disponibile solo se il modello
	viene stimato su dati panel. La statistica test è sviluppata
	secondo il metodo di <cite key="pesaran04">Pesaran
	(2004)</cite>.  L'ipotesi nulla riguarda il termine di errore
	assunto come indipendentemente distribuito per tutte le
	osservazioni cross-section o gli individui.
      </para>
      <para>
	Per impostazione predefinita il programma mostra la
	regressione ausiliaria sulla quale la statistica test è
	basata, laddove possibile.  Questa funzione può venir
	soppressa utilizzando o l'opzione <opt>quiet</opt> (che mostra
	le informazioni strettamente necessarie) oppure con l'opzione
	<opt>silent</opt> (che non mostra alcuna informazione). La
	statistica test ed il relativo p-value possono essere
	richiamati utilizzando gli accessori <fncref targ="$test"/> e
	<fncref targ="$pvalue"/>.
      </para>
      <para>
	Nel caso di modelli stimati col metodo dei minimi quadrati a
	due stadi (si veda <cmdref targ="tsls"/>), non è possibile
	usare il test LM, quindi gretl offre alcuni test equivalenti;
	in questo caso, l'opzione <flag>--autocorr</flag> calcola il
	test di Godfrey per l'autocorrelazione (si veda <cite
	key="godfrey94" p="true">Godfrey, 1994</cite>), mentre
	l'opzione <flag>--white</flag> produce il test HET1 per
	l'eteroschedasticità (si veda <cite key="pesaran99"
	p="true">Pesaran e Taylor, 1999</cite>.
      </para>
      <para>
	Per ulteriori test diagnostici sui modelli si vedano anche le
	voci <cmdref targ="chow"/>, <cmdref targ="cusum"/>, <cmdref
	targ="reset"/> e <cmdref targ="qlrtest"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test</menu-path>
    </gui-access>

  </command>

  <command name="mpi" section="Programming"
	   label="Message Passing Interface">
    <usage>
      <arguments>
	<argument>vedi oltre</argument>
      </arguments>
    </usage>
    <description>
      <para>
	Il comando <lit>mpi</lit> si trova all'inizio di un blocco
	(che termina con <lit>end mpi</lit>) eseguito usando la
	parallelizzazione MPI (Message Passing Interface). Si veda il
	documento <doc>gretl-mpi.pdf</doc> (in inglese) per una
	descrizione completa.
      </para>
    </description>
  </command>

  <command name="mpols" section="Estimation"
	   label="Stima OLS a precisione multipla">

    <usage>
      <arguments>
	<argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--simple-print</flag>
	  <effect>non mostra le statistiche ausiliarie</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non mostra i risultati</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Calcola le stime OLS per il modello indicato usando aritmetica
	in virgola mobile a precisione multipla. Questo comando è
	disponibile solo se <program>gretl</program> è compilato con
	il supporto per la libreria Gnu Multiple Precision (GMP). Per
	impostazione predefinita, vengono usati 256 bit di precisione
	nei calcoli, ma è possibile aumentare questo valore usando la
	variabile d'ambiente <lit>GRETL_MP_BITS</lit>.  Ad esempio,
	usando l'interprete dei comandi bash, è possibile aumentare la
	precisione a 1024 bit eseguendo il comando seguente prima di
	avviare gretl
      </para>
      <code>
	export GRETL_MP_BITS=1024
      </code>
      <para context="cli">
	Per questo comando è disponibile un'opzione abbastanza speciale (utile
	soprattutto a scopo di test): se la lista <repl>variabili-indipendenti</repl>
	è seguita da un punto e virgola, e da un'ulteriore lista di numeri,
	questi numeri vengono interpretati come potenze di <repl>x</repl> da aggiungere
	alla regressione, dove <repl>x</repl> è l'ultima variabile della lista
	<repl>variabili-indipendeti</repl>. Questi termini addizionali vengono
	calcolati e memorizzati in precisione multipla. Nell'esempio seguente,
	<lit>y</lit> è regredita su <lit>x</lit> e sulla seconda, terza e quarta
	potenza di <lit>x</lit>:
      </para>
      <code context="cli">
	mpols y 0 x ; 2 3 4
      </code>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/MPOLS - Minimi quadrati in alta precisione</menu-path>
    </gui-access>

  </command>

<command name="nadarwat" section="Estimation" label="Nadaraya-Watson"
	 context="gui">
  <description>
    <para>
      Calcola lo stimatore nonparametrico di Nadaraya&ndash;Watson
      per la media condizionale della variabile dipendente,
      <math>m(x)</math>, per ogni valore valido della variabile
      <math>x</math>.
    </para>
    <para>
      La funzione kernel <math>K</math> è data da <math>K =
      exp(-x</math><sup>2</sup><math> / 2h)</math> per <math>|x|
      &lt; T</math> e zero altrove. <math>T</math> è un parametro
      di rifinitura che di default è impostato su 4<math>h</math>.
    </para>
    <para>
      L'ampiezza di banda, che di solito è un numero piccolo,
      controlla quanto liscia debba essere la funzione
      <math>m(x)</math> (più è alto il valore, più liscia sarà la
      funzione); per impostazione predefinita quest'ultimo è un valore
      determinato dai dati proprozionale a <math>n</math><sup>-0.2</sup>,
      dove <math>n</math> è l'ampiezza del campione.
    </para>
    <para>
      Se viene spillata la casella <quote>escludine uno</quote>,
      verrà usata una variante dello stimatore in cui la
      <math>i</math>-esima osservazione non viene usata per
      calcolare <math>m(x</math><sub>i</sub><math>)</math>. Questo
      rende lo stimatore Nadaraya&ndash;Watson più robusto
      numericamente e il suo uso è, di norma, consigliabile quando
      lo stimatore è usato per l'inferenza.
    </para>
    <para>
      Per maggiori dettagli in merito alla stima non-parametrica si
      veda <guideref targ="chap:nonparam"/>.
    </para>
  </description>
</command>

<command name="negbin" section="Estimation"
	 label="Negative Binomial regression">

  <usage>
    <arguments>
      <argument>depvar</argument>
      <argument>indepvars</argument>
      <argument separated="true" optional="true">offset</argument>
    </arguments>
    <options>
      <option>
	<flag>--model1</flag>
	<effect>usa il modello NegBin 1</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>matrice di covarianza QML</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>vedi <cmdref targ="logit"/> per una spegazione</effect>
      </option>
      <option>
	<flag>--opg</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>stampa la matrice di covarianze</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>camtriv.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Stima un modello Binomiale Negativo.  Il comando assume che la
      variabile dipendente rappresenti un conteggio del numero di
      volte in cui si è verificato un certo evento e deve assumere
      solo valori interi non negativi. Di default, viene usata la
      distribuzione NegBin 2, in cui la varianza condizionale è data
      da &mu;(1 + &alpha;&mu;), dove &mu; denota la media
      condizionale.  Tuttavia, se vien data l'opzione
      <opt>model1</opt> allora la varianza condizionale sarà data
      da &mu;(1 + &alpha;).
    </para>
    <para>
      L'argomento opzionale <lit>offset</lit> funziona come per il
      comando <cmdref targ="poisson"/>.  In effetti, il modello di
      Poisson è un caso particolare del binomiale negativo con
      &alpha; = 0.
    </para>
    <para>
      Di default, gli errori standard vengono calcolati unsando
      un'approssimazione numerica dell'Hessiana sul punto di
      massimo.  Con l'opzione <opt>opg</opt> la matrice di
      covarianze verrà invece calcolata tramite il prodotto esterno
      dei gradienti (OPG), o via QML con l'opzione <opt>robust</opt> usando un
      <quote>sandwich</quote> dell'hessiana inversa e dell'OPG.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modelli/Modelli non lineari/Dati di conto</menu-path>
  </gui-access>
</command>

<command name="nls" section="Estimation" label="Minimi quadrati non-lineari">

  <usage>
    <arguments>
      <argument>funzione</argument>
      <argument optional="true">derivate</argument>
    </arguments>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa il modello stimato</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--no-gradient-check</flag>
	<effect>si veda oltre</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>wg_nls.inp</demo>
	<demo>ects_nls.inp</demo>
      </demos>
    </examples>
  </usage>

  <description context="gui">
    <para>
      Esegue una stima con minimi quadrati non-lineari (NLS:
      Nonlinear Least Squares) usando una versione modificata
      dell'algoritmo di Levenberg&ndash;Marquardt. Occorre fornire
      una specificazione di funzione e si raccomanda di specificare
      anche le espressioni per le derivate di questa funzione
      rispetto a ognuno dei parametri, se possibile. Se non si
      indicano le derivate, occorre fornire una lista dei parametri
      da stimare (separati da spazi o virgole), preceduta dalla
      parola chiave <lit>params</lit>; quest'ultimi possono essere
      sia scalari che vettori, che una qualsiasi combinazione tra i
      due.
    </para>
    <para>
      Esempio: si supponga di avere un dataset con le variabili
      <math>C</math> e <math>Y</math> (&eg; <lit>greene11_3.gdt</lit>)
      e di voler stimare una funzione di consumo non-lineare del tipo:
      <equation status="display"
		tex="\[C = \alpha + \beta Y^{\gamma}\]"
		ascii="C = alfa + beta * Y^gamma"
		graphic="greene_Cfunc"/>
    </para>
    <para>
      I parametri alfa, beta e gamma devono per prima cosa
      essere aggiunti al dataset, con i relativi valori iniziali
      indicati. Le linee appropriate possono essere digitate in
      seguito nella finestra di specificazione degli NLS prima di
      specificare la funzione obiettivo.
    </para>
    <para>
    Nella finestra NLS si inseriranno le righe seguenti:</para>
    <code>
      C = alfa + beta * Y^gamma
      deriv alfa = 1
      deriv beta = Y^gamma
      deriv gamma = beta * Y^gamma * log(Y)
    </code>
    <para>
      La prima riga indica la specificazione della funzione, mentre
      le righe successive forniscono le derivate della funzione rispetto
      ad ognuno dei tre parametri. Se non vengono fornite le righe
      "deriv", viene calcolata un'approssimazione numerica del
      Jacobiano.
    </para>
    <para>
      Se i parametri alfa, beta e gamma non sono stati dichiarati in precedenza,
      è possibile premettere alle righe viste sopra le seguenti:
    </para>
    <code>
      scalar alpha = 1
      scalar beta = 1
      scalar gamma = 1
    </code>
    <para>
      Per ulteriori dettagli sulla stima NLS si veda <guideref
      targ="chap:nls"/>.
    </para>
  </description>

  <description context="cli">
    <para>
      Esegue una stima con minimi quadrati non-lineari (NLS:
      Nonlinear Least Squares) usando una versione modificata
      dell'algoritmo di Levenberg&ndash;Marquardt. Occorre fornire
      una specificazione di funzione e dichiarare i parametri di
      interesse della funzione ed i relativi valori iniziali prima
      che la stima venga eseguita.  Opzionalmente, è anche possibile
      specificare le espressioni per le derivate della funzione
      rispetto a ognuno dei parametri. Se non si indicano le
      derivate, occorre fornire una lista dei parametri da stimare
      (separati da spazi o virgole), preceduta dalla parola chiave
      <lit>params</lit>. In quest'ultimo caso, viene calcolata
      un'approssimazione numerica del Jacobiano.
      </para>
      <para>
	È più semplice mostrare il funzionamento con un esempio. Quello
        che segue è uno script completo per stimare la funzione di
        consumo non-lineare presentata in <book>Econometric
        Analysis</book> di William Greene (capitolo 11 della quarta
        edizione, o capitolo 9 della quinta). I numeri alla sinistra
        delle righe sono dei punti di riferimento e non fanno parte dei
      comandi. Si noti che le opzioni, come ad esempio <opt>vcv</opt>
      per mostrare la matrice di covarianza delle stime dei parametri,
      vanno aggiunte al comando finale <lit>end nls</lit>.
      </para>
      <code>
	1   open greene11_3.gdt
	2   ols C 0 Y
	3   genr a = $coeff(0)
	4   genr b = $coeff(Y)
	5   genr g = 1.0
	6   nls C = a + b * Y^g
	7   deriv a = 1
	8   deriv b = Y^g
	9   deriv g = b * Y^g * log(Y)
	10  end nls --vcv
      </code>

      <para>
	Spesso è comodo inizializzare i parametri con riferimento a un
        modello lineare collegato, come è mostrato nelle righe da 2 a 5.
	I parametri alfa, beta e gamma possono essere impostati a
        qualunque valore iniziale (non necessariamente sulla base di un
        modello stimato con OLS), ma la convergenza della procedura NLS
        non è garantita per qualunque punto di partenza.
      </para>
      <para>
	I veri comandi NLS occupano le righe da 6 a 10. Sulla riga 6
        viene dato il comando <cmd>nls</cmd>: viene specificata una
        variabile dipendente, seguita dal segno uguale, seguito da una
        specificazione di funzione. La sintassi per l'espressione a
        destra è la stessa usata per il comando <cmd>genr</cmd>. Le tre
        righe successive specificano le derivate della funzione di
        regressione rispetto a ognuno dei parametri. Ogni riga inizia
        con il comando <cmd>deriv</cmd>, che indica il nome di un parametro,
        il segno di uguale e un'espressione che indica come calcolare la
        derivata (anche qui la sintassi è la stessa di <cmd>genr</cmd>).
        In alternativa, invece di fornire le derivate, è possibile sostituire
        le righe dalla 7 alla 9 con la seguente:
      </para>
      <code>
	params a b g
      </code>
      <para>
        La riga 10, <cmd>end nls</cmd>, completa il comando ed esegue la stima.
      </para>
      <para>
	Se si forniscono le derivate in forma analitica, di default
	gretl effettuerà una verifica numerica sulla correttezza
	dell'espressione data. Occasionalmente, questa procedura
	potrebbe produrre <quote>falsi positivi</quote>, ad esempio
	indicando come errate delle derivate che invece sono correte,
	facendo si che la stima di quest'ultime venga negata. Per
	evitare che ciò accada, e/o per compilare leggermente più
	velocemente il codice, è possibile utilizzare l'opzione
	<opt>no-gradient-check</opt>. Ovviamente questo andrebbe fatto
	solo in caso di assoluta certezza circa la correttezza delle
	derivate analitiche.
      </para>
      <subhead>Nomi dei parametri</subhead>
      <para>
	Quando si stima un modello non lineare spesso risulta
	conveniente rinominare i parametri in maniera
	sintetica. Durante la stampa del risultato, comunque, è
	desiderabile che le etichette date, per quanto sintetiche,
	risultino le più informative possibili. Questo risultato può
	essere ottenuto aggiungendo al comando la parola chiave
      <lit>param_names</lit>. Per un modello con <math>k</math>
      parametri l'argomento che segue a questa parola chiave
      dovrebbe essere o una stringa letterale, posta tra virgolette,
      contenente <math>k</math> nomi diversi separati da spazi o
      virgole, oppure il nome di un vettore contente un lista di
      nomi <math>k</math> di variabile al suo interno.
      </para>
      <para>
	Per ulteriori dettagli sulla stima NLS si veda <guideref
	targ="chap:nls"/>.
      </para>
      </description>

      <gui-access>
<menu-path>/Modello/Modelli non lineari/NLS - Minimi quadrati non lineari</menu-path>
</gui-access>

</command>

<command name="normtest" section="Tests" label="Test di normalità">

  <usage>
    <arguments>
<argument>series</argument>
</arguments>
<options>
  <option>
<flag>--dhansen</flag>
<effect>test di Doornik&ndash;Hansen, utilizzato di default</effect>
</option>
<option>
<flag>--swilk</flag>
<effect>test di Shapiro&ndash;Wilk</effect>
</option>
<option>
<flag>--lillie</flag>
<effect>test di Lilliefors</effect>
</option>
<option>
<flag>--jbera</flag>
<effect>test di Jarque&ndash;Bera</effect>
</option>
<option>
<flag>--all</flag>
<effect>esegue tutti i test</effect>
</option>
<option>
<flag>--quiet</flag>
<effect>non mostra i dettagli dei risultati</effect>
</option>
</options>
</usage>

<description>
  <para>
Conduce un test di normalità per la <repl>serie</repl>
specificata. Il tipo di test eseguito è determinato dalle
opzioni del comando (se non ne viene usata alcuna, viene
eseguito il test di Doornik&ndash;Hansen).  Nota: si
raccomanda l'utilizzo dei test di Doornik&ndash;Hansen e
Shapiro&ndash;Wilk rispetto agli altri test per via delle
loro migliori proprietà in campioni relativamente
piccoli.
</para>
<para>
  La statistica test e il suo p-value possono essere
  recuperati usando gli accessori <fncref targ="$test"/> e
  <fncref targ="$pvalue"/>. Se si usa l'opzione
  <opt>all</opt>, i risultati richiamati saranno quelli del
  test di Doornik&ndash;Hansen.
</para>
</description>

</command>

<command name="nulldata" section="Dataset"
	 label="Creazione di un dataset vuoto">

  <usage>
    <arguments>
<argument>lunghezza_serie</argument>
</arguments>
<options>
  <option>
<flag>--preserve</flag>
<effect>preserva le matrici</effect>
</option>
</options>
<examples>
<example>nulldata 500</example>
</examples>
</usage>

<description>
  <para>
    Crea un dataset <quote>vuoto</quote>, che contiene solo una
    costante e una variabile indice, con periodicità 1 e il numero
    indicato di osservazioni. Ad esempio, è possibile creare un
    dataset a scopo di simulazione usando alcuni comandi come
    <cmd>uniform()</cmd> e <cmd>normal()</cmd>) i quali
    genereranno serie di dati ex nihilo che dovranno poi venir
    riempiti con dati. Questo comando può risultare
    particolarmente comodo se utilizzato assieme a
<cmd>loop</cmd>.  Si veda anche l'opzione <quote>seed</quote>
del comando <cmdref targ="set"/>.
</para>
<para>
  Per impostazione predefinita, questo comando cancella tutti i
  dati presenti nell'ambiente di lavoro di gretl. Usando
  l'opzione <opt>preserve</opt>, verranno mantenute tutte le
  matrici attualmente definite.
</para>
</description>

<gui-access>
  <menu-path>/File/Nuovo dataset</menu-path>
</gui-access>

</command>

<command name="ols" section="Estimation"
	 label="Minimi quadrati ordinari">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>errori standard clusterizzati</effect>
      </option>
      <option>
	<flag>--jackknife</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--simple-print</flag>
	<effect>non mostra le statistiche ausiliarie</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
      <option>
        <flag>--anova</flag>
        <effect>stampa una tabella ANOVA</effect>
      </option>
      <option>
	<flag>--no-df-corr</flag>
	<effect>sopprime la correzione per i gradi di libertà</effect>
      </option>
      <option>
	<flag>--print-final</flag>
	<effect>si veda sotto</effect>
      </option>
    </options>
    <examples>
      <example>ols 1 0 2 4 6 7</example>
      <example>ols y 0 x1 x2 x3 --vcv</example>
      <example>ols y 0 x1 x2 x3 --quiet</example>
    </examples>
  </usage>

  <description>
    <para context="gui">
      Calcola le stime minimi quadrati ordinari (OLS: Ordinary Least
      Squares) per il modello specificato.
    </para>

    <para context="cli">
      Calcola le stime minimi quadrati ordinari (OLS: Ordinary Least
      Squares) usando la <repl>variabile-dipendente</repl> e la lista
      di <repl>variabili-indipendenti</repl>, che possono essere
      specificate per nome o numero. Il termine costante può essere
      indicato usando il numero 0.
    </para>

    <para>
      Oltre alle stime dei coefficienti e agli errori standard, il
      programma mostra i p-value per le statistiche <math>t</math>
      (a due code) e <math>F</math>.  Un p-value inferiore a 0.01
      indica significatività al livello dell'1 per cento ed è denotato
      con <lit>***</lit>. <lit>**</lit> indica invece la significatività
      tra l'1 e il 5 per cento, mentre <lit>*</lit> indica un livello di
      significatività tra il 5 e il 10 per cento. Vengono mostrate anche
      le statistiche di selezione del modello (il criterio di informazione
      di Akaike, AIC, e il criterio di informazione bayesiana di Schwarz,
      BIC). La formula usata per AIC è descritta in <cite key="akaike74">Akaike (1974)</cite>,
      ossia meno due volte la log-verosimiglianza massimizzata più il doppio
      del numero di parametri stimati.
    </para>

    <para context="cli">
      Usando l'opzione <opt>no-df-corr</opt> la correzione
      per i gradi di libertà non viene applicata nel calcolo della varianza
      stimata dell'errore (e quindi anche dell'errore standard delle stime dei parametri).
    </para>

    <para context="cli">
      L'opzione <opt>print-final</opt> è utilizzabile solo nel contesto
      di un <cmdref targ="loop"/>. L'effetto è quello di eseguire la
      regressione in modo silenzioso per tutte le iterazioni del loop
      tranne l'ultima. Si veda <guideref targ="chap:looping"/> per i dettagli.
    </para>

    <para context="cli">
      Varie variabili interne possono essere recuperate per futuri scopi di stima.
      Ad esempio:
    </para>
    <code context="cli">
      series uh = $uhat
    </code>
    <para context="cli">
      dove così facendo si salvano i residui stimati dal modello sotto il nome
      <lit>uh</lit>. Per ulteriori riferimenti si guardi anche alla sezione
      <quote>accessori</quote> di gretl function.
    </para>

    <para context="cli">
      La formula utilizzata nella versione <opt>HC</opt> per generare
      errori standard robusti con l'opzione <opt>robust</opt> può
      essere calibrata attraverso il comando <cmdref targ="set"/>.
      L'opzione <opt>jackknife</opt> ha l'effetto di selezionare la
      versione <lit>3a</lit> della matrice <lit>HC</lit>. L'opzione
      <opt>cluster</opt> annulla la procedura di selezione della
      versione della matrice HC in quanto produce errori standard
      robusti in seguito all'operazione di raggruppamento delle
      singole osservazioni di <repl>clustvar</repl>.  Si veda anche
      <guideref targ="chap:robust_vcv"/> per maggiori dettagli.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/OLS - Minimi quadrati ordinari</menu-path>
    <other-access>Pulsante Beta-hat sulla barra degli strumenti</other-access>
  </gui-access>

</command>

<command name="omit" section="Tests" label="Omette variabili">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--test-only</flag>
	<effect>non rimpiazza il modello corrente</effect>
      </option>
      <option>
	<flag>--chi-square</flag>
	<effect>restituisce un test chi-quadro di Wald</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>stampa solo i risultati del test</effect>
      </option>
      <option>
	<flag>--silent</flag>
	<effect>non stampa nulla</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>stampa la matrice di varianze-covarianze del modello ridotto</effect>
      </option>
      <option>
	<flag>--auto</flag>
	<optparm>alpha</optparm>
	<effect>eliminazione sequenziale, si veda oltre</effect>
      </option>
    </options>
    <examples>
      <example>omit 5 7 9</example>
      <example>omit seasonals --quiet</example>
      <example>omit --auto=BIC</example>
      <example>omit --auto=0.05</example>
      <demos>
	<demo>restrict.inp</demo>
	<demo>sw_ch12.inp</demo>
	<demo>sw_ch14.inp</demo>
      </demos>
    </examples>
  </usage>

  <description context="gui">
    <para>
      Questo comando stima di nuovo il modello dato, dopo aver omesso
      le variabili specificate.  Oltre ai consueti risultati della
      stima del modello, viene fornita una statistica test per la
      significatività congiunta delle variabili omesse: l'ipotesi
      nulla è che i coefficienti di tutte le variabili omesse siano
      pari a zero.
    </para>
      <para>
	Selezionando l'opzione <quote>Wald test</quote>, viene
	valutata la significatività congiunta delle variabili
	specificate per mezzo di un test di Wald e la stima vincolata
	non viene eseguita.
      </para>
      <subhead>Eliminazione sequenziale</subhead>
      <para>
	L'opzione <quote>Eliminazione sequenziale</quote> mette in
	atto la regressione cosiddetta <quote>backward
	stepwise</quote>. In questo caso, la lista
	<repl>varlist</repl> è un elenco di
	<emphasis>candidati</emphasis> da omettere dal modello
	originale. A ogni passaggio, il metodo individua il candidato
	che offre il miglioramento maggiore in base al criterio
	specificato (<math>P</math>-value a due code o criterio
	informativo), se presente. L'algoritmo si interrompe quando
	non è possibile alcun ulteriore miglioramento. Se almeno un
	regressore è stato omesso, vengono quindi mostrate le stime
	ridotte.
      </para>
      <para>
	Quando si seleziona un metodo stepwise, l'elenco delle
	variabili da omettere viene ignorato per default, a favore del
	trattamento di tutti i regressori come candidati
	all'omissione. Tuttavia, è possibile limitare i candidati
	selezionando la casella <quote>Testa solo le variabili
	selezionate</quote>.
      </para>
    </description>

  <description context="cli">
    <para>
      Questo comando deve seguire un comando di stima. Nella sua forma
      principale, questo comando calcola un test di Wald per la
      significatività congiunta delle variabili presenti nella
      <repl>lista variabili</repl>, che deve essere un sottoinsieme
      (non necessariamente proprio) delle variabili indipendenti
      presenti nell'ultimo modello stimato. I risultati possono poi
      venire richiamati attraverso l'uso degli accessori <fncref
      targ="$test"/> e <fncref targ="$pvalue"/>.
    </para>
    <para>
      A meno che non vengano rimossi tutti i regressori, il modello
      ristretto che viene stimato va a rimpiazzare il modello
      originale come <quote>modello corrente</quote> con lo scopo, ad
      esempio, di richiamare i residui come <lit>$uhat</lit> o di
      eseguire dei test. Questo comportamento può essere soppresso
      attraverso l'uso dell'opzione <opt>test-only</opt>.
    </para>
    <para>
      Per default, viene usata la forma <math>F</math> del test di
      Wald; se invece si vuole un test chi-quadro, si usi l'opzione
      <opt>chi-square</opt>.
    </para>
    <para>
      Se il modello ristretto viene sia stimato che stampato l'utilizzo
      dell'opzione <opt>vcv</opt> ha l'effetto di stampare anche la matrice
      di covarianze, altrimenti se non usata l'opzione viene ignorata.
    </para>
    <subhead>L'opzione "auto"</subhead>
    <para>
      L'opzione <opt>auto</opt> (che non può essere combinata con
      <opt>test-only</opt>) invoca una regressione stepwise
      all'indietro. In questo caso, <repl>varlist</repl> viene
      considerata un elenco di variabili <quote>candidate</quote> da
      omettere dal modello originale. A ogni passo, il metodo
      determina la miglior candidata da eliminare in base al criterio
      specificato (indicato come parametro dell'opzione). L'algoritmo
      si arresta quando non è possibile alcun ulteriore
      miglioramento. Il criterio deve assumere una delle seguenti
      forme:
    </para>
    <ilist>
      <li>
	<para>
	  Un criterio di informazione: <lit>AIC</lit>, <lit>BIC</lit>
	  o <lit>HQC</lit>. Il candidato <quote>migliore</quote> a
	  ogni passaggio è quindi quello la cui omissione fornisce il
	  maggiore miglioramento (riduzione) nel criterio selezionato,
	  finché non vi è alcun candidato la cui omissione fornisca un
	  miglioramento, quando l'algoritmo si arresta.
	</para>
      </li>
      <li>
	<para>
	  Un valore &alpha; (frazione decimale positiva). In questo
	  caso, il regressore con il valore <math>P</math> a due code
	  più alto viene scelto per l'omissione, finché non vi è alcun
	  candidato il cui valore <math>P</math> sia maggiore di
	  &alpha;; a quel punto, l'algoritmo si arresta.
	</para>
      </li>
    </ilist>
    <para>
      Se non viene specificato alcun <repl>criterio</repl> con
      l'opzione <opt>auto</opt>, l'impostazione predefinita è
      utilizzare il metodo del valore <math>P</math> con &alpha; =
      0.10.
    </para>
  </description>
  <gui-access>
    <menu-path>Finestra del modello, /Test/OMIT - Ometti variabili</menu-path>
  </gui-access>
</command>

<command name="online" section="Dataset" context="gui"
	 label="Accesso ai database online">

  <description>
    <para>
      Gretl può accedere ai database della Wake Forest University
    (se il proprio computer è connesso a internet).</para>

    <para>
      Dal menù <quote>File, Database</quote>, selezionare
      <quote>Sul server di gretl</quote>: apparirà una finestra che
      mostra i database disponibili alla Wake Forest (a seconda della
      località e della velocità della connessione internet,
      l'operazione può richiedere alcuni secondi). Oltre al nome del
      database e a una breve descrizione, apparirà un campo
      <quote>Stato</quote>, che mostra se il database è stato
      installato localmente (sul disco del computer), e, in caso
      positivo, se la versione installata è aggiornata a quella
    disponibile sul server.</para>

    <para>
      Se un database è stato installato localmente ed è
      aggiornato, non c'è nessun vantaggio nell'accedervi attraverso il
      server, mentre per un database non installato o non aggiornato, può essere
      utile scaricare un elenco delle serie di dati, facendo clic su
      <quote>Scarica l'elenco delle serie</quote>. Apparirà una nuova
      finestra da cui è possibile visualizzare i valori di una serie
      scelta, vederne il grafico o importarle in gretl. È possibile
      effettuare queste operazioni usando il menù <quote>Serie</quote>,
      o attraverso il menù pop-up che appare facendo clic col tasto
      destro su una serie. È anche possibile cercare nell'elenco una
      variabile in particolare, usando il comando <quote>Trova</quote>
    del menù.</para>

    <para>
      Per poter accedere a un database anche offline, basta selezionare la
      riga del database desiderato nella prima finestra e premere il pulsante
      <quote>Installa</quote>. Il database verrà scaricato in formato
      compresso, verrà decompresso e installato sul proprio disco fisso,
      in modo da poter essere caricato usando il menù <quote>File,
    Database, Gretl</quote>.</para>

  </description>
</command>

<command name="open" section="Dataset" label="Apre un dataset" context="cli">

  <usage>
    <arguments>
      <argument>file-dati</argument>
    </arguments>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>non stampare la lista di serie</effect>
      </option>
      <option>
	<flag>--preserve</flag>
	<effect>mantieni in memoria le variabili non-serie</effect>
      </option>
      <option>
	<flag>--select</flag>
	<optparm>selezione</optparm>
	<effect>leggi solo le serie specificate, vedi sotto</effect>
      </option>
      <option>
	<flag>--frompkg</flag>
	<optparm>pkgname</optparm>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--all-cols</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--www</flag>
	<effect>usa un database sul server di gretl</effect>
      </option>
      <optnote>Si veda oltre per le opzioni specifiche per i fogli elettronici</optnote>
    </options>
    <examples>
      <example>open data4-1</example>
      <example>open voter.dta</example>
      <example>open fedbog --www</example>
    </examples>
  </usage>

  <description>
    <para>
      Apre un file di dati o un database (vedi <guideref
      targ="chap:datafiles"/> per una spiegazione sulla differenza
      fra le due possibilità). L'effetto del comando è abbastanza
      diverso nei due casi: quando si apre un file di dati, il suo
      contenuto viene letto in memoria, sostituendo i dati
      eventualmente già presenti. Per aggiungere
      dati al dataset aperto, vedi <cmdref targ="append"/> o, per
      maggiore flessibilità, <cmdref targ="join"/>. Se invece viene
      aperto un database, nessun dato viene letto immediatamente. Il
      comando si limita a impostare la fonte per i susseguenti
      comandi <cmdref targ="data"/>, usati per effettuare
      l'importazione vera e propria. Si veda <quote>Apertura di un
      database</quote> più sotto.
    </para>
    <para>
      Se non si specifica un percorso completo, il programma
      cercherà automaticamente il file in alcuni percorsi
      predefiniti, a partire dal valore attuale di
      <cmdref targ="workdir"/>. Se non si specifica un'estensione per il
      file, come nel primo degli esempi, gretl assume che si tratti
      di un file di dati standard, con estensione <lit>.gdt</lit>. A
      seconda del nome del file e di alcune sue caratteristiche,
      gretl cerca di indovinare il formato dei dati (standard, testo
      semplice, CSV, MS Excel, Stata, SPSS, ecc.).
    </para>
    <para>
      Usando l'opzione <opt>frompkg</opt>, <program>gretl</program>
      cercherà il file di dati specificato nella sottodirectory
      associata al pacchetto <repl>pkgname</repl>.
    </para>
    <para>
      Se l'argomento <repl>nome-file</repl> è un URI che inizia con
      <lit>http://</lit> o <lit>https://</lit>, allora
      <program>gretl</program> cercherà di scaricare il file dalla
      rete prima di aprirlo.
    </para>
    <para>
      Come impostazione predefinita, l'apertura di un nuovo file di
      dati annulla la sessione corrente, il che implica la perdita
      di tutte le variabili di tipo matrice, scalare e stringa. Se
      si vuole preservare tali variabili (con l'eccezione delle
      serie, che sono necessariamente eliminate), va usata l'opzione
      <opt>preserve</opt>.
    </para>
    <subhead context="cli">Fogli elettronici</subhead>
    <para>
      Quando si apre un file di un foglio elettronico (Gnumeric,
      Open Document o XLS), è possibile fornire fino a tre parametri
      aggiuntivi, oltre al nome del file. Per prima cosa, è
      possibile selezionare un particolare foglio di lavoro
      all'interno del file, indicando il suo numero con la sintassi
      <opt>sheet=2</opt>, oppure indicando il suo nome tra
      virgolette doppie, usando la sintassi
      <opt>sheet="MacroData"</opt>.  L'impostazione predefinita
      consiste nel leggere il primo foglio di lavoro del file. È
      anche possibile specificare la riga/colonna da cui iniziare a
      leggere, usando la sintassi
    </para>
    <code>
      --coloffset=3 --rowoffset=2
    </code>
    <para>
      che indica a gretl di ignorare le prime 3 colonne e le prime 2 righe.
      L'impostazione predefinita consiste nel leggere tutte le celle del
      foglio, a partire dalla prima in alto a sinistra.
    </para>
    <subhead context="cli">File di testo con delimitatori</subhead>
    <para>
      Con file di testo, gretl in genere si aspetta di trovare le
      colonne di dati separate da un qualche carattere standard; in
      genere, la virgola, il tab, lo spazio o il punto e virgola
      (copyright Totò e Peppino). Come impostazione base, gretl
      cerca di trovare nella prima colonna etichette identificative
      o date, se l'intestazione è vuota o contiene qualcosa che
      verosimilmente va interpretato in tal modo, come
      <quote>year</quote>, <quote>date</quote> o
      <quote>obs</quote>. Questa euristica sulla prima colonna può
      essere disattivata attraverso l'opzione <opt>all-cols</opt>
      option.
    </para>
    <subhead context="cli">File di testo in formato fisso</subhead>
    <para>
      Tuttavia, c'è anche modo di leggere dati in <quote>formato
      fisso</quote>, dove non ci sono delimitatori ma esiste una
      specifica del formato; ad esempio, <quote>la variabile
      <math>k</math> occupa 8 caratteri a partire dal
      24esimo</quote>.  Per leggere file siffatti, va aggiunta la
      stringa <opt>fixed-cols=</opt><repl>colspec</repl>, dove
      <repl>colspec</repl> si compone di interi separati da virgole.
      Essi vengono interpretati a coppie, in cui il primo elemento
      denota la colonna di partenza, misurata in byte dall'inizio
      della riga (dove 1 indica il primo byte); il secondo elemento
      indica quanti byte vanno letti per quel dato campo. Facciamo
      un esempio: il comando
    </para>
    <code>
      open fixed.txt --fixed-cols=1,6,20,3
    </code>
    <para>
      farà sì che vengano letti 6 byte a partire dalla colonna 1 per
      la prima variabile; per la seconda, 3 byte a partire dalla
      colonna 20.  Linee vuote, o che iniziano con <lit>#</lit>,
      vengono ignorate; per tutte le altre si applica la regola del
      formato, e se viene trovato qualcosa non interpretabile come
      numero, viene segnalato un errore.  Se i dati sono letti senza
      problemi, le variabili avranno per nome <lit>v1</lit>,
      <lit>v2</lit>, ecc.  Sta all'utente dare alle variabili nomi e
      descrizioni informative tramite i comandi <cmdref
      targ="rename"/> e/o <cmdref targ="setinfo"/>.
    </para>
    <subhead context="gui">Serie di stringhe di valori</subhead>
    <para>
      Di default, quando si importa un file contenente delle
      stringhe di valori una casella di testo si aprirà mostrando i
      contenuti del file <lit>string_table.txt</lit>, il quale
      contiene una legenda sull'associazione fra le stringhe ed i
      valori numerici corrispondenti. Per far sì che ciò non accada,
      si usi l'opzione <opt>quiet</opt>.
    </para>
    <subhead context="cli">Apertura di una selezione</subhead>
    <para>
      In generale, l'uso di <lit>open</lit> con un file di dati (al
      contrario di ciò che accade con un database) implica la
      lettura di tutte le serie che esso contiene. Tuttavia, per
      dati in formato gretl nativo (<lit>gdt</lit> e
      <lit>gdtb</lit>) è possibile indicare un sottinsieme delle
      serie da leggere. L'opzione da usare a questo scopo è
      <opt>select</opt>, che richiede un argomento. Quest'ultimo può
      prendere tre forme: il nome di una serie singola, una lista di
      nomi, comppresa fra virgolette doppie e separati da spazi, o
      un array di stringhe preesistente. Ad esempio:
    </para>
    <code>
      # serie singola
      open somefile.gdt --select=x1
      # più serie
      open somefile.gdt --select="x1 x5 x27"
      # metodo alternativo
      strings Sel = defarray("x1", "x5", "x27")
      open somefile.gdt --select=Sel
    </code>
    <subhead context="cli">Apertura di un database</subhead>
    <para>
      Come si diceva sopra, questo comando può essere usato anche
      per aprire un database (gretl, RATS 4.0 o PcGive) per la
      lettura. In questo caso, dev'essere seguito dal comando
      <cmdref targ="data"/> per estrarre una particolare serie dal
      database.
    </para>
    <para>
      Sono ammessi anche altri casi: in primo luogo, se si usa
      l'opzione <lit>www</lit>, il programma cercherà di accedere al
      database specificato sul server di gretl &mdash; ad esempio il
      database "Federal Reserve interest rates" nel terzo degli
      esempi visti sopra. Un altra possibilità è quella di usare il
      comando nella forma <quote><lit>open dbnomics</lit></quote>,
      che userà DB.NOMICS come fonte dei dati; su questo argomento,
      vedi <mnu targ="gretlDBN">dbnomics per gretl</mnu>.  Infine,
      se viene date l'opzione <opt>odbc</opt> gretl prenderà i dati
      da un database ODBC. Per spiegazioni dettagliate, si veda
      <guideref targ="chap:odbc"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>/File/Apri dati</menu-path>
    <other-access>Trascinare un file di dati in gretl (MS Windows o Gnome)</other-access>
  </gui-access>

</command>

<command name="orthdev" section="Transformations"
	 label="Deviazioni ortogonali" context="cli">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Utilizzabile solo con dati panel. Per ognuna delle variabili nella
      <repl>lista-variabili</repl> viene generata una serie di deviazioni
      ortogonali in avanti, salvata col nome della variabile prefissata da
      <lit>o_</lit>. Quindi, <cmd>orthdev x y</cmd> crea le nuove variabili
      <lit>o_x</lit> e <lit>o_y</lit>.
    </para>
    <para>
      I valori sono salvati con un periodo di ritardo rispetto alla loro
      collocazione temporale (ossia, <lit>o_x</lit> all'osservazione <math>t</math>
      contiene la deviazione che, in senso stretto, corrisponde al periodo
      <math>t</math> &minus; 1). Questo comportamento è coerente con quello
      delle differenze prime: viene persa la prima osservazione di ogni serie,
      non l'ultima.
    </para>
  </description>

</command>

<command name="outfile" section="Printing" label="Stampa diretta su file" context="cli">

  <usage>
    <altforms>
	<altform><lit>outfile</lit> <repl>nomefile</repl></altform>
	<altform><lit>outfile</lit> <lit>--buffer=</lit><repl>varstr</repl></altform>
	<altform><lit>outfile</lit> <lit>--tempfile=</lit><repl>varstr</repl></altform>
    </altforms>
    <options>
      <option>
	<flag>--append</flag>
	<effect>aggiunge al file</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--buffer</flag>
	<effect>vedi sotto</effect>
      </option>
        <option>
	  <flag>--tempfile</flag>
	  <effect>vedi sotto</effect>
        </option>
        <option>
	  <flag>--decpoint</flag>
	  <effect>vedi sotto</effect>
        </option>
    </options>
</usage>

<description>
  <para>
    Il comando <lit>outfile</lit> inizia un blocco in cui tutto
    l'output stampato viene deviato a un file o a un buffer (o,
    volendo, semplicemnte buttato via). Tale blocco è chiuso dal
    comando <quote><lit>end outfile</lit></quote>, dopodiché l'output
    viene mandato di nuovo allo stream predefinito.
  </para>

  <subhead>Reindirizzamento a un file</subhead>
  <para>
    La prima variante manda l'output a un file il cui nome è dato come
    argomento <repl>nomefile</repl>. Di default, viene creato un file
    nuovo (sovrascrivendo il file dello stesso nome, se esiste).
    L'output verrà scritto nella corrente <cmdref targ="workdir"/>, a
    meno che il <repl>nomefile</repl> non contenga un percorso
    completo.  Se invece di sovrascrivere si vuole aggiungere in coda,
    va usata l'opzione <opt>append</opt>.
  </para>
  <para>
    Quello che segue è un semplice esempio, in cui l'output di una
    regressione viene scritto su un file.
  </para>
  <code>
    open data4-10
    outfile regress.txt
    ols ENROLL 0 CATHOL INCOME COLLEGE
    end outfile
  </code>
  <subhead>Nomi di file speciali</subhead>
  <para>
    Per il parametro <repl>nomefile</repl> esistono tre valori convenzionali:
  </para>
  <ilist>
    <li>
      <para>
	<lit>null</lit>: l'output viene sopppresso fino alla fine
	della ridirezione.
      </para>
    </li>
    <li>
      <para>
	<lit>stdout</lit>: l'output è ridiretto sullo <quote>standard
	output</quote>.
      </para>
    </li>
    <li>
      <para>
	<lit>stderr</lit>: l'output è ridiretto sullo <quote>standard
	error</quote>.
      </para>
    </li>
  </ilist>
  
  <subhead>Reindirizzamento a un buffer</subhead>
  <para>
    L'opzione <opt>buffer</opt> serve a mandare l'ouput a una
    variabile stringa. Il parametro per questa opzione dev'essere il
    nome di una variabile stringa preesistente, il cuni contenuto sarà
    sovrascritto.  Quello che segue è lo stesso esempio fatto appena
    sopra, a parte che l'output va ad una stringa. In questo caso
    stampando <lit>model_out</lit> si vedrà l'output reindirizzato.
  </para>
  <code>
    open data4-10
    string model_out = ""
    outfile --buffer=model_out
    ols ENROLL 0 CATHOL INCOME COLLEGE
    end outfile
    print model_out
  </code>

  <subhead>Reindirizzamento a un file temporaneo</subhead>
  <para>
    L'opzione <opt>tempfile</opt> serve a mandare l'output a un file
    temporaneo, con un nome costruito automaticamente per assicurarne
    l'unicità, nella directory <quote>di servizio</quote>. Così come
    nel caso del buffer, il parametro dell'opzione dev'essere il nome
    di una variabile stringa, che viene riempita col nome del file
    temporaneo. <i>Nota bene</i>: i file scritti sulla directory di
    servizio vengono cancellati quando si esce dal programma: non
    usate questa forma se volete che il file sia conservato.
  </para>
  <para>
    Ripetiamo l'esempio fatto sopra, con un paio di linee in più per
    illustrare il punto che <repl>varstr</repl> dice dove l'output è
    andato, e volendo lo si può leggere usando la funzione <fncref
    targ="readfile"/>.
  </para>
  <code>
    open data4-10
    string mytemp
    outfile --tempfile=mytemp
    ols ENROLL 0 CATHOL INCOME COLLEGE
    end outfile
    printf "Output went to %s\n", mytemp
    printf "The output was:\n%s\n", readfile(mytemp)
  </code>

  <para>
    In certi casi, è desiderabile avere un po' di controllo sul
    nome del file temporaneo. Questo è possibile usando una
    variabile stringa contenente sei <lit>X</lit> consecutive,
    come nell'esempio seguente:
  </para>
  <code>
    string mytemp = "tmpXXXXXX.csv"
    outfile --tempfile=mytemp
    ...
  </code>
  <para>
    In questo caso, <lit>XXXXXX</lit> sarà sostituito da caratteri
    a caso che assicurano l'unicità del nome del file, ma il
    suffisso <quote><lit>.csv</lit></quote> sarà preservato. Come
    nel caso più semplice presentato prima, il file viene scritto
    automaticamente nella directory <quote>nascosta</quote> e il
    contenuto della variabile stringa passato tramite l'opzione
    viene modificato così da contenere l'intero percorso.
  </para>
  
  <subhead>L'opzione quiet</subhead>
  <para>
    L'effetto dell'opzione <opt>quiet</opt> è quello di disattivare la
    stampa dei comandi e dei messaggi ausiliari nel frattempo che
    l'output viene reindirizzato. È l'equivalente di fare:
  </para>
  <code>
    set echo off
    set messages off
  </code>
  <para>
    se non per il fatto che al termine della ridirezione i valori
    originali di <lit>echo</lit> e <lit>messages</lit> vengono
    ripristinati. Quest'opzione è disponibile in tutti i casi.
  </para>

  <subhead>Separatore decimale</subhead>
  <para>
    L'effetto dell'opzione <opt>decpoint</opt> è di far sì che,
    durante la ridirezione, il separatore decimale sia il punto
    anziché la virgola. Al termine del blocco <lit>outfile</lit> il
    separatore decimale torna ad essere quello che era prima. Questa
    opzione è particolarmente utile se il file di testo da creare
    costituisce l'input per qualche altro programma che richiede che le
    cifre seguano la convenzione inglese, come sarebbe il caso, ad
    esempio, di uno script gnuplot o R.
  </para>

  <subhead>Livelli di ridirezione</subhead>

  <para>
    In un dato punto del codice, ci può essere solo un file aperto
    con questa tecnica; quindi, le chiamate a questo comando non
    possono essere annidate. Ciononostante, questo comando è
    consentito nelle funzioni scritte dall'utente (purché il file
    di output venga chiuso nella stessa funzione), cosicché
    l'output può essere ridiretto temporaneamente e poi riassegnato
    al file di output originale. Ad esempio, il codice
  </para>
  <code>
    function void f (string s)
        outfile inner.txt
	    print s
        end outfile
    end function

    outfile outer.txt --quiet
    print "Fuori"
    f("Dentro")
    print "Ancora fuori"
    end outfile
  </code>
  <para>
    produrrà un file di nome <quote>outer.txt</quote> contenente le
    due linee
  </para>
  <code>
    Fuori
    Ancora fuori
  </code>
  <para>
    e un file di nome <quote>inner.txt</quote> contenente la linea
  </para>
  <code>
    Dentro
  </code>
</description>

</command>

<command name="packages" section="Utilities" label="Pacchetti di funzioni" context="gui">
  <description>
    <para>
      Le funzionalità di gretl possono essere estese per mezzo dei
      pacchetti di funzioni. Ce ne sono di due tipi: gli
      <quote>addon</quote> ufficiali e i pacchetti contribuiti dalla
      comunità. Assieme, essi coprono molti metodi statistici e
      computazionali non disponibili come comandi o funzioni native.
    </para>
    <para>
      Gli addon ufficiali sono inclusi nell'installazione per Windows
      e Mac. Su Linux, se non sono preinstallati vengono scaricati
      alla bisogna. Per verificare se gli addon sono aggiornati, usare
      <mnu targ="SFAddons">Controlla disponibilità componenti
      aggiuntivi</mnu> nel menu Aiuto.
    </para>
    <para>
      La lista dei pacchetti contribuiti installati è disponibile
      usando la voce di menu <mnu targ="LocalGfn">Sul sistema
      locale</mnu>, e se si è collegati alla rete la lista di tutti
      quelli disponibili è visualizzabile tramite <mnu
      targ="RemoteGfn">Sul server</mnu>. Entrambi si trovano sotto
      /File/Pacchetti di funzioni.
    </para>
    <para>
      Diversi pacchetti offrono l'opzione di attaccarsi al menu
      dell'interfaccia grafica. Per ispezionare questa funzionalità,
      usare <mnu targ="Registry">registro del pacchetto</mnu>
      (accesso via il bottone delle preferenze nella lista dei
      pacchetti installati).
    </para>
    <para>
      Per maggiori dettagli sull'installazione e sul lavoro con i
      pacchetti allora si guardi <mnu targ="Pkgbook">Guida ai
      pacchetti di funzioni</mnu> (sotto il menù di aiuto). Questa
      guida contiene anche dettagli su come scriverne di
      propri. Un'ottima infarinata in merito può essere trovata al
      <url>http://gretl.sf.net/gfnguide/gfn_for_dummies.html</url>.
    </para>
    <para>
      Per avere a che fare con i pacchetti tramite la linea di comando
      di gretl si veda il comando <cmdref targ="pkg"/>.
    </para>
  </description>
</command>

<command name="panel" section="Estimation" label="Modelli panel">

  <usage>
    <arguments>
      <argument>variabile dipendente</argument>
      <argument>variabili indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--fixed-effects</flag>
	<effect>stima con effetti di gruppo fissi</effect>
      </option>
      <option>
	<flag>--random-effects</flag>
	<effect>effetti casuali o modello GLS</effect>
      </option>
      <option>
	<flag>--nerlove</flag>
	<effect>usa la transformazione di Nerlove</effect>
      </option>
      <option>
	<flag>--pooled</flag>
	<effect>stima un modello OLS pooled</effect>
      </option>
      <option>
	<flag>--between</flag>
	<effect>stima il modello tra i gruppi</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti, si veda oltre</effect>
      </option>
        <option>
	  <flag>--cluster</flag>
	  <optparm>cvar</optparm>
	  <effect>errori standard clusterizzati; vedi sotto</effect>
        </option>
      <option>
	<flag>--time-dummies</flag>
	<effect>include variabili dummy temporali</effect>
      </option>
      <option>
	<flag>--unit-weights</flag>
	<effect>minimi quadrati ponderati</effect>
      </option>
      <option>
	<flag>--iterate</flag>
	<effect>stima iterativa</effect>
      </option>
      <option>
	<flag>--matrix-diff</flag>
	<effect>esegue un test di Hausman con differenza fra
	matrici</effect>
      </option>
      <option>
	<flag>--unbalanced</flag>
	<optparm>metodo</optparm>
	<effect>solamente per random effects, si veda oltre</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>mostra meno risultati</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra più risultati</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>penngrow.inp</demo>
	<demo>panel-robust.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Stima un modello panel, con lo stimatore a effetti fissi come
      default; la stima è implementata sottraendo le medie di gruppo o
      delle unità dai dati originali.
    </para>
    <para context="cli">
      Se l'opzione <opt>random-effects</opt> è data allora verrano
      eseguite le stime del modello ad effetti random, utilizzando
      di default il metodo descritto da <cite key="swamy72">Swamy e
      Arora (1972)</cite>. In questo caso solamente l'opzione
      <opt>matrix-diff</opt> consente l'utilizzo forzato del metodo
      della differenza fra matrici (anziché il metodo della
      regressione), in modo tale da consentire l'utilizzo del test
      di Hausman per la consistenza dei stimatori ad effetti
      random. Altra specifica allo stimatore ad effetti random è
      data dall'utilizzo del comando <opt>nerlove</opt>, il quale
      utilizza il metodo di <cite key="nerlove71">Nerlove
      (1971)</cite> invece del metodo di Swamy e Arora.
    </para>
    <para context="cli">
      In alternativa, con l'opzione <opt>unit-weights</opt>, il modello viene
      stimato con i minimi quadrati ponderati, con i pesi costruiti a partire
      dalla varianza residua per le rispettive unità cross section nel
      campione. Solo in questo caso, è possibile usare l'opzione
      <opt>iterate</opt> per produrre stime iterative: nel caso di
      convergenza, le stime sono di massima verosimiglianza.
    </para>
    <para context="cli">
      Come ulteriore alternativa, se si usa l'opzione <opt>between</opt>,
      viene stimato il modello tra i gruppi, ossia una regressione OLS usando
      le medie dei gruppi.
    </para>
    <para context="cli">
      Il metodo predefinito per calcolare errori standard robusti in
      modelli con dati panel è descritto dallo stimatore HAC di
      Arellano. In alternativa,ci sono gli stimatori <quote>Panel
      Corrected</quote> (<cite key="beck-katz95">Beck and Katz,
      1995</cite>) e <quote>Spatial Correlation Consistent</quote>
      (<cite key="driscoll_kraay98">Driscoll and Kraay,
      1998</cite>). Questi vengono selezionati tramite il comando
      <lit>set panel_robust</lit>, con argomenti <lit>pcse</lit> e
      <lit>scc</lit> rispettivamente. Un'ulteriore alternativa a
      queste tre opzioni è data dall'opzione <opt>cluster</opt>; si
      veda <guideref targ="chap:robust_vcv"/> per i dettagli. Quando è
      specificata l'opzione <opt>robust</opt> il test <math>F</math>
      viene eseguito sullo stimatore ad effetti fissi utilizzando il
      metodo robusto di <cite key="welch51">Welch (1951)</cite>.
    </para>
    <para context="gui">
      Se la casella "Random effects" è spuntata allora verrà
      eseguita una stima GLS ad effetti random. Da impostazione
      predefinita, per la trasformazione GLS viene usato il metodo
      di Swamy e Arora, ma il metodo di Nerlove è disponibile come
      opzione (attraverso l'utilizzo dell'apposito selettore). Una
      ulteriore opzione è quella data da
      <quote>Swamy-Arora/Baltagi-Chang</quote>: in caso di panel non
      bilanciati questo implica una modifica del metodo di
      Swamy-Arora ideato da <cite key="baltagi-chang94">Baltagi e
      Chang (1994)</cite>, altrimenti il metodo è equivalente a
      quello di Swamy-Arora.
    </para>
    <para context="cli">
      L'opzione <opt>unbalanced</opt> è disponibile solo per modelli a
      effetti random: può essere utilizzato per scegliere un metodo
      ANOVA da usare con panel non bilanciati.  Per default, gretl
      utilizza il metodo di Swamy&ndash;Arora come per i panel
      bilanciati, eccezion fatta per l'utilizzo di una media armonica
      delle singole lunghezze temporali al posto di una <math>T</math>
      comune. Con quest'opzione è possibile specificare sia
      <lit>bc</lit>, per usare il metodo di <cite
      key="baltagi-chang94">Baltagi e Chang (1994)</cite>, o
      <lit>stata</lit>, per emulare l'opzione <lit>sa</lit> per il
      comando <lit>xtreg</lit> in Stata.
    </para>
    <para>
      Per maggiori dettagli sulla stima panel, si veda <guideref
      targ="chap:panel"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Panel</menu-path>
  </gui-access>

</command>

<command name="panel-between" section="Estimation" context="gui"
	 label="Modello panel tra i gruppi">

  <description>
    <para>
      Questa finestra di dialogo permette di immettere la specificazione per
      un modello panel <quote>tra i gruppi</quote>, ossia una regressione che
      usa le medie di gruppo dei dati, ignorando quindi la variazione
      all'interno dei gruppi. Questo modello di solito non è di grande
      interesse in sé, ma può essere utile a scopo di confronto, ad esempio
      rispetto al modello a effetti fissi.
    </para>
  </description>

</command>

<command name="panel-mode" section="Dataset" context="gui"
	 label="Organizzazione dei dati panel">

  <description>
    <para>
      Questa finestra di dialogo offre tre opzioni per definire un
      dataset come panel. Le prime due opzioni richiedono che il
      dataset sia già organizzato in un formato panel (anche se gretl
      può non essersi accorto di ciò). La terza opzione richiede che
      il dataset contenga variabili che rappresentano la struttura
      panel.
    </para>
    <para>
      <emphasis>Pila di serie storiche</emphasis>: date <repl>N
      </repl> unità cross section nel dataset e <repl>T</repl>
      osservazioni temporali per ogni unità, selezionando questa
      opzione si indica a gretl che il dataset attuale è composto da
      <repl>N</repl> blocchi consecutivi di <repl>T</repl>
      osservazioni ciascuno. Il passo successivo consiste nello
      specificare il valore di <repl>N</repl>.
    </para>
    <para>
      <emphasis>Pila di dati cross section</emphasis>: si indica a
      gretl che il dataset è composto da <repl>T</repl> blocchi
      consecutivi di <repl>N</repl> osservazioni cross section
      ciascuno, uno per per ogni periodo. Il passo successivo consiste
      nello specificare il valore di <repl>N</repl>.
    </para>
    <para>
      Se il numero di osservazioni del dataset è un numero primo, le
      due opzioni precedenti non sono disponibili.
    </para>
    <para>
      <emphasis>Usa variabili indice</emphasis>: si indica che il
      dataset è organizzato in modo qualsiasi, ma contiene due
      variabili che indicizzano le unità cross section e quelle
      temporali. Il passo successivo consiste nell'indicare queste due
      variabili. Le variabili indice per i panel possono assumere solo
      valori interi e non negativi e non devono avere valori
      mancanti. Se il dataset non contiene variabili di questo tipo,
      questa opzione non è disponibile.
    </para>
    <para>
      <emphasis>Converti da serie temporali affiancate</emphasis>:
      questa opzione è disponibile solo se il dataset corrente ha
      una struttura di serie striche e contiene più di una
      variabile. Selezionando questa opzione, i dettagli vengono
      forniti tramite il pulsante Guida nel passaggio successivo.
    </para>
  </description>

</command>

  <command name="ts-to-panel" section="Dataset" context="gui"
    label="Side-by-side time series to panel">

    <description>
      <para>
	Per spiegare questa opzione, la cosa migliore è fare due esempi.
      </para>
      <para>
	<emphasis>Esempio 1</emphasis>: un dataset di serie storiche
	contiene quattro serie (a parte <lit>const</lit>), che
	contengono il PIL di Francia, Germania, Italia e
	Spagna. Selezionando 1 (il valore predefinito) per il
	<quote>Numero di blocchi affiancati</quote> si vedrà 4 per il
	<quote>Numero di unità</quote>. È quindi possibile
	trasformare le quattro serie in un'unica serie per il PIL in
	formato panel; i dati per paese sono impilati nell'ordine del
	set di dati.
	</para>
	<para>
	  <emphasis>Esempio 2</emphasis>: il dataset è come
	  nell'esempio 1, tranne per il fatto che le serie del PIL per
	  paese sono seguite da altre quattro serie, contenenti dati
	  sulla disoccupazione <emphasis>per gli stessi quattro paesi,
	  nello stesso ordine della serie del
	  PIL</emphasis>. Selezionando 2 blocchi affiancati si vedrà 4
	  come il numero di unità. Procedendo, verranno fornite due
	  serie panel, uno per il PIL e uno per la disoccupazione.
      </para>
      <para>
	Possono esserci tanti blocchi di serie (e quindi quante serie
	panel) si voglia, a condizione che ciascun blocco contenga
	dati per lo stesso insieme di unità, nello stesso ordine. In
	caso contrario, il dataset panel risultante non avrebbe senso.
      </para>
      <para>
	Come controllo di integrità, il numero totale di serie
	temporali deve essere esattamente divisibile per il numero di
	blocchi affiancati. Ne consegue che se il dataset originale
	contiene un numero primo di serie, l'unica opzione offerta è
	quella di trasformarle in un'unica serie panel. Se il dataset
	contiene serie aggiuntive da non trasformare, bisogna eliminarle
	prima di procedere.
      </para>
    </description>
  </command>

<command name="panel-wls" section="Estimation" context="gui"
	 label="Minimi quadrati ponderati a gruppi">

  <description>
    <para>
      Minimi quadrati ponderati a gruppi per dati panel. Calcola le stime WLS
      con i pesi basati sulle varianze stimate degli errori per le rispettive
      unità cross section nel campione.
    </para>
    <para>
      Selezionando l'opzione di iterazione, la procedura viene iterata: ad
      ogni passo, i residui vengono ricalcolati usando le stime WLS
      disponibili per i parametri, fornendo così un nuovo insieme di stime per
      le varianze degli errori, e quindi un nuovo insieme di pesi.
      Le iterazioni si arrestano quando la massima differenza nelle stime dei
      parametri tra un passo e l'altro scende sotto 0.0001, oppure se il
      numero di iterazioni supera 20. Se la procedura converge, le stime
      risultanti sono di massima verosimiglianza.
    </para>
  </description>

</command>

<command name="panplot" section="Graphs"
	 label="grafico di una serie panel" context="cli">

  <usage>
    <arguments>
      <argument>variabile</argument>
    </arguments>
    <options>
      <option>
	<flag>--means</flag>
	<effect>medie per gruppo attraverso il tempo</effect>
      </option>
      <option>
	<flag>--overlay</flag>
	<effect>unità mescolate, N &lt;= 130</effect>
      </option>
      <option>
	<flag>--sequence</flag>
	<effect>unità in sequenza, N &lt;= 130</effect>
      </option>
      <option>
	<flag>--grid</flag>
	<effect>unità su griglia, N &lt;= 16</effect>
      </option>
      <option>
	<flag>--stack</flag>
	<effect>unità sovrapposte verticalmente, N &lt;= 6</effect>
      </option>
      <option>
	<flag>--boxplots</flag>
	<effect>boxplot per unità, in sequenza, N &lt;= 150</effect>
      </option>
      <option>
	<flag>--boxplot</flag>
	<effect>boxplot per tutte le unità</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>nomefile</optparm>
	<effect>ridireziona l'output</effect>
      </option>
    </options>
    <examples>
      <example>panplot x --overlay</example>
      <example>panplot x --means --output=display</example>
    </examples>
  </usage>

  <description>
    <para>
      Comando grafico specifico per dati panel: la serie
      <repl>variabile</repl> viene graficata a seconda delle opzioni
      specificate.
    </para>
    <para>
      A parte le opzioni <opt>means</opt> e <opt>boxplot</opt> quel
      che viene graficato è la variazione della serie sia sotto il
      profilo longitudinale che quello temporale.  Questo tipo di
      grafici è limitato dal numero di unità nel dataset in uso. Ad
      esempio, l'opzione <opt>overlay</opt>, che mostra una serie
      storica per ciascuna unità, è disponibile soltanto se il numero
      di unità <math>N</math> è minore o uguale a 130. (In caso
      contrario, il grafico diventa troppo denso per essere
      informativo.) Se un dataset è troppo grande da permettere
      l'applicazione del comando, va selezionato preventivamente un
      sottocampione di unità, come ad esempio
    </para>
    <code>
      smpl 1 100 --unit
      panplot x --overlay
      smpl full
    </code>
    <para>
      L'opzione <opt>output=</opt><repl>filename</repl> è usata per
      controllare forma e destinazione dell'output; per dettagli,
      vedi il comando <cmdref targ="gnuplot"/>.
    </para>

  </description>

  <gui-access>
    <other-access>Main window pop-up menu (single selection)</other-access>
  </gui-access>

</command>

<command name="panspec" section="Tests" label="Diagnosi panel">
  <usage>
    <options>
      <option>
	<flag>--nerlove</flag>
	<effect>usa il metodo di Nerlove per effetti casuali</effect>
      </option>
      <option>
	<flag>--matrix_diff</flag>
	<effect>usa il metodo di differenze tra matrici per il test di Hausman</effect>
      </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>Non stampare l'output</effect>
	</option>
    </options>
  </usage>
  <description>
    <para>
      Questo test è disponibile solo dopo aver stimato un modello OLS
      su dati panel. Testa il semplice modello <quote>pooled</quote>
      (con tutte le osservazioni mescolate indistintamente) contro le
      principali alternative: il modello a effetti fissi e quello a
      effetti casuali.
    </para>
    <para>
      Il modello a effetti fissi permette all'intercetta della regressione di
      variare per ogni unità cross section. Viene eseguito un test
      <math>F</math> per l'ipotesi nulla che le intercette non
      differiscano tra loro.  Il modello a effetti casuali scompone la
      varianza dei residui in due parti: una specifica alle unità cross section
      e una specifica all'osservazione particolare (la stima può essere
      eseguita solo se il numero delle unità cross section nel dataset è
      maggiore del numero dei parametri da stimare). La statistica LM di
      Breusch&ndash;Pagan testa l'ipotesi nulla che il modello pooled OLS sia
      adeguato contro l'alternativo modello a effetti casuali.
    </para>
    <para>
      Può accadere che il modello pooled OLS sia rifiutato nei confronti
      di entrambe le alternative, a effetti fissi o casuali. A patto
      che gli errori specifici di unità o di gruppo siano non
      correlati con le variabili indipendenti, lo stimatore a effetti
      casuali è più efficiente dello stimatore a effetti fissi; nel
      caso contrario lo stimatore a effetti casuali non è consistente
      e deve essergli preferito lo stimatore a effetti fissi. L'ipotesi
      nulla per il test di Hausman è che l'errore specifico di gruppo non
      sia correlato con le variabili indipendenti (e quindi che il
      modello a effetti casuali sia preferibile). Un basso p-value per
      questo test suggerisce di rifiutare il modello a effetti casuali
      in favore del modello a effetti fissi.
    </para>
    <para>
      Le prime due opzioni per questo comando riguardano il modello ad
      effetti casuali.  Di default viene utilizzato il metodo di
      Swamy e Arora ed il test di Hausman viene calcolato usando il
      metodo di regressione. Le opzioni di cui sopra consentono di
      abilitare, in alternativa, il metodo di Nerlove per effetti
      casuali e/o l'approccio di differenza tra matrici per il
      calcolo del test di Hausman.
    </para>
       <para>
	Se il comando va a buon fine, gli accessori <fncref
	targ="$test"/> e <fncref targ="$pvalue"/> ritornano vettori a
	tre elementi contenenti rispettivamente le statistiche test e
	i p-value per i tre test menzionati sopra: poolability (Wald),
	poolability (Breusch&ndash;Pagan), e Hausman. Nel caso in cui
	questo sia tutto quel che serve, è consigliabile usare
	l'opzione <opt>quiet</opt> per evitare di stampare i
	risulatati.
      </para>
      <para>
	Si noti che dopo la stima a effetti casuali con il comando
	<cmd>panel</cmd>, il test di Hausman viene calcolato
	automaticamente e il risultato è disponibile attraverso l'accessore <fncref
	targ="$hausman"/>.
      </para>
 </description>

  <gui-access>
    <menu-path>Finestra del modello, /Test/HAUSMAN - Diagnosi panel</menu-path>
  </gui-access>

</command>

<command name="pca" section="Statistics"
	 label="Analisi delle componenti principali">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--covariance</flag>
	<effect>usa la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--save</flag>
	<optparm optional="true">n</optparm>
	<effect>salva le componenti principali</effect>
      </option>
      <option>
	<flag>--save-all</flag>
	<effect>salva tutte le componenti</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa i risultati</effect>
      </option>
    </options>
  </usage>

  <description context="gui">
    <para>
      Analisi delle componenti principali. Mostra gli autovalori
      della matrice di correlazione (o della matrice di covarianza, se si usa
      la casella opportuna) per le variabili selezionate, insieme alla
      proporzione della varianza comune spiegata da ogni componente. Mostra
      anche i corrispondenti autovettori (o <quote>pesi della
      componente</quote>).
</para>
<para>
  Nella finestra che mostra i risultati è possibile salvare le componenti
  principali come serie nel dataset.
</para>
</description>

<description context="cli">
  <para>
    Analisi delle Componenti Principali. A meno che l'opzione
    <opt>quiet</opt> non sia presente, stampa gli autovalori
    associati alla matrice di correlazione (o matrice di
    covarianze se è specificata l'opzione <opt>covariance</opt>)
    per le variabili inserite nella <repl>lista-variabili</repl>,
    con allegate proporzioni della varianza totale spiegata dalle
    singole compenenti. Stampa anche i corrispondenti autovettori,
    o <quote>pesi delle componenti</quote>.
</para>
<para>
  Se si dà l'opzione <opt>save-all</opt> allora tutte le
  componenti verranno salvate nel dataset come variabili
  denominate <lit>PC1</lit>, <lit>PC2</lit> e così via. Queste
  variabili artificiali sono definite come la la combinazione
  lineare delle <math>X</math><sub>i</sub> standardizzate (dove
  <math>X</math><sub>i</sub> è l'<math>i</math>-esima variabile
  della <repl>lista-variabili</repl>) con i pesi.
</para>
<para>
  Se si dà l'opzione <opt>save</opt> senza un parametro
  specificato le componenti con autovalori maggiori della media
  (il che significa maggiori di 1.0 se l'analisi è basata sulla
  matrice di correlazione) sono salvati nel dataset come nuove
  variabili, come descritto sopra. Se invece si dà un valore per
  <repl>n</repl>, con quest'opzione allora le <math>n</math> più
  importanti componenti vengono salvate.
</para>
<para>
  Si veda anche la function <fncref targ="princomp"/>.
</para>
</description>

<gui-access>
<menu-path>/Visualizza/Componenti principali</menu-path>
<other-access>Pop-up nella finestra principale (selezione multipla)</other-access>
</gui-access>

</command>

<command name="pergm" section="Statistics"
	 label="Periodogramma">

  <usage>
    <arguments>
<argument>nome-variabile</argument>
<argument optional="true">banda</argument>
</arguments>
<options>
  <option>
<flag>--bartlett</flag>
<effect>usa la finestra di Bartlett</effect>
</option>
<option>
<flag>--log</flag>
<effect>usa una scala logaritmica</effect>
</option>
<option>
<flag>--radians</flag>
<effect>mostra la frequenza in radianti</effect>
</option>
<option>
<flag>--degrees</flag>
<effect>mostra la frequenza in gradi</effect>
</option>
<option>
<flag>--plot</flag>
<optparm>modalità o nome del file</optparm>
<effect>si veda oltre</effect>
</option>
</options>
</usage>

<description>
  <para>
    Calcola e mostra (graficamente se non si è in modalità batch)
    lo spettro della variabile specificata.  Per impostazione predefinita
    viene mostrato il periodogramma nel campione, mentre usando  l'opzione
    <opt>bartlett</opt>, lo spettro viene stimato usando una
    finestra di Bartlett per i ritardi (si veda ad esempio <book>Econometric
    Analysis</book> di Greene per una discussione su questo argomento).
    L'ampiezza predefinita della finestra di Bartlett è pari a due volte la
    radice quadrata dell'ampiezza campionaria, ma questo valore può essere
    impostato manualmente usando il parametro <repl>banda</repl>, fino a un
    massimo pari a metà dell'ampiezza campionaria.
</para>
<para>
  Usando l'opzione <opt>log</opt>, lo spettro viene
  rappresentato su una scala logaritmica.
</para>
<para>
  Le due opzioni (mutualmente escludibili) <opt>radians</opt> e
  <opt>degrees</opt> condizionano la tipologia dell'asse di
  frequenza quando il periodogramma viene rappresentato. Da
  impostazione predefinita, la frequenza è scalata per il numero
  di osservazioni nel campione; tuttavia, queste opzioni
  comportano che l'asse di frequenza possa venire ridenominato
  da 0 a &pi; radianti o da 0 a 180&deg;, rispettivamente.
  </para>
  <para>
    Di default, se il programma non è in modalità batch, viene
    mostrato il periodogramma a video. Questo comportamento è
    modificabile attraverso l'opzione <opt>plot</opt>. I parametri
    accettabili nel caso sono <lit>none</lit> (sopprime il
    grafico); <lit>display</lit> (per mostrare a video il grafico
    anche se il programma è in batch mode); oppure un nome di
    file. L'effetto di dare un nome di file è quello descritto per
    l'opzione <opt>output</opt> del comando <cmdref
    targ="gnuplot"/>.
</para>
<para>
  Quando viene mostrato il periodogramma del campione, vengono mostrati
  anche due test per l'integrazione frazionale (<quote>memoria
  lunga</quote>) della serie, ossia il test di Geweke e Porter-Hudak
  (GPH), e lo stimatore locale di Whittle. L'ipotesi nulla in entrambi
  i casi è che l'ordine di integrazione sia zero. Per impostazione
  predefinita, l'ordine per questi test è il valore minore tra
  <math>T</math>/2 e <math>T</math><sup>0.6</sup>; anche
  questo valore può essere modificato con il parametro di banda.
</para>
</description>

<gui-access>
  <menu-path>/Variabile/Spettro</menu-path>
  <other-access>Menù pop-up nella finestra principale (selezione singola)</other-access>
</gui-access>

</command>

<command name="pkg" section="Utilities" context="cli">
  <usage>
    <arguments>
      <argument>azione</argument>
      <argument>nomepacchetto</argument>
    </arguments>
    <options>
      <option>
	<flag>--local</flag>
	<effect>installa da file in locale</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--staging</flag>
	<effect>vedi sotto</effect>
      </option>
    </options>
    <examples>
      <example>pkg install armax</example>
      <example>pkg install /path/to/myfile.gfn --local</example>
      <example>pkg query ghosts</example>
      <example>pkg run-sample ghosts</example>
      <example>pkg unload armax</example>
    </examples>
  </usage>

  <description>
    <para>
      Comando per installare, rimuovere dalla memoria, disinstallare o
      ottenere informazioni sui pacchetti di funzioni . Il
      parametro <repl>azione</repl> deve essere uno
      fra <lit>install</lit>, <lit>query</lit>, <lit>run&#8209;sample</lit>, 
      <lit>unload</lit>, <lit>remove</lit> o <lit>index</lit>. Più
	sotto è anche descritta un'estensione per i pacchetti
	contenenti dati.
    </para>
    <para>
      <lit>install</lit>: Nella sua forma più semplice, senza
      opzioni e con l'argomento <repl>pkgname</repl> che corrisponde
      al nome <quote>semplice</quote> di un pacchetto (come nel
      primo esempio), il pacchetto stesso verrà scaricato dal server
      di gretl (a meno che <repl>nomepacchetto</repl> non cominci
      con <lit>http://</lit>) e installato in locale. In questo
      caso, indicare l'estensione è superfluo. Se viene data
      l'opzione <opt>local</opt>, l'argomento
      <repl>nomepacchetto</repl> deve essere il percorso completo di
      un file di pacchetto sulla macchina locale, completo di
      estensione (<lit>.gfn</lit> o <lit>.zip</lit>). L'azione
      conseguente al comando è di copiarlo (se <lit>gfn</lit>), o
      espanderlo (se <lit>zip</lit>) nel posto giusto, ossia dove il
      comando <cmdref targ="include"/> sia in grado poi di trovarlo.
    </para>
    <para>
      <lit>query</lit>: L'effetto di default effect è di stampare
      alcune informazioni di base sul pacchetto (autore, versione,
      ecc.). Se il pacchetto include risorse addizionali (file di dati
      e/o script aggiuntivi), queste verranno elencate.  Selezionando
      l'opzione <opt>quiet</opt> però non viene stampato nulla; le
      informazioni, invece, vengono salvate in un bundle, accessibile
      via <fncref targ="$result"/>.
    </para>
      <para>
	<lit>run-sample</lit>: esegue lo script di esempio includo nel
	pacchetto.
      </para>
    <para>
      <lit>unload</lit>: l'argomento <repl>pkgname</repl> deve
      essere dato in forma semplice, senza percorso o suffisso (come
      nell'ultimo esempio). L'effetto è scaricare il pacchetto dalla
      memoria e rimuoverlo, anche dal menu GUI a cui sia eventualmente
      attaccato.
    </para>
    <para>
      <lit>remove</lit>: come <lit>unload</lit>, ma in aggiunta cancella
      anche dal disco i file di pacchetto.
    </para>
    <para>
      <lit>index</lit>: è un caso particolare, in cui il nome del
      pacchetto deve essere sostituito dalla stringa
      <quote><lit>addons</lit></quote>: l'effetto è quello di
      aggiornare l'indice dei pacchetti standard, anche noti come
      <quote>addons</quote>. Quest'operazione viene svolta in
      automatico di tanto in tanto, ma in certi casi la si potrebbe
      voler fare a mano. in tal caso, l'opzione <opt>verbose</opt>
      produce un report di ciò che viene cercato e trovato. Ad
      esempio:
    </para>
    <code>
      pkg index addons --verbose
    </code>
      <subhead>Pacchetti di dati</subhead>
      <para>
	Oltre al suo utilizzo con i pacchetti di funzioni, il
        comando <lit>pkg install</lit> può essere utilizzato anche con
        pacchetti di file di dati del tipo <lit>tar.gz</lit>, come
        elencato
        in <url>https://gretl.sourceforge.net/gretl_data.html</url>. Ad
        esempio, per installare i dati del testo di Verbeek si può
        usare
      </para>
      <code>
        pkg install verbeek.tar.gz
      </code>
      <para>
        Si noti che per questi file l'unica azione supportata è <lit>install</lit>.
      </para>
      <subhead>Staging</subhead>
      <para>
	L'opzione <opt>staging</opt> è pensata per gli sviluppatori ed
	è disponibile solo insieme all'azione <lit>install</lit>
	applicata a un pacchetto di funzioni. Il suo effetto è che il
	pacchetto in questione viene scaricato
	dall'area <lit>staging</lit> di sourceforge anziché dall'area
	pubblica. I pacchetti in staging non sono ancora approvati per
	l'uso generale, quindi questa opzione è rivolta a chi sa quel
	che fa.
      </para>
  </description>

  <gui-access>
    <menu-path>/File/Pacchetti/Sul server</menu-path>
  </gui-access>

</command>

<command name="pkg-depends" section="Programming"
	 label="Dependencies" context="gui">
  <description>
    <para>
      Ciò che intendiamo come <quote>dipendenze</quote> sono i
      pacchetti da cui il vostro pacchetto dipende per le
      funzionare, che ovviamente devono essere installati e caricati
      affinché il vostro funzioni correttamente. In questa finestra
      di dialogo, se ne possono indicare fino a quattro.
    </para>
    <para>
      Ed esempio, immaginate che il vostro pacchetto usi delle
      funzioni contenute nel pacchetto <lit>extra</lit>, che
      contiene diverse utility per la scrittura di script in
      hansl. In questo caso, si può inserire
    </para>
    <code>
      extra
    </code>
    <para>
      in una delle caselle disponibili (la prima, se non ce ne sono
      altre). Si noti che il suffisso <lit>.gfn</lit> o
      <lit>.zip</lit> va incluso, ma non il path completo del
      pacchetto in questione.
    </para>
    <para>
      La primo pacchetto da cui si dipende può essere indicato come
      <quote>fornitore</quote>. In questo caso, il vostro pacchetto
      avrà accesso anche alle funzioni private del pacchetto da cui
      dipende, cosa che di solito non è necessaria, ma che può
      tornare utile in certi casi.
    </para>
  </description>
</command>

<command name="plot" section="Graphs" context="cli">
  <usage>
    <arguments>
      <argument>data</argument>
    </arguments>
    <options>
      <option>
	<flag>--output</flag>
	<optparm>nomefile</optparm>
	<effect>reindirizza l'output ad un file specifico</effect>
      </option>
      <option>
	<flag>--outbuf</flag>
	<optparm>stringa</optparm>
	<effect>invia l'output alla stringa specificata</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>nile.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Il blocco <lit>plot</lit> offre un'alternativa al comando
      <cmdref targ="gnuplot"/>, che potrebbe essere più efficace per
      produrre grafici particolarmente elaborati (con diverse opzioni
      e/o comandi gnuplot inseriti). Oltre alla spiegazione seguente,
      si possono trovare altri esempi consultando <guideref
      targ="chap:graphs"/>.
    </para>
    <para>
      Un blocco <lit>plot</lit> comincia col comando <lit>plot</lit>
      seguito dall'argomento <repl>data</repl>, che indica i dati da
      usare: quest'ultimo dev'essere il nome di una lista, una
      matrice, o una serie singola. Se l'argomento <repl>data</repl>
      non viene specificato allora il blocco deve obbligatoriamente
      contere almeno una funzione analitica da graficare; queste
      funzioni posso essere scritte tramite righe <lit>literal</lit>
      o <lit>printf</lit> (si veda oltre).
    </para>
    <para>
      Se viene fornita una lista o una matrice, l'ultimo elemento
      (se lista) o l'ultima colonna (se matrice) è preso come asse
      delle ascisse e le altre come ordinata,
      a meno che non venga usata l'opzione <opt>time-series</opt>,
      nel qual caso tutte le variabili vanno in ordinata.
    </para>
    <para>
      L'opzione di fornire il nome di una singola serie è ristretta solo
      ai dati temporali, nel qual caso si assume che si voglia ricevere
      un grafico time-series; altrimenti verrà riportato un errore.
    </para>
    <para>
      La linea iniziale può essere dotata del prefisso
      <quote><repl>nome</repl> <lit>&lt;-</lit></quote>
      per salvare il grafico come icona nel programma GUI. Il blocco
      si chiude con <lit>end plot</lit>.
    </para>
    <para>
      All'interno del blocco si possono avere zero o più linee di
      questo tipo, identificate da una delle seguenti parole chiave:
    </para>
    <ilist>
      <li>
	<para>
	  <lit>option</lit>: specifica una singola opzione.
	</para>
      </li>
      <li>
	<para>
	  <lit>options</lit>: specifica più di una opzione per
	  una singola riga, sono separate da spazi.
	</para>
      </li>
      <li>
	<para>
	  <lit>literal</lit>: un comando da passare a gnuplot senza
	  modifiche.
	</para>
      </li>
      <li>
	<para>
	  <lit>printf</lit>: una comando printf il cui risultato
	  verrà passato a gnuplot senza modifiche.
	</para>
      </li>
    </ilist>
    <para>
      Si noti che tutte le opzioni diverse da
      <opt>output</opt> e <opt>outbuf</opt> normalmente usate col
      comando <cmdref targ="gnuplot"/> devono essere fornite
      utilizzando <lit>option</lit> o <lit>options</lit> e non è
      necessario fornire il consueto doppio trattino prima
      dell'identificatore dell'opzione. Per i dettagli sugli effetti
      delle varie opzioni vedere <cmdref targ="gnuplot"/>.
    </para>
    <para>
      L'uso del blocco <lit>plot</lit> è illustrato al meglio
      tramite un esempio:
    </para>
    <code>
      string title = "My title"
      string xname = "My x-variable"
      plot plotmat
      options with-lines fit=none
      literal set linetype 3 lc rgb "#0000ff"
      literal set nokey
      printf "set title \"%s\"", title
      printf "set xlabel \"%s\"", xname
      end plot --output=display
    </code>
    <para>
      Questo esempio ipotizza che <lit>plotmat</lit> sia un nome di
      una matrice avente almeno 2 colonne (o di una lista avente
      almeno 2 membri). Si noti che è considerata buona pratica
      quella di utilizzare l'opzione <opt>output</opt> (solamente)
      nell'ultima linea del blocco.
    </para>
    <subhead>Disegnare una banda usando una matrice</subhead>
    <para>
      Le opzioni <opt>band</opt> e <opt>band-style</opt> funzionano
      principalmente come descritto nell'help del comando
      <lit>gnuplot</lit>, con le seguenti eccezioni: quando i dati
      sono passati in forma di matrice, il primo parametro per
      <opt>band</opt> deve essere dato come il nome di una matrice
      con 2 colonne (contenenti, rispettivamente, il centro e
      l'ampiezza della banda). Questo parametro prende il posto dei
      due valori richiesti dalla versione <lit>gnuplot</lit> di
      questa opzione (nome della serie o ID numerico o colonne della
      matrice). Per esempio:
    </para>
    <code>
      scalar n = 100
      matrix x = seq(1,n)'
      matrix y = x + filter(mnormal(n,1), 1, {1.8, -0.9})
      matrix B = y ~ muniform(n,1)
      plot y
      options time-series with-lines
      options band=B,10 band-style=fill
      end plot --output=display
    </code>
    <subhead>Disegnare senza dati</subhead>
    <para>
      Il seguente esempio mostra un semplice caso di come si
      specifica un grafico senza l'utilizzo di una sorgente dati.
    </para>
    <code>
      plot
      literal set title 'CRRA utility'
      literal set xlabel 'c'
      literal set ylabel 'u(c)'
      literal set xrange[1:3]
      literal set key top left
      literal crra(x,s) = (x**(1-s) - 1)/(1-s)
      printf "plot crra(x, 0) t 'sigma=0', \\"
      printf " log(x) t 'sigma=1', \\"
      printf " crra(x,3) t 'sigma=3"
      end plot --output=display
    </code>
  </description>

</command>

<command name="polyweights" section="Transformations" context="gui"
	 label="Trend polinomiale">

  <description>
    <para>
      Quando si usa un trend polinomiale per approssimare una serie
      storica, si può voler dare più peso alle osservazioni
      all'inizio e alla fine del campione. (I punti in mezzo hanno
      dei vicini su ambo il lati che, probabilmente, portano il
      polinomio nella stessa direzione.)
    </para>
    <para>
      Gli schemi di ponderazione offerti qui (quadratico, a coseno e
      a gradini) possono essere usati allo scopo. Selezionando uno
      di essi, bisogna poi scegliere il valore per due settaggi
      aggiuntivi: per primo, il massimo peso da usare (il minimo è
      1.0), e per secondo la frazione di campione centrale a cui
      dare un peso uniforme (minimale).
    </para>
    <para>
      Supponiamo, ad esempio, di scegliere un peso massimo pari a
      3.0 e una frazione centrale di 0.4. Ciò implica che il 40%
      centrale dei dati riceverà una ponderazione di
      1.0. Selezionando la ponderazione a gradini, il primo e
      l'ultimo 30% delle osservazioni riceve un peso pari a 3.0;
      altrimenti, il peso per il primo 30% delle osservazioni
      decresce gradualmente da 3.0 to 1.0, e per l'ultimo 30% delle
      osservazioni cresce gradualmente da 1.0 to 3.0.
    </para>
  </description>

</command>

<command name="poisson" section="Estimation" label="Stima Poisson">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
      <argument separated="true" optional="true">offset</argument>
    </arguments>
    <options>
      <option>
        <flag>--robust</flag>
        <effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
      </option>
      <option>
        <flag>--vcv</flag>
        <effect>stampa la matrice di covarianze</effect>
      </option>
      <option>
        <flag>--verbose</flag>
        <effect>stampa i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa i risultati</effect>
      </option>
    </options>
    <examples>
      <example>poisson y 0 x1 x2</example>
      <example>poisson y 0 x1 x2 ; S</example>
      <demos>
	<demo>camtriv.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Stima una regressione di Poisson, in cui la variabile dipendente
      rappresenta le occorrenze di un qualche tipo di evento e può assumere solo
      valori interi non negativi.
    </para>

    <para>
      Se una variabile casuale discreta <math>Y</math> segue la
      distribuzione di Poisson,
      <equation status="display"
		tex="\[\mathrm{Pr}(Y = y) = \frac{e^{-v} v^y}{y!}\]"
		ascii="Pr(Y = y) = exp(-v) * v^y / y!"
		graphic="poisson1"/>
      per <math>y</math> = 0, 1,
      2,&hellip;.  La media e la varianza della distribuzione sono entrambe uguali a
      <math>v</math>. Nel modello di regressione di Poisson, il parametro
      <math>v</math> è rappresentato da una funzione di una o più varabili
      indipendenti. La versione più comune del modello (e l'unica supportata da
      gretl) ha
      <equation status="display"
		tex="\[v = \mathrm{exp}(\beta_0+\beta_1 x_1+\beta_2 x_2 + \cdots)\]"
		ascii="v = exp(b0 + b1*x1 + b2*x2 + ...)"
		graphic="poisson2"/>
      ossia il logaritmo di
      <math>v</math> è una funzione lineare delle variabili indipendenti.
    </para>

    <para>
      Opzionalmente è possibile aggiungere una variabile
      <quote>offset</quote> alla specificazione, ossia una variabile
      di scala, il cui logaritmo viene aggiunto alla funzione di
      regressione lineare (con un coefficiente implicito di 1.0). Ciò
      ha senso se si ipotizza che il numero di occorrenze dell'evento
      in questione sia proporzionale a qualche fattore noto, a parità
      di altre condizioni. Ad esempio, il numero di incidenti stradali
      può essere ipotizzato proporzionale al volume del traffico, che
      potrebbe essere specificato come una variabile di
      <quote>offset</quote> in un modello di Poisson per il tasso di
      incidenti.  La variabile di offset dev'essere strettamente
      positiva.
    </para>
    <para>
      Da impostazione predefinita gli errori standard sono calcolati
      usando la matrice Hessiana. Se viene data l'opzione
      <opt>robust</opt> allora gli errori standard vengono calcolati
      secondo il metodo o di Huber&ndash;White o QML. In questo
      particolare caso la matrice di covarianze stimata è il
      prodotto del <quote>sandwich</quote> tra l'Hessiana inversa
      (negativa) ed il prodotto esterno del gradiente.
    </para>
    <para>
      Si veda anche la voce <cmdref targ="negbin"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Modelli non lineari/Poisson</menu-path>
  </gui-access>

</command>

<command name="print" section="Printing" label="Stampa dati o stringhe" context="cli">

  <usage>
    <altforms>
      <altform><lit>print</lit> <repl>lista-variabili</repl></altform>
      <altform><lit>print</lit></altform>
      <altform><lit>print</lit> <repl>nomi-oggetto</repl></altform>
      <altform><lit>print</lit> <repl>stringa</repl></altform>
    </altforms>
    <options>
      <option>
	<flag>--byobs</flag>
	<effect>per osservazione</effect>
      </option>
      <option>
	<flag>--no-dates</flag>
	<effect>usa i numeri delle osservazioni</effect>
      </option>
      <option>
	<flag>--range</flag>
	<optparm>inizio:fine</optparm>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--midas</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--tree</flag>
	<effect>specifico per bundle; vedi sotto</effect>
      </option>
    </options>
    <examples>
      <example>print x1 x2 --byobs</example>
      <example>print my_matrix</example>
      <example>print "Questa è una stringa"</example>
      <example>print my_array --range=3:6</example>
      <example>print hflist --midas</example>
    </examples>
  </usage>
  
  <description>
    <para>
      Si noti che <lit>print</lit> è un comando relativamente
      <quote>rozzo</quote> (principalmente rivolto alla stampa di
      serie); per alternative più avanzate e meno restrittive, si
      vedano i comandi <cmdref targ="printf"/> e <cmdref
      targ="eval"/>.
    </para>
    <para>
      Nella prima variante mostrata sopra (vedia anche il primo
      esempio), <repl>lista</repl> dev'essere una lista di serie
      (sia come variabile predefinita che come lista di nomi o
      numeri ID separati da spazi). In tal caso, il comando stampa i
      valori delle variabili specificate. Per default, la stampa
      avviene <quote>per variabile</quote>, ma con l'opzione
      <opt>byobs</opt> i dati vengono stampati per osservazione. Nel
      secondo caso, il comportamento predefinito è quello di
      mostrare la data (per serie storiche) o il marcatore (se
      esiste) all'inizio di ogni riga.  L'opzione
      <opt>no-dates</opt> sopprime la visualizzazione delle date o
      dei marcatori: viene mostrato solo un semplice numero di
      osservazione. Si veda l'ultimo paragrafo di questa voce per
      l'effetto in questo contesto dell'opzione <opt>midas</opt>
      (che si applica solo a liste predefinite).
      </para>
      <para>
	Se al comando non vengono forniti argomenti (la seconda variante
	mostrata all'inizio), l'azione è simile a quella appena
	descritta, con tanto di opzioni aggiuntive. La sola
      differenza è che vengono stampate <emphasis>tutte</emphasis>
      le serie nel dataset aperto.
      </para>
      <para>
	La terza variante (con l'argomento <repl>nomi-oggetto</repl>; vedi
	il secondo esempio) funziona con una lista di nomi (separati da
	spazi) di variabili diversi da serie: scalari, matrici, stringhe,
	bundle, array. Di questi oggetti, vengono mostrati i valori. Nel
	caso dei bundle, gli elementi vengono ordinati per tipo e
	alfabeticamente.
      </para>
      <para>
      Nella quarta forma (terzo esempio), <repl>stringa</repl>
      dev'essere una stringa racchiusa da virgolette doppie (senza
      che vi sia nient'altro dopo). La stringa viene stampata,
      seguita da un <quote>a capo</quote>.
    </para>
    <para>
      L'opzione <opt>range</opt> è usata per controllare la quantità
      di informazione stampata. I valori (interi)
      <repl>inizio</repl> e <repl>fine</repl> fanno riferimento alle
      osservazioni per serie e liste, alle rghe per le matrici, agli
      elementi per gli array, e alle linee di testo per le
      stringhe. In tutti i casi, il valore minimo per
      <repl>inizio</repl> è 1 e il massimo <repl>stop</repl> è la
      dimensione <quote>per riga</quote> dell'oggetto in
      questione. Valori negativi per questi indici sono interpretati
      come valori a partire dal fondo. Gli indici possono avere la
      forma di numeri o di variabili scalari predefinite. Se
      <repl>inizio</repl> viene omesso, si intende 1 e se viene
      omesso <repl>fine</repl> si intende <quote>fino in
      fondo</quote>. Si noti che nel caso di serie e liste, gli
      indici sono relativi al sottocampione in uso.
    </para>
    <para>
      L'opzione <opt>tree</opt> è specifica alla stampa di un
      bundle: essa fa sì che venga stampato anche il contenuto degli
      eventuali altri bundle contenuti in quello specificato (anche
      come array di bundle). Altrimenti, vengono elencati solo gli
      elementi di livello più alto.
    </para>
    <para>
      L'opzione <opt>midas</opt> è specifica alla stampa di una
      lista di serie; in particolare, è usata per quei dataset che
      contengono una o più serie ad alta frequenza, ognuna
      rappresentata da una <cmdref targ="MIDAS_list"/>. Se viene
      passata come argomento una lista di questo tipo, verrà
      stampata (per osservazione) la serie alla sua frequenza
      <quote>nativa</quote>.
    </para>
  </description>
  
  <gui-access>
    <menu-path>/Dati/Mostra valori</menu-path>
  </gui-access>
  
</command>

<command name="printf" section="Printing" label="Stampa formattata" context="cli">
  
  <usage>
    <arguments>
      <argument>formato</argument>
      <argpunct>, </argpunct>
      <argument>argomenti</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Stampa valori scalari, serie, matrici o stringhe formattandoli
      secondo le indicazioni di una stringa di formato (che supporta
      un piccolo sottoinsieme del comando <lit>printf()</lit> del
      linguaggio di programmazione C). I formati numerici
      riconosciuti sono <lit>%e</lit>, <lit>%E</lit>, <lit>%f</lit>,
      <lit>%g</lit>, <lit>%G</lit>, <lit>%d</lit>, e <lit>%x</lit>,
      con i vari modificatori disponibili in C. Esempi: la stringa
      di formato <lit>%.10g</lit> stampa un valore con 10 cifre
      significative; <lit>%12.6f</lit> stampa un valore con 6 cifre
      decimali e una larghezza di 12 caratteri. Si noti comunque che
      in gretl il formato <lit>%g</lit> è una buona scelta di
      default per tutti i valori numerici; non c'è bisogno di andare
      troppo sul complicato. Il formato <lit>%s</lit> è consigliato
      qualora si lavori con le stringhe.
    </para>

    <para>
      La stringa di formato deve essere racchiusa tra virgolette
      doppie, i valori da stampare devono seguire la stringa di
      formato, separati da virgole. I valori possono avere tre forme:
      a) nomi di variabili; b) espressioni valide per
      il comando <cmd>genr</cmd>; c) le funzioni speciali <lit>varname()</lit>
      o <lit>date()</lit>. L'esempio seguente stampa i valori
      di due variabili e quello di un'espressione calcolata:
    </para>

    <code>
      ols 1 0 2 3
      genr b = $coeff(2)
      genr se_b = $stderr(2)
      printf "b = %.8g, standard error %.8g, t = %.4f\n", b, se_b, b/se_b
    </code>
    
    <para>
      Le prossime righe mostrano l'uso delle funzioni varname e date,
      che mostrano rispettivamente il nome di una variabile dato il
      suo numero identificativo, e una stringa data, dato un numero
      di osservazione.
    </para>
    <code>
      printf "Il nome della variabile %d è %s\n", i, varname(i)
      printf "La data dell'osservazione %d è %s\n", j, date(j)
    </code>
    <para>
      Se si usa un argomento matrice insieme a un formato numerico, l'intera
      matrice verrà stampata usando per ogni elemento il formato numerico
      indicato. La stessa cosa vale per le serie, tranne per il fatto che
      l'intervallo di valori stampato è controllato dall'impostazione del
      campione corrente.
    </para>
    <para>
      La lunghezza massima di una stringa di formato è di 127
      caratteri. Vengono riconosciute le sequenze di escape
      <lit>\n</lit> (newline), <lit>\t</lit> (tab),
      <lit>\v</lit> (tab verticale) e <lit>\\</lit> (barra inversa).
      Per stampare un segno di percentuale, si usi <lit>%%</lit>.
    </para>
    <para>
      Come in C, i valori numerici che fanno parte del formato (larghezza e
      precisione) possono essere dati direttamente come numeri, come in
      <lit>%10.4f</lit>, o come variabili. Nell'ultimo caso, si inseriscono
      asterischi nella stringa di formato e si forniscono nell'ordine gli
      argomenti corrispondenti. Ad esempio:
    </para>
    <code>
      scalar larghezza = 12
      scalar precisione = 6
      printf "x = %*.*f\n", larghezza, precisione, x
    </code>
  </description>
  
</command>

<command name="probit" section="Estimation"
	 label="Stima probit">

  <usage>
    <arguments>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>si veda <cmdref targ="logit"/> per una spiegazione</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
        <flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non stampa i risultati</effect>
      </option>
      <option>
	<flag>--p-values</flag>
	<effect>mostra i p-value invece degli effetti
	marginali</effect>
      </option>
      <option>
        <flag>--estrella</flag>
         <effect>seleziona una variante dello pseudo-R-quadro</effect>
      </option>
      <option>
	<flag>--random-effects</flag>
	<effect>stima un modello panel a effetti casuali (RE)</effect>
      </option>
      <option>
	<flag>--quadpoints</flag>
	<optparm>k</optparm>
	<effect>numero di punti di quadratura per la stima RE</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>ooballot.inp</demo>
	<demo>oprobit.inp</demo>
	<demo>reprobit.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Se la variabile dipendente è binaria (tutti i suoi valori sono
      0 o 1), esegue una stima di massima verosimiglianza dei
      coefficienti delle <repl>variabili-indipendenti</repl> con il
      metodo Newton&ndash;Raphson. Visto che il modello è nonlineare, gli
      effetti marginali (pendenze) dipendono dai valori delle
      variabili indipendenti: per impostazione predefinita, al posto
      dei p-value vengono mostrate le pendenze rispetto ad ognuna
      delle variabili indipendenti, calcolate in corrispondenza
      della media della variabile. Questo comportamento può essere
      soppresso usando l'opzione <opt>p-values</opt>.  La
      statistica chi-quadro testa l'ipotesi nulla che tutti i
      coefficienti tranne la costante siano pari a zero.
    </para>
    <para context="cli">
      In modalità predefinita, gli errori standard sono calcolati
      tramite l'inversa negativa della matrice Hessiana. Se si usa
      l'opzione <opt>robust</opt>, verranno calcolati gli errori
      standard con il metodo QML o con quello di Huber&ndash;White.
      In questo caso, la matrice di covarianza stimata è un
      <quote>sandwich</quote> dell'inversa dell'Hessiana stimata e
      del prodotto esterno del gradiente. Per i dettagli, si veda
      Davidson e MacKinnon 2004, cap. 10.
    </para>
    <para context="cli">
      Per idefault, viene mostrata la statistica pseudo-R-quadro
      suggerita da <cite key="mcfadden74">McFadden (1974)</cite>, ma
      nel caso binario, se viene specificata l'opzione
      <opt>estrella</opt>, viene invece mostrata la variante
      consigliata da <cite key="estrella98">Estrella
      (1998)</cite>. Questa variante, presumibilmente, imita più da
      vicino le proprietà del normale <math>R</math><sup>2</sup> nel
      contesto della stima OLS.
   </para>
   <para context="gui">
      In modalità predefinita, gli errori standard sono calcolati
      tramite l'inversa negativa della matrice Hessiana. Se si
      seleziona la casella "Errori standard robusti", verranno
      calcolati gli errori standard con il metodo QML o con quello di
      Huber&ndash;White. In questo caso, la matrice di covarianza
      stimata è un <quote>sandwich</quote> dell'inversa
      dell'Hessiana stimata e del prodotto esterno del
      gradiente. Per i dettagli, si veda Davidson e MacKinnon 2004,
      cap. 10.
    </para>
    <para>
      Se la variabile dipendente non è binaria ma è discreta allora si
      otterranno delle stime Ordered Probit. (Se la variabile selezionata
      come dipendente non è nemmeno discreta allora viene segnalato un
      errore.)
    </para>
    <subhead>Probit per dati panel</subhead>
    <para>
      Con l'opzione <opt>random-effects</opt>, il termine di errore è
      composto per ipotesi da due componenti gaussiane: una
      specifica per l'unità cross-sezionale e invariante nel tempo
      (nota come <quote>effetto individuale</quote>) e l'altra
      specifica per quella particolare osservazione.
    </para>
    <para>
      Il calcolo della log-verosimiglianza per questo modello viene
      effettuato tramite la quadratura di Gauss-Hermite per
      approssimare il valore di valori attesi di funzioni di
      variabili casuali normali. Il numero di punti di quadratura
      usati si può scegliere tramite l'opzione
      <opt>quadpoints</opt> (il default è 32). Un numero elevato
      di questi aumenta l'accuratezza dei risultati, ma al costo di
      tempi di calcolo più lunghi; in questo caso la stima può
      richiedere molto tempo con dataset grandi.
    </para>
    <para>
      Oltre ai parametri standard (e statistiche associate) relativi
      alle variabili esplicative, dopo la stima di questo tipo di
      modello vengono presentati alcuni risultati aggiuntivi:
    </para>
    <ilist>
      <li>
	<para>
	  <lit>lnsigma2</lit>: la stima ML del logaritmo della
	  varianza dell'effetto individuale;
	</para>
      </li>
      <li>
	<para>
	  <lit>sigma_u</lit>: la stima dell'errore quadratico medio
	  dell'effetto individuale;
	</para>
      </li>
      <li>
	<para>
	  <lit>rho</lit>: la quota stima dell'effetto individuale
	  sulla varianza totale del termine di errore composito
	  (anche nota come correlazione intra-classe).
	</para>
      </li>
    </ilist>
    <para>
      Il test LR per l'ipotesi nulla <lit>rho</lit>=0 consente di
      stabilire se la specificazione a effetti random è davvero
      necessaria. Sotto la nulla, una semplice specificazione probit
      è del tutto adeguata. Se la nulla non viene rigettata allora questo
      suggerirà che una semplice specificazione pooled per il modello probit
      risulta più che adeguata.
    </para>
    <para>
      Il probit per l'analisi delle proporzioni non è ancora stato
      implementato in	<program>gretl</program>.
    </para>
  </description>
  
  <gui-access>
    <menu-path>/Modello/Modelli non lineari/Probit</menu-path>
  </gui-access>
  
</command>

<command name="pvalue" section="Utilities" label="Calcola p-value" context="cli">
  
  <usage>
    <arguments>
      <argument>distribuzione</argument>
      <argument optional="true">parametri</argument>
      <argument>valore-x</argument>
    </arguments>
    <examples>
      <example>pvalue z zscore</example>
      <example>pvalue t 25 3.0</example>
      <example>pvalue X 3 5.6</example>
      <example>pvalue F 4 58 fval</example>
      <example>pvalue G shape scale x</example>
      <example>pvalue B bprob 10 6</example>
      <example>pvalue P lambda x</example>
      <example>pvalue W shape scale x</example>
      <demos>
	<demo>mrw.inp</demo>
	<demo>restrict.inp</demo>
      </demos>
    </examples>
  </usage>
  
  <description>
    <para>
      Calcola l'area alla destra del <repl>valore-x</repl> nella
      distribuzione indicata (<lit>z</lit> per la Gaussiana,
      <lit>t</lit> per la <math>t</math> di Student, <lit>X</lit>
      per la chi-quadro, <lit>F</lit> per la <math>F</math>,
      <lit>G</lit> per la gamma, <lit>B</lit> per la binomiale,
      <lit>P</lit> per la Poisson, <lit>exp</lit> per l'esponenziale
      negativa e <lit>W</lit> per la Weibull).
    </para>
    <para>
      A seconda della distribuzione, occorre fornire le seguenti
      informazioni, prima del <repl>valore-x</repl>: per le
      distribuzioni <math>t</math> e chi-quadro occorre indicare i
      gradi di libertà; per la <math>F</math> sono richiesti i gradi
      di libertà al numeratore e al denominatore; per la gamma sono
      richiesti il parametro di forma e quello di scala; per la
      binomiale sono richieste la probabilità di
      <quote>successo</quote> e il numero di prove; per la
      distribuzione di Poisson va indicato il parametro &lgr; (che
      rappresenta sia la media che la varianza); per l'esponenziale,
      il parametro di scala; per la distribuzione Weibull, i
      parametri di forma e scala.  Come si vede dagli esempi
      precedenti, gli argomenti numerici possono essere indicati
      sotto forma di numero o come nomi di variabili.
    </para>
    <para>
      Si noti che talvolta la distribuzione gamma viene
      caratterizzata dai parametri di media e varianza, invece che
      da quelli di forma e scala.  La media è il prodotto di forma e
      scala, mentre la varianza è il prodotto tra la forma e il
      quadrato della scala. Quindi la scala si può ottenere come la
      varianza divisa per la media, mentre la forma come la media
      divisa per la scala.
    </para>
  </description>
  
  <gui-access>
    <menu-path>/Strumenti/Calcola p-value</menu-path>
  </gui-access>
  
</command>

<command name="qlrtest" section="Tests" label="Test del rapporto di verosimiglianza di Quandt">

  <usage>
    <options>
      <option>
	<flag>--limit-to</flag>
	<optparm>lista</optparm>
	<effect>limita il test a una parte delle variabili esplicative</effect>
      </option>
      <option>
	<flag>--plot</flag>
	<optparm>mode-or-filename</optparm>
	<effect>si veda sotto</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra l'output</effect>
      </option>
    </options>
  </usage>
  
  <description>
    <para>
      Per un modello stimato con OLS su serie storiche, esegue il
      test del rapporto di verosimiglianza di Quandt (QLR) per un
      break strutturale in un punto incognito del campione,
      escludendo il 15% delle osservazioni all'inizio e ella fine
      del campione.
    </para>
    <para>
      Per ogni possibile punto di rottura compreso nel 70% centrale
      delle osservazioni, viene eseguito un test di Chow (si veda
      <cmdref targ="chow"/>); come per il test di Chow vero e
      proprio, questo è un test di Wald robusto se il modello
      originale è stato stimato con l'opzione <opt>robust</opt>. La
      statistica del test QLR è il massimo dei valori <math>F</math>
      di questi test e segue una distribuzione non standard.
    </para>
    <para>
      Il p-value asintotico è ottenuto usando il metodo di <cite
	key="hansen97">Bruce Hansen (1997)</cite>.
    </para>
    <para>
      Oltre agli accessori standard <fncref targ="$test"/> e <fncref
      targ="$pvalue"/>, questo comando genera anche <fncref
      targ="$qlrbreak"/>, che restituisce l'indice
      dell'ossservazione alla quale la statistica test è massima.
    </para>
    <para context="cli">
      L'opzione <opt>limit-to</opt> serve a limitare le interazioni
      con la dummy di divisione del campione nei test di Chow a un
      sottoinsieme dei regressori originali. Il parametro dev'essere
      una lista predefinita che non può contenere la costante; gli
      elementi della lista devono essere tutti scelti fra i regressori
      originali.
    </para>
    <para>
      Quando questo comando viene eseguito interattivamente, di
      default verrà mostrato un grafico delle statistiche del test
      di Chow.  Questo comportamento si può modificare con l'opzione
      <opt>plot</opt>. I parametri consentiti sono <lit>none</lit>
      (per fare a meno del grafico); <lit>display</lit> (per
      mostrare il grafico anche quando non si è in modo
      interattivo), oppure un nome di file. Per la descrizione
      dell'effetto di quest'ultima scelta, si veda l'opzione
      <opt>output</opt> del comando <cmdref targ="gnuplot"/>.
    </para>
  </description>
  
  <gui-access>
    <menu-path>Finestra del modello, /Test/QLR</menu-path>
  </gui-access>
  
</command>

<command name="qqplot" section="Graphs" label="Q-Q plot">

  <usage>
    <altforms>
      <altform><lit>qqplot</lit> <repl>y</repl></altform>
      <altform><lit>qqplot</lit> <repl>y</repl> <repl>x</repl></altform>
    </altforms>
    <options>
      <option>
	<flag>--z-scores</flag>
	<effect>v. oltre</effect>
      </option>
      <option>
	<flag>--raw</flag>
	<effect>v. oltre</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>nomefile</optparm>
	<effect>manda il grafico ad un file specificato</effect>
      </option>
    </options>
  </usage>

  <description>
    <para context="gui">
      Con una sola serie selezionata, mostra un grafico della
      distribuzione empirica della serie stessa contro i quantili
      della normale. La serie deve includere almeno 20 valori validi
      nel campione selezionato al momento. Per impostazione
      predefinita, i quantili empirici vengono disegnati contro
      quelli della normale avente media e varianza uguali a quelli
      campionari della serie, ma sono disponibili due alternative: i
      dati possono essere standardizzati prima, oppure i quantili
      empirici possono essere disegnati contro quelli della normale
      standardizzata.
    </para>
    <para context="cli">
      Con una sola serie come argomento, mostra un grafico della
      distribuzione empirica della serie stessa (indicata col nome o
      con il suo numero ID) contro i quantili della normale. La
      serie deve includere almeno 20 valori validi nel campione
      selezionato al momento. Per impostazione predefinita, i
      quantili empirici vengono disegnati contro quelli della
      normale avente media e varianza uguali a quelli campionari
      della serie, ma sono disponibili due alternative: con
      l'opzione <opt>z-scores</opt>, i dati vengono standardizzati
      prima, oppure, con l'opzione <opt>raw</opt>, i quantili
      empirici possono essere disegnati contro quelli della normale
      standardizzata.
    </para>
    <para>
      Tramite l'opzione <opt>output</opt> si invia il grafico al
      file desiderato; usare <quote>display</quote> per forzare l'output
      allo schermo, ad esempio nel contesto di un loop. si veda il comando
      <cmdref targ="gnuplot"/> per maggiori dettagli in merito a quest'opzione.
    </para>
    <para>
      Con due argomenti, <repl>y</repl> and <repl>x</repl>, mostra
      un grafico dei quantili empirici di <repl>y</repl> contro
      quelli di <repl>x</repl>. I dati non vengono standardizzati.
    </para>
  </description>

  <gui-access>
    <menu-path>/Variabile/Q-Q normale</menu-path>
    <menu-path>/Visualizza/Grafico/Q-Q</menu-path>
  </gui-access>
  
</command>

<command name="quantreg" section="Estimation"
	 label="Regressione quantile">
  
  <usage>
    <arguments>
      <argument>tau</argument>
      <argument>variabile-dipendente</argument>
      <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--intervals</flag>
	<optparm optional="true">level</optparm>
	<effect>calcola gli intervalli di confidenza</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>sopprime la stampa dei risultati</effect>
      </option>
    </options>
    <examples>
      <example>quantreg 0.25 y 0 xlist</example>
      <example>quantreg 0.5 y 0 xlist --intervals</example>
      <example>quantreg 0.5 y 0 xlist --intervals=.95</example>
      <example>quantreg tauvec y 0 xlist --robust</example>
      <demos>
	<demo>mrw_qr.inp</demo>
      </demos>
    </examples>
  </usage>
  
  <description context="gui">
    <para>
      Regressione a quantili. Per default, gli errori standard sono
      calcolati con la formula asintotica di Koenker e Bassett
      (<book>Econometrica</book>, 1978), ma se si attiva la casella
      <quote>robust</quote> verrà usata la variante robusta per
      l'eteroschedasticità di Koenker e Zhao (<book>Journal of
      Nonparametric Statistics</book>, 1994).
    </para>
    <para>
      Se si abilita l'opzione <quote>Calcola intervalli di confidenza</quote>,
      gretl calcolerà gli intervalli di confidenza invece degli errori
      standard. La casella <quote>robust</quote> mantiene il suo effetto: se
      non è selezionata, gli intervalli sono calcolati nell'ipotesi di errori
      IID, altrimenti gretl usa lo stimatore robusto sviluppato da
      Koenker e Machado (<book>Journal of the American
      Statistical Association</book>, 1999).  Si noti che questi intervalli
      non sono calcolati semplicemente aggiungendo e sottraendo un certo numero
      di errori standard: in generale sono asimmetrici rispetto alle stime
      puntuali dei parametri.
    </para>
    <para>
      È possibile indicare un elenco di quantili (il menù a discesa contiene
      alcune possibilità predefinite), e in tal caso gretl calcolerà stime
      quantili ed errori standard o intervalli di confidenza per ognuno dei
      valori specificati.
    </para>
    <para>
      Per un approfondimento, si veda <guideref targ="chap:quantreg"/>.
    </para>
  </description>
  
  <description context="cli">
    <para>
      Regressione a quantili. Il primo argomento, <repl>tau</repl>, è il
      quantile condizionale per cui si desiderano le stime. Può essere un
      valore numerico o il nome di una variabile scalare predefinita; il
      valore deve essere compreso nell'intervallo da 0.01 a 0.99 (in
      alternativa, può essere indicato un vettore di valori, si veda sotto per
      i dettagli). Gli argomenti dal secondo in poi compongono un elenco di
      regressori sul modello di quello usato in <cmdref targ="ols"/>.
    </para>
    <para>
      Senza l'opzione <opt>intervals</opt>, vengono mostrati gli
      errori standard per le stime quantili; per impostazione
      predefinita questi sono calcolati con la formula asintotica di
      <cite key="koenker-bassett78">Koenker e Bassett (1978)</cite>,
      ma se si usa l'opzione <opt>robust</opt>, verrà usata la
      variante robusta per l'eteroschedasticità utilizzando il
      metodo di <cite key="koenker-zhao94">Koenker e Zhao
      (1994)</cite>.
    </para>
    <para>
      Se si usa l'opzione <opt>intervals</opt>, gretl calcolerà gli
      intervalli di confidenza invece degli errori standard.  Questi
      intervalli sono calcolati col metodo dell'inversione del rango e in
      generale sono asimmetrici rispetto alle stime puntuali dei parametri.
      Se non si usa l'opzione <quote>--robust</quote>, gli intervalli sono
      calcolati nell'ipotesi di errori IID <cite key="koenker94" p="true">(Koenker,
      1994)</cite>, mentre se viene indicata sono calcolati con lo stimatore
      robusto sviluppato <cite key="koenker-machado99">Koenker e Machado (1999)</cite>.
    </para>
    <para>
      Per impostazione predefinita vengono prodotti intervalli di confidenza
      al 90%. È possibile specificare un altro livello di confidenza (sotto
      forma di frazione decimale), aggiungendolo all'opzione, come in
      <lit>--intervals=0.95</lit>.
    </para>
    <para>
      Invece di indicare <repl>tau</repl> come uno scalare, è possibile usare
      un vettore, indicando il nome di una matrice predefinita. In questo
      caso le stime vengono eseguite per tutti i valori di <repl>tau</repl>, e
      i risultati mostrano la sequenza delle stime quantili per ognuno dei
      regressori.
    </para>
  </description>
  
  <gui-access>
    <menu-path>/Modello/Stima robusta/Regressione quantile</menu-path>
  </gui-access>
  
</command>

<command name="quit" section="Utilities" label="Esce dal programma" context="cli">

  <description>
    <para>
      Esce dalla modalità corrente di gretl.
    </para>
    <ilist>
      <li>
	<para>
	  Quando il comando è in uno script, l'esecuzione dello
	  script viene interrotta.  Se il contesto è gretlcli (il
	  client testuale) in modalità batch, terminerà gretlcli
	  stesso; altrimenti, il programma tornerà in modalità interattiva.
	</para>
      </li>
      <li>
	<para>
	  Quando il comando viene eseguito nel terminale GUI, il
	  terminale si chiuderà.
	</para>
      </li>
      <li>
	<para>
	  Quando il comando viene eseguito in modo interattivo, il
	  programma esce.
	</para>
      </li>
    </ilist>
    <para>
      Si noti che questo comando non può essere eseguito all'interno
      di funzioni o di loop.
    </para>
    <para>
      In comando <lit>quit</lit> non provoca l'uscita dal programma
      GUI in alcun caso. Per uscire, si può usare la voce
      <lit>Esci</lit> del menu <lit>File</lit>, o <lit>Ctrl+Q</lit>,
      o cliccando sul pulsante di chiusura della barra della
      finestra.
    </para>
  </description>

</command>

<command name="regls" section="Estimation"
	 label="Regularized least squares" context="gui">
  <description>
    <para>
      Questa finestra di dialogo permette di utilizzare alcuni dei
      metodi per minimi quadrati regolarizzati che sono implementati
      nella funzione <lit>regls</lit>.
    </para>
    <para>
      Sono previste tre varianti: LASSO, che penalizza la somma dei
      valori assoluti dei coefficienti; Ridge, che penalizza la
      somma dei loro quadrati; e la "rete elastica", che è una
      combinazione degli altri due, regolata dall'iperparametro
      &alpha;. (&alpha; = 1 porta al LASSO, &alpha; = 0 al Ridge;
      valori intermedi danno una combinazione ponderata.)
    </para>
    <para>
      Il termine &lgr; specifica quanto sia forte la
      penalizzazione. Sì può specificare un unico valore frazionale
      per &lgr;-fraction (da 0 = nessuna penalizzazione a 1 =
      massima penalizzazione), oppure un numero di valori per
      &lgr;. Nel secondo caso i valori di penalizzazione vengono
      scalati automaticamente.
    </para>
    <para>
      Selezionandi più valori &lgr; diventa disponibile l'opzione di
      cross-validation. In tal caso si può scegliere il numero di
      <quote>fold</quote> per i dati di training (predefinito 10) e se
      questi fold devono essere sottoinsiemi casuali o contigui delle
      osservazioni. Si può anche scegliere di mostrare un grafico
      dell'errore quadratico medio (MSE) rispetto alla frazione &lgr;.
    </para>
    <para>
      	Il pulsante <quote>Opzioni avanzate</quote> porta a una nuova
      	finestra che permette un controllo più fine sulla procedura di
      	regolarizzazione. Tuttavia, si noti che è possibile esercitare
      	un controllo molto più puntuale su questa procedura usando la
      	funzione <lit>regls</lit> da script. Si veda
      	<doc>regls.pdf</doc> per ulteriori dettagli.
    </para>
  </description>
</command>

<command name="regls-advanced" section="Estimation"
	 label="Opzioni regls avanzate" context="gui">
  <description>
    <para>
      Ciò che si seleziona in questa finestra viene applicato solo
      quando è pertinente, a seconda delle scelte fatte nella finestra
      principale di regls. Le scelte vengono ricordate per tutta la
      sessione di gretl.
      </para>
      <ilist>
	<li>
	  <para>
	    Scelta dell'algoritmo: si possono scegliere il metodo CCD
	    (Cyclical Coordinate Descent) sia per il LASSO che per la
	    regressione Ridge, invece dei metodi di default cioè lo
	    ADMM (Alternating Direction Method of Multipliers) per il
	    e la scompozizione in valori singolari (SVD) per il Ridge.
	  </para>
	</li>
	<li>
	  <para>
	    Il criterio di default per la <quote>migliore</quote>
	    performance nella cross validation è la minimizzazione
	    dell'errore quadratico medio (MSE), ma si può optare per
	    la regola alternativa <quote>dello standard
	    error</quote>. Questa alternativa, che privilegia la
	    parsimonia, sceglie la penalità più grande tale per cui lo
	    MSE è a non più di un errore standard dal minimo.
	  </para>
	</li>
	<li>
	  <para>
	    Seme per randomizzare i <quote>fold</quote>: per ottenere
	    risultati replicabili quando si usa la cross-validation
	    con fold casuali, è necessario specificare un seme per la
	    generazione dei numeri casuali.
	  </para>
	</li>
	<li>
	  <para>
	    Per accelerare la cross-validation, regls usa di default
	    la parallelizzazione MPI, se disponibile. La casella MPI
	    (che appare solo se gretl è compliato col supporto per
	    MPI) permette di disattivare quest'opzione, cosa che può
	    rivelarsi vantaggiosa per dataset piccoli.
	  </para>
	</li>
	<li>
	  <para>
	    L'opzione di mostrare il tempo di esecuzione può essere
	    utile per confrontare le prestazioni di algoritmi diversi,
	    o per controllare se c'è un vantaggio nell'uso di MPI. Il
	    tempo mostrato è relativo all'esecuzione del codice C
	    sottostante.
	  </para>
	</li>
      </ilist>
  </description>
</command>


<command name="rename" section="Dataset" label="Rinomina variabili" context="cli">

  <usage>
    <arguments>
      <argument>serie</argument>
      <argument>nuovo-nome</argument>
    </arguments>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>sopprime la stampa dell'output</effect>
      </option>
      <option>
	<flag>--case</flag>
	<effect>cambia maiuscolo/minuscolo per tutte le serie (vedi sotto)</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Senza l'opzione <opt>--case</opt>, questo comando cambia il nome
      di una <repl>serie</repl> (identificata da un nome o da un
      numero identificativo) con un <repl>nuovo-nome</repl>. Il nuovo
      nome deve essere di massimo 31 caratteri, deve iniziare con una
      lettera e deve essere composto da una combinazione di sole
      lettere, cifre e trattini.  In aggiunta il nuovo nome non deve
      essere già ad appartenente a nessun oggetto di nessun tipo del
      dataset.
    </para>
    <para>
      L'opzione <opt>--case</opt> consente di cambiare tutte le serie
      in maiuscolo/minuscolo. Con questa opzione, non si deve fornire
      il nome della serie da rinominare, perché il cambiamento si
      applicherà a tutto mil dataset. Sono disponibili le seguenti conversioni:
  </para>
  <ilist>
    <li>
      <para>
	<repl>lower</repl>: Converte tutti i nomi di serie in minuscolo.
      </para>
    </li>
    <li>
      <para>
	<repl>upper</repl>: Converte tutti i nomi di serie in maiuscolo.
      </para>
    </li>
    <li>
      <para>
	<repl>camel</repl>: Converte tutti i nomi di serie in "camelCase"
	(parole consecutive sono indicate dall'iniziale maiuscola: per esempio,
	<lit>regioneMarche</lit>).
      </para>
    </li>
    <li>
      <para>
	<repl>snake</repl>: Converte tutti i nomi di serie in "snake case"
	(parole consecutive sono separate da un trattino basso: per
	esempio, <lit>regione_marche</lit>).
      </para>
    </li>
  </ilist>
  <para>
    Si noti che in qualche caso la conversione potrebbe avere effetti
    indesiderati: ad esempio, con una serie il cui nome è tutto maiuscolo
    la conversione a "snake case" sarebbe piuttosto bizzarra.
  </para>
  <code>
    rename y x
    rename --case=upper
  </code>
    
  </description>

  <gui-access>
    <menu-path>/Variabile/Modifica attributi</menu-path>
    <other-access>Menù pop-up nella finestra principale (selezione
    singola)</other-access>
  </gui-access>

</command>

<command name="reprobit" section="Estimation" label="Random effects probit"
	 context="gui">

  <description>
    <para>
      Lo stimatore a effetti random consente di stimare un modello
      probit binario in dataset di tipo panel. Il termine di errore
      è, per ipotesi, composto da due componenti gaussiane: una
      specifica per l'unità cross-sezionale e invariante nel tempo
      (nota come <quote>effetto individuale</quote>), l'altra
      specifica per quella particolare osservazione.
    </para>
    <para>
      Il calcolo della log-verosimiglianza per questo modello viene
      effettuato tramite la quadratura di Gauss-Hermite per
      approssimare il valore di valori attesi di funzioni di
      variabili casuali normali.  In questa finestra di dialogo è
      possibile scegliere il numero di punti di quadratura usati. Un
      numero elevato di questi aumenta l'accuratezza dei risultati,
      ma al costo di tempi di calcolo più lunghi; in questo caso la
      stima può richiedere molto tempo con dataset grandi.
    </para>
    <para>
      Oltre ai parametri standard (e statistiche associate) relativi
      alle variabili esplicative, dopo la stima di questo tipo di
      modello vengono presentati alcuni risultati aggiuntivi:
    </para>
    <ilist>
      <li>
	<para>
	  <lit>lnsigma2</lit>: la stima ML del logaritmo della
	  varianza dell'effetto individuale;
	</para>
      </li>
      <li>
	<para>
	  <lit>sigma_u</lit>: la stima dell'errore quadratico medio
	  dell'effetto individuale;
	</para>
      </li>
      <li>
	<para>
	  <lit>rho</lit>: la quota stimata dell'effetto individuale
	  sulla varianza totale del termine di errore composito
	  (anche nota come correlazione intra-classe).
	</para>
      </li>
    </ilist>
    <para>
      Il test LR per l'ipotesi <lit>rho</lit>=0 consente di
      stabilire se la specificazione a effetti random è in effetti
      necessaria. Sotto la nulla, una semplice specificazione probit
      è del tutto adeguata.
    </para>
    <para>
      In modalità scripting, il modello probit a effetti random si
      ottiene usando il comando <lit>probit</lit> con l'opzione
      <opt>random-effects</opt>.
    </para>
  </description>
  
</command>

<command name="reset" section="Tests" label="Test RESET di Ramsey">

  <usage>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra la regressione ausiliaria</effect>
      </option>
      <option>
	<flag>--silent</flag>
	<effect>non mostra nulla</effect>
      </option>
      <option>
	<flag>--squares-only</flag>
	<effect>calcola il test coi soli quadrati</effect>
      </option>
      <option>
	<flag>--cubes-only</flag>
	<effect>calcola il test coi soli cubi</effect>
      </option>
	<option>
	  <flag>--robust</flag>
	  <effect>usa standard errors robusti nella regressione ausiliaria</effect>
	</option>
    </options>
  </usage>

  <description>
    <para>
      Deve seguire la stima di un modello OLS. Esegue il test RESET
      di Ramsey per la specificazione del modello (non-linearità)
      aggiungendo alla regressione i quadrati e/o cubi dei valori
      stimati, e calcola la statistica <math>F</math> per l'ipotesi
      nulla sotto la quale i coefficienti &bgr; delle variabili
      aggiunte siano uguali a zero. Per ragioni numeriche, i quadrati
      e i cubi vengono riscalati usando lo scarto quadratico medio dei
      valori stimati.
    </para>
    <para context="cli">
      Sia i quadrati che i cubi vengono aggiunti al modello in
      maniera predefinita a meno che non vengano specificate le
      opzioni <opt>squares-only</opt> o <opt>cubes-only</opt>.
    </para>
    <para context="cli">
      L'opzione <opt>silent</opt> può essere usata se si intendono
      utilizzare solo gli accessori <fncref targ="$test"/> o <fncref
      targ="$pvalue"/> per disporre direttamente dei risultati del
      test.
    </para>
      <para context="cli">
	L'opzione <opt>robust</opt> è implicita se la il modello su
	cui effettuare il test è stato stimato usando a sua volta
	errori robusti.
      </para>
  </description>

  <gui-access>
    <menu-path>Finestra del modello, /Test/RESET - Ramsey</menu-path>
  </gui-access>

</command>

<command name="restrict" section="Tests" context="cli"
	 label="Test su vincoli">

  <usage>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>non stampare le stime vincolate</effect>
      </option>
      <option>
	<flag>--silent</flag>
	<effect>non stampare niente</effect>
      </option>
      <option>
	<flag>--wald</flag>
	<effect>solo per stimatori di sistema &ndash; vedi sotto</effect>
      </option>
      <option>
	<flag>--bootstrap</flag>
	<effect>se possibile, effettuare il bootstrap del test</effect>
      </option>
      <option>
	<flag>--full</flag>
	<effect>solo OLS e VECM, vedi sotto</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>hamilton.inp</demo>
	<demo>restrict.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Impone un insieme di vincoli (solitamente lineari) su (a)
      l'ultimo modello stimato o (b) su un sistema di equazioni
      definito in precedenza.  In entrambi i casi, l'insieme di
      vincoli deve essere racchiuso tra i comandi
      <quote>restrict</quote> e <quote>end restrict</quote>.
    </para>
    <para>
      Nel caso di una equazione singola, i vincoli sono applicati
      implicitamente all'ultimo modello e vengono valutati appena
      viene terminato il comando <quote>restrict</quote>.
    </para>
    <para>
      Nel caso di un sistema (definito attraverso il comando <cmdref
      targ="system"/>), il comando iniziale <quote>restrict</quote>
      può essere seguito dal nome di un sistema di equazioni definito
      in precedenza; altrimenti, le restrizioni si applicheranno
      all'ultimo modello stimato.  I vincoli vengono valutati nella
      successiva stima del sistema effettuata con il comando <cmdref
      targ="estimate"/>. Tuttavia, se viene usata l'opzione
      <opt>wald</opt>, il vincolo viene testato immediatamente per
      mezzo di un test chi quadro di Wald usando la matrice di
      covarianze stimata. Si noti che questa opzione produrrà un
      errore se il sistema è stato definito, ma non ancora stimato.
    </para>
    <para>
      A seconda del contesto, i vincoli possono essere espressi in
      diversi modi. Quello più semplice è di esprimere ogni vincolo
      come equazione, con una combinazione lineare dei parametri a
      sinistra e uno scalare a destra del segno di uguale (una
      costante o, volendo, il nome di una variabile scalare).
    </para>
    <para>
      Nel caso un cui la stima sia di una equazione singola, i
      parametri sono indicati con la sintassi
      <lit>b[</lit><repl>i</repl><lit>]</lit>, dove <repl>i</repl>
      rappresenta la posizione nella lista dei regressori, a partire
      da uno, oppure con
      <lit>b[</lit><repl>variabile</repl><lit>]</lit>, dove
      <repl>variabile</repl> è il nome del regressore in questione.
      Nel caso di sistemi, i parametri vengono indicati con la
      sintassi <lit>b</lit> seguita da due numeri tra parentesi
      quadre.  Il primo numero rappresenta la posizione dell'equazione
      all'interno del sistema, mentre il secondo indica la posizione
      nella lista dei regressori. Ad esempio <lit>b[2,1]</lit> indica
      il primo parametro della seconda equazione, mentre
      <lit>b[3,2]</lit> il secondo parametro della terza equazione. I
      termini <lit>b</lit> nell'equazione che rappresenta un vincolo
      possono essere prefissati da un moltiplicatore numerico, usando
      il segno <lit>*</lit> per indicare la moltiplicazione, ad
      esempio <lit>3.5*b[4]</lit>.
    </para>
    <para>
      Ecco un esempio di un insieme di vincoli per un modello
      stimato in precedenza:
    </para>
    <code>
      restrict
      b[1] = 0
      b[2] - b[3] = 0
      b[4] + 2*b[5] = 1
      end restrict
    </code>
    <para>
      Ed ecco un esempio di un insieme di vincoli da applicare a un
      sistema (se il nome del sistema non contiene spazi, è
      possibile tralasciare le virgolette).
    </para>
    <code>
      restrict "Sistema 1"
      b[1,1] = 0
      b[1,2] - b[2,2] = 0
      b[3,4] + 2*b[3,5] = 1
      end restrict
    </code>
    <para>
      Nel caso di una equazione singola le restrizioni sono valutate,
      per default, tramite un test di Wald, che utilizza la matrice di
      covarianze del modello in questione.  Se il modello originale è
      stato stimato via OLS allora vengono mostrati i coefficienti
      vincolati stimati, a meno che non si utilizzi l'opzione
      <opt>quiet</opt> all'inizio del comando <lit>restrict</lit>.
      Come alternativa al test di Wald è possibile dare usare
      l'opzione <opt>bootstrap</opt> affinché venga eseguito un test
      sulla restrizione attraverso tale metodo; ciò è consentito
      solamente per modelli stimati attraverso OLS o WLS.
    </para>
    <para>
      Nel caso di un sistema, la statistica test dipende dallo
      stimatore scelto: un test del rapporto di verosimiglianza nel
      caso di un sistema stimato con un metodo di massima
      verosimiglianza, o un test <math>F</math> asintotico negli altri
      casi.
    </para>
    <subhead>Restrizioni lineari: sintassi alternativa</subhead>
    <para>
      Esistono due alternative alla rappresentazione dei vincoli
      discussa sopra.  Una sfrutta la possibilità di esprimere
      <math>g</math> restrizioni lineari su un vettore di
      <math>k</math>parametri, &bgr;, atraverso l'espressione
      <math>R</math>&bgr; &minus; <math>q</math> = 0, dove
      <math>R</math> è una matrice <by r="g" c="k"/> e
      <math>q</math> è un vettore a <math>g</math> elementi.  Le
      restrizioni possono essere date usando i nomi di matrici
      predefinite e conformabili da usare come <math>R</math> e
      <math>q</math>, come ad esempio in
    </para>
    <code>
      restrict
      R = Rmat
      q = qvec
      end restrict
    </code>
    <para>
      Una variante che può essere utile quando si usa
      <lit>restrict</lit> dentro una funzione prevede che le
      restrizioni siano espresse come array di stringhe, che viene
      usato tramite il comando <lit>inject</lit>, seguito dal nome
      dell'array. Ecco un semplice esempio:
    </para>
    <code>
      strings RS = array(2)
      RS[1] = "b[1,2] = 0"
      RS[2] = "b[2,1] = 0"
      restrict
      inject RS
      end restrict
    </code>
    <para>
      In pratica, stringhe di questo tipo possono essere create
      usando la funzione <fncref targ="sprintf"/>.
    </para>
    <subhead>Restrizioni non lineari</subhead>
    <para>
      Se si deve testare un vincolo non lineare (possibilità al
      momento prevista solo per i modelli ad equazione singola)
      bisogna dare al vincolo in nome di una funzione, preceduto da
      <quote><lit>rfunc = </lit></quote>, come ad esempio in
    </para>
    <code>
      restrict
      rfunc = myfunction
      end restrict
    </code>
    <para>
      La funzione vincolo deve avere, come unico argomento, una
      <lit>const matrix</lit>, che verrà automaticamente riempita col
      vettore dei parametri.  La funzione deve ritornare un vettore
      zero sotto lipotesi nulla e non-zero altrimenti.  La lunghezza
      del vettore è il numero di vincoli. Questa funzione è usata come
      argomento dalla routine interna di calcolo dello jacobiano, che
      calcola un test di Wald per mezzo del <quote>delta
      method</quote>.
    </para>
    <para>
      Quello che segue è un semplice esempio di funzione atta allo
      scopo di testare una restrizione non-lineare, cioè che due
      coppie di parametri stiano nello stesso rapporto fra loro.
    </para>
    <code>
      function matrix restr (const matrix b)
      matrix v = b[1]/b[2] - b[4]/b[5]
      return v
      end function
    </code>
    <para>
      Se il comando <lit>restrict</lit> va a buon fine, gli
      accessori <fncref targ="$test"/> e <fncref targ="$pvalue"/>
      restituiscono la statistica test ed il suo relativo p-value.
    </para>
    <para>
      Quando si testano delle restrizioni su un modello ad equazione
      singola stimato via OLS, o su una VECM, l'opzione
      <opt>full</opt> può essere usata per impostare le stime
      vincolate come <quote>ultimo modello</quote> di riferimento,
      allo scopo di compiere ulteriori test o di utilizzare
      eventuali accessori del tipo <lit>$coeff</lit> e
      <lit>vcv</lit>. Si noti che alcune considerazioni particolari
      sopraggiungono nel caso in cui si testino delle restrizioni su
      modelli VECM. Per maggiori dettagli si consiglia la lettura
      del<guideref targ="chap:vecm"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>Modello, /Test/Vincoli lineari</menu-path>
  </gui-access>

</command>

<command name="restrict-model" section="Tests" context="gui"
	 label="Vincoli su un modello">

  <description>
    <para>
      Ognuno dei vincoli da imporre a un modello deve essere espresso
      sotto forma di equazione con una combinazione lineare dei
      parametri al primo membro e un valore numerico al secondo. Nel
      caso della singola equazione, i parametri sono indicati con la
      sintassi <lit>b[</lit><repl>i</repl><lit>]</lit>, dove
      <repl>i</repl> rappresenta la posizione nella lista dei
      regressori, a partire da uno, oppure
      <lit>b[</lit><repl>variabile</repl><lit>]</lit>, dove
      <repl>variabile</repl> è il nome del regressore in questione.
    </para>
    <para>
      I termini <lit>b</lit> nell'equazione che rappresenta un vincolo
      possono essere prefissati con un moltiplicatore numerico usando il
      carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
      <lit>3.5*b[4]</lit>.
    </para>
    <para>
      Ecco ad esempio un insieme di vincoli:
    </para>
    <code>
      b[1] = 0
      b[2] - b[3] = 0
      b[4] + 2*b[5] = 1
    </code>
  </description>

</command>

<command name="restrict-system" section="Tests" context="gui"
	 label="Vincoli su un sistema di equazioni">

  <description>
    <para>
      Ognuno dei vincoli da imporre ad un sistema deve essere espresso
      sotto forma di equazione con una combinazione lineare dei parametri al
      primo membro e un valore numerico al secondo.
      I parametri vengono indicati con la sintassi <lit>b</lit> seguita da due
      numeri tra parentesi quadre.  Il primo numero rappresenta la posizione
      dell'equazione all'interno del sistema, mentre il secondo indica la
      posizione nella lista dei regressori, entrambi contati a partire da uno.
      Ad esempio <lit>b[2,1]</lit> indica il primo parametro della seconda
      equazione, mentre <lit>b[3,2]</lit> il secondo parametro della terza
      equazione.
    </para>
    <para>
      I termini <lit>b</lit> nell'equazione che rappresenta un vincolo
      possono essere prefissati con un moltiplicatore numerico usando il
      carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
      <lit>3.5*b[1,4]</lit>.
    </para>

    <para>
      Ecco ad esempio un insieme di vincoli:</para>

    <code>
      b[1,1] = 0
      b[1,2] - b[2,2] = 0
      b[3,4] + 2*b[3,5] = 1
    </code>

  </description>

</command>

<command name="restrict-vecm" section="Tests" context="gui"
	 label="Vincoli su un VECM">

  <description>
    <para>
      Questo comando impone restrizioni lineari sulle relazioni
      di cointegrazione (beta) e/o sui coefficienti di aggiustamento (alfa)
      in un modello vettoriale a correzione d'errore (VECM).
    </para>
    <para>
      Ognuno dei vincoli deve essere espresso sotto forma di equazione,
      con una combinazione lineare dei parametri al primo membro e un valore
      numerico al secondo membro. Le restrizioni su beta possono essere non
      omogenee (valore diverso da zero al secondo membro), ma quelle su alfa
      devono essere omogenee (valore zero al secondo membro).
    </para>
    <para>
      Se il VECM è di rango 1, è possibile esprimere gli elementi di beta nella
      forma <lit>b[</lit><repl>i</repl><lit>]</lit>,  dove <repl>i</repl>
      rappresenta la posizione nel vettore di correzione dell'errore, a
      partire da uno. Ad esempio, <lit>b[2]</lit> indica il secondo elemento
      di beta. Se il rango è maggiore di 1, è possibile esprimere i parametri
      usando <lit>b</lit> seguito da due numeri tra parentesi quadre. Ad
      esempio <lit>b[2,1]</lit> rappresenta il primo elemento nel secondo
      vettore di cointegrazione.
    </para>
    <para>
      Per riferirisi agli elementi di alfa, basta usare <lit>a</lit> al posto di
      <lit>b</lit>.
    </para>
    <para>
      Gli identificatori dei parametri nell'equazione che rappresenta un vincolo
      possono essere prefissati con un moltiplicatore numerico usando il
      carattere <lit>*</lit> per indicare la moltiplicazione, ad esempio
      <lit>3.5*b[4]</lit>.
    </para>
    <para>
      Ecco ad esempio un insieme di vincoli su un VECM di rango 1.
    </para>
    <code>
      b[1] + b[2] = 0
      b[1] + b[3] = 0
    </code>
    <para>
      Si veda anche <guideref targ="chap:vecm"/>.
    </para>

  </description>

</command>

<command name="rmplot" section="Graphs"
	 label="Grafici range-mean">

  <usage>
    <arguments>
      <argument>nome-variabile</argument>
    </arguments>
    <options>
      <option>
	<flag>--trim</flag>
	<effect>si veda oltre</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra l'output</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>nomefile</optparm>
	<effect>si veda oltre</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Grafici range&ndash;mean: questo comando crea un semplice
      grafico che aiuta a capire se una serie storica
      <math>y</math>(t) ha varianza costante o no. L'intero
      campione t=1,...,T viene diviso in piccoli sotto-campioni di
      dimensione arbitraria <math>k</math>. Il primo
      sotto-campione è formato da
      <math>y</math>(1), ... ,<math>y</math>(k), il secondo
      da <math>y</math>(k+1), ... , <math>y</math>(2k), e
      così via.  Per ogni sotto-campione, vengono calcolati la media e
      il campo di variazione (range: il valore massimo meno quello
      minimo) e viene costruito un grafico con le medie sull'asse
      orizzontale e i campi di variazione su quello verticale, in modo
      che ogni sotto-campione sia rappresentato da un punto sul piano.
      Se la varianza della serie è costante, ci si aspetta che il
      campo di variazione del sotto-campione sia indipendente dalla
      media del sotto-campione; se i punti si dispongono su una linea
      crescente, la varianza della serie cresce al crescere della
      media, viceversa se i punti si dispongono su una linea
      decrescente.
    </para>
    <para>
      Oltre al grafico, gretl mostra anche le medie e i campi di
      variazione per ogni sotto-campione, insieme al coefficiente di
      pendenza della regressione OLS del campo di variazione sulla
      media e il p-value per l'ipotesi nulla che la pendenza sia
      zero.  Se il coefficiente di pendenza è significativo al
      livello del 10 per cento, viene mostrata sul grafico la linea
      stimata della regressione del campo di variazione sulla media.
      La statistica <math>t</math> per l'ipotesi nulla, e il corrispondente
      p-value, vengono registrati e possono venire richiamati attraverso
      gli accessori <fncref targ="$test"/> e <fncref targ="$pvalue"/>.
    </para>
    <para context="cli">
      Se l'opzione <opt>trim</opt> è presente il valore minimo ed il
      valore massimo di ogni sotto-campione vengono scartati prima
      che la media ed il campo di variazione siano calcolati. Questo
      rende ancor più marginale la presenza di eventuali outlier
      che potrebbero distorcere i risultati dell'analisi.
    </para>
    <para context="cli">
      Se l'opzione <opt>quiet</opt> è data nessun grafico viene
      mostrato e nessun output viene stampato; solamente la
      statistica <math>t</math> ed il corrispondente p-value vengono
      registrati. Altrimenti il formato del grafico può venire
      controllato attraverso l'opzione <opt>output</opt>;
      quest'ultima funziona esattamente come descritto nel comando
      <cmdref targ="gnuplot"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Variabile/Grafico range-mean</menu-path>
  </gui-access>

</command>

<command name="run" section="Programming" label="Esegue uno script di comandi" context="cli">

  <usage>
    <arguments>
      <argument>file-input</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Esegue i comandi nel <repl>file-input</repl> e restituisce il
      controllo al prompt interattivo. Questo comando si intende
      usato con il programma a riga di comando gretlcli, o con il
      <quote>terminale di gretl</quote> nel programma con
      interfaccia grafica.
    </para>
    <para>
      Si veda anche <cmdref targ="include"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>Icona Esegui nella finestra comandi</menu-path>
  </gui-access>

</command>

<command name="runs" section="Tests" label="Test delle successioni">

  <usage>
    <arguments>
      <argument>nome-variabile</argument>
    </arguments>
    <options>
      <option>
        <flag>--difference</flag>
        <effect>usa la differenza prima della variabile</effect>
      </option>
      <option>
	<flag>--equal</flag>
	<effect>i valori positivi e negativi sono equiprobabili</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Esegue il test non parametrico <quote>delle successioni</quote>
      per la casualità della variabile specificata, dove le successioni
      sono definite come sequenze di valori consecutivi positivi o negativi.
      Ad esempio, per testare la casualità delle deviazioni dalla mediana per
      una variabile chiamata <lit>x1</lit>, con una mediana diversa da zero,
      eseguire i comandi seguenti:
    </para>
    <code>
      genr signx1 = x1 - median(x1)
      runs signx1
    </code>
    <para>
      Se si usa l'opzione <opt>difference</opt>, la variabile viene differenziata
      prima dell'analisi, quindi le successioni sono interpretabili come
      sequenze di incrementi o decrementi consecutivi nel valore della
      variabile.
    </para>
    <para>
      Se si usa l'opzione <opt>equal</opt>, l'ipotesi nulla incorpora
      l'assunzione che i valori positivi e negativi siano equiprobabili,
      altrimenti la statistica test è invariante rispetto
      all'<quote>equilibrio</quote> del processo che genera la sequenza,
      focalizzandosi solo sull'indipendenza.
    </para>
  </description>

  <gui-access>
    <menu-path>/Strumenti/Test non parametrici</menu-path>
  </gui-access>

</command>

<command name="sampling" section="Dataset" context="gui"
	 label="Impostazione del campione">

  <description>
    <para>
      Il menù Campione offre vari modi di selezionare un
      sotto-campione dal dataset in uso.
    </para>
    <para>
      Scegliendo <quote>Campione/Imposta in base a
      condizione...</quote>, viene chiesto di inserire un'espressione
      Booleana (logica), dello stesso tipo di quella che si userebbe
      per definire una variabile dummy. Ad esempio, l'espressione
      <quote>sqft &gt; 1400</quote> selezionerà solo le osservazioni
      per cui la variabile sqft ha un valore maggiore di 1400. Le
      condizioni possono essere concatenate con gli operatori logici
      <quote>&amp;&amp;</quote> (AND) e <quote>||</quote> (OR) e
      possono essere negate usando <quote>!</quote> (NOT). Se il
      dataset contiene variabili dummy, è anche possibile selezionarne
      una per definire il campione (le osservazioni incluse saranno
      quelle per cui la dummy vale 1).
    </para>
    <para>
      Il comando <quote>Campione/Scarta valori mancanti</quote>
      ridefinisce il campione in modo da escludere tutte le osservazioni
      per cui i valori di una o più variabili sono mancanti (lasciando
      nel campione solo i casi completi).
    </para>
    <para>
      Per selezionare le osservazioni per cui solo una certa
      variabile non ha valori mancanti, occorre usare
      <quote>Campione/Imposta in base a condizione...</quote> e inserire
      la condizione Booleana <quote>ok(nome-variabile)</quote>
      (sostituire <quote>nome-variabile</quote> con il nome della
      variabile che si intende usare).
    </para>
    <para>
      Se sono state associate etichette alle osservazioni, è possibile
      escludere una particolare osservazione dal campione impostando una
      condizione del tipo obs!="Francia". L'etichetta dell'osservazione deve
      essere racchiuso tra virgolette doppie.
    </para>
    <para>
      Occore tenere presente che ridefinendo il campione basandosi
      su una variabile dummy, un'espressione Booleana o sul criterio
      delle osservazioni mancanti, tutte le informazioni
      <quote>strutturali</quote> contenute nel file con la descrizione
      dei dati (riguardanti la struttura di serie storiche o di panel
      dei dati) vengono perse. È possibile reimpostare la struttura
      originale con <quote>Campione/Imposta frequenza e
      inizio...</quote>.
    </para>
    <para>
      Si veda <guideref targ="chap:sampling"/> per maggiori dettagli.
    </para>
  </description>
</command>

<command name="save-labels" section="Utilities"
	 label="Save or remove series labels" context="gui">
  <description>
    <para>
      Se scegliete Export, gretl scriverà un file contenente le etichette
      descrittive di tutte le variabili nel dataset corrente dotate di etichetta.
      Il file sarà in formato testo con una linea per ogni variabile.
      La linea di una variabile priva di etichetta verrà lasciata vuota.
    </para>
    <para>
      Se scegliete Remove, verranno cancellate le etichette
      descrittive di tutte le variabili dotate di etichetta. Una scelta di questo tipo
      è appropriata solo se le etichette correnti sono state aggiunte per errore.
    </para>
  </description>
</command>

<command name="add-labels" section="Utilities"
	 label="Add series labels" context="gui">
  <description>
    <para>
      Se scegliete Sì, vi apparirà la finestra di dialogo usata per
      aprire un file di testo contenente le etichette descrittive
      per le variabili nel dataset corrente. Il file deve contenere
      un'etichetta per ogni linea; una linea vuota significa nessuna
      etichetta. Gretl tenterà di leggere un numero di etichette
      pari a quello delle variabili nel dataset, esclusa la
      costante.
    </para>
  </description>
</command>

<command name="save-script" section="Utilities"
	 label="Save commands?" context="gui">
  <description>
    <para>
      Se scegliete Sì gretl trascriverà su un file una registrazione
      dei comandi eseguiti nel corso della sessione corrente. La
      maggior parte dei comandi che scegliete di eseguire usando un
      <quote>point and click</quote> hanno uno <quote>script</quote>
      equivalente, ed è questo script che verrà trascritto.  Il file
      così generato può servire come punto di partenza per la
      stesura di uno script di comandi di gretl.
    </para>
    <para>
      Se non vi interessa la possibilità che in uscita venga salvata una registrazione
      dei comandi, deselezionate la casella nella finestra di dialogo salva comandi.
    </para>
  </description>
</command>

<command name="save-session" section="Utilities"
	 label="Save this gretl session?" context="gui">
  <description>
    <para>
      Se scegliete Sì, gretl scriverà un file contenente
      una<quote>fotografia</quote> della sessione corrente, compresa
      una copia del dataset corrente e di tutti i modelli, grafici o
      altri oggetti che avete salvato <quote>come icone</quote>.  In
      seguito potete riaprire questo file per ricreare lo stato di
      gretl al momento in cui è stata abbandonata la sessione (v. il
      menu <quote>File/Sessioni</quote>).
    </para>
    <para>
      Se siete interessati prevalentemente a lavorare con gretl
      usando script di comandi (un modo di procedere che consigliamo
      caldamente per svolgere analisi econometriche
      <quote>serie</quote>), probabilmente non vi interessa salvare
      la sessione, ma dovete essere sicuri di salvare nello script
      tutte le modifiche che vi interessa conservare. Potreste anche
      voler salvare le modifiche effettuate al dataset, a meno che
      non siano facilmente ricreabili eseguendo uno script.
    </para>
    <para>
      Se lavorate con script e non vi interessa la possibilità di
      salvare la sessione in uscita, deselezionate la casella nella
      finestra di dialogo salva sessione.
    </para>
  </description>
</command>

<command name="scatters" section="Graphs"
	 label="Grafici multipli per coppie di variabili">

  <usage>
    <arguments>
      <argument>variabile-y</argument>
      <argument separated="true">lista-variabili-x</argument>
      <argument alternate="true">lista-variabili-y ; variabile-x</argument>
    </arguments>
    <options>
      <option>
	<flag>--with-lines</flag>
	<effect>crea grafici lineari</effect>
      </option>
      <option>
	<flag>--matrix</flag>
	<optparm>nome</optparm>
	<effect>mostra le colonne della matrice</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>noemfile</optparm>
	<effect>manda l'output al file specificato</effect>
      </option>
    </options>
    <examples>
      <example>scatters 1 ; 2 3 4 5</example>
      <example>scatters 1 2 3 4 5 6 ; 7</example>
      <example>scatters y1 y2 y3 ; x --with-lines</example>
    </examples>
  </usage>

  <description>
    <para context="cli">
      Produce grafici della <repl>variabile-y</repl> rispetto ad
      ognuna delle variabili nella <repl>lista-variabili-x</repl>,
      oppure di tutte le variabili nella
      <repl>lista-variabili-y</repl> rispetto alla
      <repl>variabile-x</repl>.  Il primo esempio visto sopra assegna
      la variabile 1 all'asse <math>y</math> e produce quattro
      grafici, il primo con la variabile 2 sull'asse <math>x</math>,
      il secondo con la variabile 3 sull'asse <math>x</math>, e così
      via. Il secondo esempio rappresenta ognuna delle variabili da 1
      a 6 rispetto alla variabile 7 sull'asse <math>x</math>. Questi
      gruppi di grafici sono utili nell'analisi esplorativa dei
      dati. È possibile creare fino a sei grafici alla volta,
      eventuali variabili in sovrappiù saranno ignorate.
    </para>
    <para context="cli">
      Per impostazione predefinita vengono prodotti dei classici grafici a
      dispersione, ma se si usa l'opzione <opt>with-lines</opt> vengono
      mostrate anche le linee di collegamento tra i punti del grafico.
    </para>
    <para context="cli">
      Per una spiegazione dell'opzione <opt>output</opt>, si veda il
      comando <cmdref targ="gnuplot"/> command.
    </para>
    <para context="cli">
      Se la fonte dei dati è una matrice predefinita, la
      <repl>x</repl> e la <repl>y</repl> devono essere specificate coi
      corrispondenti numeri di colonna. Se non vengono fornite liste,
      tutte le colonne vengono mostrate avendo in ascissa il tempo o
      una variabile indice.
    </para>
    <para context="gui">
      Produce grafici a dispersione della <quote>Variabile asse
	Y</quote> selezionata rispetto ad ognuna delle <quote>Variabili
	asse X</quote> selezionate (ma è possibile fare anche
      viceversa). Questi gruppi di grafici sono utili nell'analisi
      esplorativa dei dati. È possibile creare fino a 16 grafici alla
      volta, eventuali variabili in sovrappiù saranno ignorate.
    </para>
    <para context="gui">
      Per default i data sono mostrati come punti, ma si può usare il bottone
      <quote>Usa linee</quote>.
    </para>
      <para>
	Si veda anche <cmdref targ="tsplots"/> per semplici grafici
	multipli di serie storiche e <cmdref targ="gridplot"/> per un
	modo più flessibile di comporre grafici su una griglia.
      </para>
  </description>

  <gui-access>
    <menu-path>/Visualizza/Grafici multipli</menu-path>
  </gui-access>

</command>

<command name="script-editor" section="Utilities" context="gui"
	 label="Preferenze per l'editor">

  <description>
    <para>
      Nota: alcune di questi settaggi si applicano solo quando
      quelli che vengono editati sono script nativi di gretl (Smart
      Tab and Enter, Script editor uses tabs); altri si applicano
      qualsiasi sia il tipo di script da editare (Show line numbers,
      Highlighting style).
    </para>
    <para>
      <emphasis>Tab e Invio intelligenti</emphasis>: Se questo
      settaggio è abilitato, premere il tasto <lit>Tab</lit>
      all'inizio della linea in uno script hansl farà sì che il
      programma, anziché inserire una tabulazione, cercherà di
      aggiustare il livello di indentazione rispetto alle alter
      linee dello script. Nello stesso modo, premendo
      <lit>Invio</lit> il programma cercherà di far si che
      l'indentazione della linea sia corretta.
    </para>
    <para>
      <emphasis>Mostra i numeri di linea</emphasis>: Mostra i numeri di
      linea nel margine sinistro della finestra.
    </para>
    <para>
      <emphasis>Usa i tab nell'editor</emphasis>: Fa sì che, quando siano
      aperti più script contemporaneamente, ognuno di essi sia mostrato in
      un <quote>tab</quote>; altrimenti, ci sarà una finestra per ogni script.
    </para>
    <para>
      <emphasis>Auto-completamento</emphasis>: Se questa opzione è
      disponibile, verranno offerti possibile completamenti per la parola
      cche si sta digitando, in automatico o premendo il tasto
      tabulazione. Per selezionare un completamento, si possono usare le
      frecce su/giù e il tasto <lit>Invio</lit>; continuando a digitare i
      suggerimenti vengono cancellati.
    </para>
    <para>
      <emphasis>Attiva le parentesi automatiche</emphasis>: Fa sì che,
      digitando una parentesi sinistra tonda, quadra o graffa alla fine
      della linea venga inserita in automatico la parentesi destra
      corrispondente. Il cursore verrà posizionato fre le due.
    </para>
    <para>
      <emphasis>Numero di spazi per tab</emphasis>: A quanti spazi
      corrisponde la tabulazione? Un intero da 2 a 8.
    </para>
    <para>
      <emphasis>Stile grafico</emphasis>: In questa tendina sono elencati
      varie combinazioni di colori; alcuni sono a fondo chiaro e altri a
      fondo scuro.
    </para>
  </description>

</command>

<command name="sdiff" section="Transformations" label="Differenziazione stagionale" context="cli">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
  </usage>

  <description>
    <para>
      Calcola la differenza stagionale di ogni variabile della
      <repl>lista-variabili</repl> e salva il risultato in una nuova
      variabile con il prefisso <lit>sd_</lit>. Il comando è
      disponibile solo per serie storiche stagionali.
    </para>
  </description>

  <gui-access>
    <menu-path>/Aggiungi/Differenze stagionali</menu-path>
  </gui-access>

</command>

<command name="set" section="Programming"
	 label="Imposta parametri del programma" context="cli">

  <usage>
    <altforms>
      <altform><lit>set</lit> <repl>variabile</repl> <repl>valore</repl></altform>
      <altform><lit>set --to-file=</lit><repl>filename</repl></altform>
      <altform><lit>set --from-file=</lit><repl>filename</repl></altform>
      <altform><lit>set stopwatch</lit></altform>
      <altform><lit>set</lit></altform>
    </altforms>
    <examples>
      <example>set svd on</example>
      <example>set csv_delim tab</example>
      <example>set horizon 10</example>
      <example>set --to-file=mysettings.inp</example>
    </examples>
  </usage>

  <description>
    <para>
      L'uso più comune di questo comando è quello mostrato nella
      prima variante qui sopra, dove viene fissato il valore di un
      certo parametro. Più avanti, questo aspetto sarà analizzato in
      dettaglio. Gli altri usi sono: con <opt>from-file</opt> per
      leggere un file di script contenente certe impostazioni e
      applicarle alla sessione corrente; con <opt>stopwatch</opt>,
      per azzerare il <quote>cronometro</quote> della CPU di gretl
      (si veda lo help per l'accessore <fncref targ="$stopwatch"/>).
      Se il comando <cmd>set</cmd> è usato senza parametri, vengono
      mostrate le impostazioni attuali per tutti i parametri
      rilevanti.
    </para>
    <para>
      Il valore impostato rimane in vigore per la durata della
      sessione di gretl, a meno di non essere modificato da un
      ulteriore esecuzione del comando <cmd>set</cmd>. I parametri
      che possono essere impostati in questo modo sono elencati di
      seguito.  Si noti che le impostazioni di <lit>hac_lag</lit>,
      <lit>hc_version</lit> e <lit>hac_kernel</lit> sono usate
      quando viene data l'opzione <opt>robust</opt> a un comando di
      stima.
    </para>
    <para>
      Le impostazioni disponibili sono raggruppate in categorie:
      interazione col programma, metodi numerici, generazione di
      numeri casuali, stima robusta, filtri, stima di modelli per
      serie storiche e interazione con R.
    </para>

    <para>
      <emphasis>Interazione con il programma</emphasis>
    </para>
    <para>
      Queste impostazioni servono per controllare vari aspetti del modo in cui
      gretl interagisce con l'utente.
    </para>
    <ilist>
      <li>
	<para><lit>workdir</lit>: <repl>path</repl>.  Stabilisce la
	  directory di default per la lettura/scrittura dei file, ogni
	  qual volta non si specifichino percorsi completi.
	</para>
      </li>
      <li>
	<para><lit>use_cwd</lit>: <lit>on</lit> oppure
	  <lit>off</lit> (il default). Regola l'inizializzazione
	  automatica di <lit>workdir</lit>: se <lit>on</lit>, essa
	  viene ereditata dalla shell, altrimenti viene fissata al
	  valore che aveva nella sessione gretl precedente.
	</para>
      </li>
      <li>
	<para><lit>echo</lit>: <lit>off</lit> o <lit>on</lit>
	  (valore predefinito).  Sopprime o ripristina l'indicazione
	  dei comandi eseguiti nell'output dei risultati.</para>
      </li>
      <li>
	<para><lit>messages</lit>: <lit>off</lit> o <lit>on</lit> (valore
	  predefinito). Sopprime o ripristina l'indicazione dei messaggi
	  informativi associati a vari comandi, ad esempio quando viene
	  generata una nuova variabile o viene modificato l'intervallo del
	  campione.
	</para>
      </li>
      <li>
	<para><lit>verbose</lit>: <lit>off</lit> oppure
	  <lit>on</lit> (valore predefinito). Funziona come
	  <quote>interruttore doppio</quote> per <lit>echo</lit> e
	  <lit>messages</lit> (vedi sopra), ponendoli ambedue accesi o
	  spenti.
	</para>
      </li>
      <li>
	<para><lit>warnings</lit>: <lit>off</lit> oppure <lit>on</lit>
	  (valore predefinito). Sopprime o ripristina i messaggi cautelativi
	  relativi a problemi numerici, come ad esempio quando quando certe
	  operazioni aritmetiche producono valori non finiti o la
	  convergenza di un ottimizatore è dubbia.
	</para>
      </li>
      <li>
	<para><lit>csv_delim</lit>: <lit>comma</lit> (virgola,
	  valore predefinito), <lit>space</lit> (spazio), o
	  <lit>tab</lit>. Imposta il delimitatore di colonna usato nel
	  salvataggio di dati su file in formato CSV.
	</para>
      </li>
      <li>
	<para><lit>csv_write_na</lit>: la stringa usata per
	  rappresentare i valori mancanti quando si esportano dati in
	  formato CSV. Massimo 7 caratteri; il default è
	  <lit>NA</lit>.
	</para>
      </li>
      <li>
	<para><lit>csv_read_na</lit>: la stringa usata per
	  rappresentare i valori mancanti quando si esportano dati in
	  formato CSV. Massimo 7 caratteri; il default dipende se una
	  colonna di dati contiene dati numerici (o per lo più tali) o
	  stringa. Per dati numerici, i valori seguenti sono tutti
	  sinomimi di <quote>dato mancant</quote>: una cella vuota, or
	  una qualunque delle stringhe <lit>NA</lit>, <lit>N.A.</lit>,
	  <lit>na</lit>, <lit>n.a.</lit>, <lit>N/A</lit>,
	  <lit>#N/A</lit>, <lit>NaN</lit>, <lit>.NaN</lit>,
	  <lit>.</lit>, <lit>..</lit>, <lit>-999</lit>, and
	  <lit>-9999</lit>.  Per valori stringa, si conta come
	  mancante una cella vuota o una contenente una stringa
	  vuota. Questi valori di default possono essere reimpostati
	  dando <lit>default</lit> come valore per
	  <lit>csv_read_na</lit>. Per specificare che siano
	  considerate mancanti solo celle vuote, va dato un valore di
	  <lit>""</lit>. Si noti comunque che celle vuote vengono
	  lette come valori mancanti indipendentemente da questo
	  settaggio.
	</para>
      </li>
      <li>
	<para><lit>csv_digits</lit>: un intero positivo contenente
	  il numero di cifre significative da usare quando si salva in
	  formato CSV. Di default, si usano fino a 15 cifre (a seconda
	  della precisione dei dati originali). Si noti che l'output
	  in CSV usa la funzione <lit>fprintf</lit> della libreria C
	  con la conversione <quote><lit>%g</lit></quote>, il che
	  implica che gli zeri in fondi non vengono stampati.
	</para>
      </li>
      <li>
	<para><lit>display_digits</lit>: un intero da 3 a 6,
	specificante il numero di cifre significative da usare
	nell'output di coefficienti di regressione e corrispondenti
	errori standard (il default è 6). Questo settaggio è anche
	attivo sul numero di cifre usato dal comando <cmdref
	targ="summary"/>; in questo caso, il default (che è anche il
	massimo) è 5.
	</para>
      </li>
      <li>
	<para><lit>mwrite_g</lit>: <lit>on</lit> or <lit>off</lit>
	  (il default). Quando gretl scrive una matrice come file di testo,
	  di default usa la notazione scientifica con precisione a 18 cifre,
	  ciò che garantisce cche i valori salvati siano una
	  rappresentazione fedele delle quantità in memoria. Tuttavia, a
	  volte può essere preferibile usare una notazione più compatta, con
	  6 cifre di precisione massima e il formato <lit>%g</lit>, per
	  rendere il file più leggibile ad occhi umani; questo effetto si
	  ottiene con <lit>set mwrite_g on</lit>.
	</para>
      </li>
      <li>
	<para><lit>force_decpoint</lit>: <lit>on</lit> o <lit>off</lit>
	  (valore predefinito).  Forza gretl a usare il carattere punto come
	  separatore decimale, in un ambiente in cui il separatore standard è
	  un altro carattere (tipicamente la virgola).
	</para>
      </li>
      <li>
	<para><lit>loop_maxiter</lit>: un valore intero non negativo
	  (default = 100000).  Imposta il numero massimo di iterazioni
	  consentite prima che un loop di tipo <lit>while</lit> si fermi (si
	  veda <cmdref targ="loop"/>).  Si noti che questa impostazione
	  riguarda solo la variante <lit>while</lit>, visto che lo scopo è
	  quello di interrompere possibili cicli infiniti. Il valore
	  speciale 0 viene usato per rendere tali cicli potenzialmente
	  infiniti, visto che non viene fatto alcun controllo sul numero di
	  iterazioni. Usare con cautela.
	</para>
      </li>
      <li>
	<para><lit>max_verbose</lit>: <lit>on</lit>, <lit>off</lit>
	  (valore predefinito) oppure <lit>full</lit>. Controlla la
	  verbosità di comandi e funzioni che usano metodi di ottimizzazione
	  numerica.  La scelta <lit>on</lit> si applica a funzioni (come ad
	  es. <fncref targ="BFGSmax"/> e <fncref targ="NRmax"/>) che, per
	  default, operano senza output; l'effetto è quello di stampare
	  informazioni di base sulle iterazioni. Il settaggio
	  <lit>full</lit> può essere usato per avere un output più
	  dettagliato, che comprende i valori dei parametri ed il gradiente
	  della funzione obiettivo ad ogni iterazione. Questa scelta si
	  applica sia a funzioni del tipo menzionato sopra sia a comandi che
	  usano l'ottimizzazione numerica, come <cmdref targ="arima"/>,
	  <cmdref targ="probit"/> o <cmdref targ="mle"/>. Nel caso dei
	  comandi l'effetto è di rendere l'opzione <opt>verbose</opt> più
	  dettagliata. Si veda anche <guideref targ="chap:numerical"/>.
	</para>
      </li>
      <li>
	<para><lit>debug</lit>: <lit>1</lit>, <lit>2</lit> o <lit>0</lit>
	  (valore predefinito). Da usare per le funzioni definite dall'utente.
	  Impostare <lit>debug</lit> a 1 equivale a impostare
	  <lit>messages</lit> in tutte queste funzioni; impostando la
	  variabile a <lit>2</lit> ha l'effetto aggiuntivo di impostare
	  <lit>max_verbose</lit> in tutte le funzioni.
	</para>
      </li>
      <li>
	<para><lit>shell_ok</lit>: <lit>on</lit> o <lit>off</lit>
	  (valore predefinito). Abilita l'esecuzione di programmi esterni da
	  gretl attraverso la shell di sistema. Per motivi di sicurezza, la
	  funzione è disabilitata per impostazione predefinita; inoltre è
	  possibile abilitarla solo tramite l'interfaccia grafica
	  (Strumenti/Preferenze/Generali). Una volta abilitata, l'impostazione
	  rimarrà attiva per le successive sessioni, fino a che non sarà
	  disabilitata esplicitamente.
	</para>
      </li>
      <li>
	<para><lit>bfgs_verbskip</lit>: un intero. Questo parametro regola
	  l'effetto dell'opzione <opt>verbose</opt> per quei comandi che
	  usano BFGS come algoritmo di ottimizzazione, e serve a rendere
	  l'output più compatto. Se <lit>bfgs_verbskip</lit> è, ad esempio,
	  3, allora l'opzione <opt>verbose</opt> farà si che vengano
	  stampate solo le iterazioni 3, 6, 9 e così via.
	</para>
      </li>
      <li>
	<para><lit>skip_missing</lit>: <lit>on</lit> (il default) oppure
	  <lit>off</lit>. Controlla ciò che gretl fa quando si costruisce
	  una matrice da una o più serie: il default è di saltare le righe
	  che contengono almeno un valore mancante, ma impostando questo
	  parametro a <lit>off</lit> i valori mancanti vengono convertiti in
	  NaNs.
	</para>
      </li>
      <li>
	<para><lit>matrix_mask</lit>: il nome di una serie, o la parola
	  <lit>null</lit>. Questo parametro permette di costruire matrici da
	  serie con maggiore flessibilità rispetto a
	  <lit>skip_missing</lit>: le righe che andranno nella matrice sono
	  quelle per cui la serie specificata presenta valori validi
	  non-zero. Questo settaggio resta in vigore finché non viene
	  specificata una serie diversa, o rimosso usando la parola
	  <lit>null</lit>.
	</para>
      </li>
	<li>
	  <para><lit>quantile_type</lit>: deve essere uno tra
	  <lit>Q6</lit> (il default), <lit>Q7</lit> o
	  <lit>Q8</lit>. Seleziona il metodo specifico utilizzato
	  dalla funzione <fncref targ="quantile"/>. Per i dettagli,
	  vedere <cite key="hyndman96">Hyndman e Fan (1996)</cite> o
	  la voce di Wikipedia all'indirizzo
	  <url>https://en.wikipedia.org/wiki/Quantile</url>.
	  </para>
	</li>
      <li>
	<para><lit>huge</lit>: un numero grande positivo (di default,
	  1.0E100). Questo settaggio controlla il valore ritornato
	  dall'accessore <fncref targ="$huge"/>.
	</para>
      </li>
      <li>
	<para><lit>assert</lit>: <lit>off</lit> (default),
	  <lit>warn</lit> oppure <lit>stop</lit>. Controlla cosa
	  succede se la funzione <fncref targ="assert"/> fallisce,
	  ossia ritorna 0.
	</para>
      </li>
      <li>
	<para><lit>datacols</lit>: un intero da 1 a 15, con valore
	  di default 5. Fissa il massimo numero di serie mostrate
	  fianco a fianco quando i dati sono mostrati per osservazione.
	</para>
      </li>
      <li>
	<para><lit>plot_collection</lit>: <lit>on</lit>,
	  <lit>auto</lit> o <lit>off</lit>. Questo parametro determina
	  il modo in cui i grafici sono mostrati durante l'uso
	  interattivo. Quando è <lit>on</lit>, grafici della stessa
	  dimensione (in termini di pixel) sono raggruppati in una
	  <quote>collezione</quote>, ossia una finestra unica nella
	  quale si può scorrere avanti e indietro per visualizzare i
	  diversi grafici. Quando è <lit>off</lit>, invece, verrà
	  generata una finestra per grafico, come nelle versioni
	  precedenti di gretl. Infine, il valore <lit>auto</lit> fa sì
	  che la collezione venga abilitata solo per grafici che sono
	  generati con un intervallo inferiore agli 1.25 secondi l'uno
	  dall'altro (ad esempio, quando il comando di generazione
	  grafico fa parte di un loop).
	</para>
      </li>
    </ilist>

    <para>
      <emphasis>Metodi numerici</emphasis>
    </para>
    <para>
      Queste impostazioni vengono usate per controllare gli algoritmi numerici
      usati da gretl per la stima.
    </para>
    <ilist>
      <li>
	<para><lit>optimizer</lit>: <lit>auto</lit> (il default),
	  <lit>BFGS</lit> oppure <lit>newton</lit>. Seleziona il metodo di
	  ottimizzazione usato in vari stimatori ML, quando sono applicabili
	  sia BFGS che Newton&ndash;Raphson. Il settaggio di default è di
	  usare Newton&ndash;Raphson quando sia disponibile l'hessiana
	  analitica, e se no BFGS.
	</para>
      </li>
      <li>
	<para><lit>bhhh_maxiter</lit>: un intero. Imposta il massimo numero di
	  iterazioni per la routine BHHH, che è usata dal comando
	  <cmd>arma</cmd>. Se non viene raggiunta la convergenza dopo
	  <lit>bhhh_maxiter</lit>, il programma segnala un errore. Il valore
	  predefinito è 500.
	</para>
      </li>
      <li>
	<para><lit>bhhh_toler</lit>: un valore a virgola mobile, oppure la
	  stringa <lit>default</lit>. Viene usato dalla routine BHHH di gretl
	  per controllare se viene raggiunta la convergenza. L'algoritmo di
	  calcolo ferma le iterazioni non appena l'incremento nella
	  log-verosimiglianza tra le iterazioni è minore di <lit>bhhh_toler</lit>.
	  Il valore predefinito è 1.0E&minus;06; questo valore può essere reimpostato
	  usando la stringa <lit>default</lit> invece di un valore numerico.
	</para>
      </li>
      <li>
	<para><lit>bfgs_maxiter</lit>: un valore intero. Rappresenta il
	  massimo numero di iterazioni per la routine BFGS di gretl,
	  usata da <cmd>mle</cmd>, <cmd>gmm</cmd> e altri stimatori.
	  Se non si raggiunge la convergenza nel numero specificato di
	  iterazioni, il programma produce un messaggio di errore. Il valore
	  predefinito dipende dal contesto, ma tipicamente è nell'ordine delle
	  500 iterazioni.
	</para>
      </li>
      <li>
	<para><lit>bfgs_toler</lit>: un valore in virgola mobile, o
	  la stringa <lit>default</lit>. Viene usato nella routine
	  BFGS di gretl per controllare se si è raggiunta la
	  convergenza. L'algoritmo si ferma appena l'incremento
	  relativo nella funzione obiettivo tra un'iterazione e
	  l'altra è minore di <lit>bfgs_toler</lit>.  Il valore
	  predefinito è pari alla precisione della macchina elevata
	  alla potenza 3/4; questo valore può essere re-impostato
	  usando la stringa <lit>default</lit> invece di un valore
	  numerico.
	</para>
      </li>
      <li>
	<para><lit>bfgs_maxgrad</lit>: un valore in virgola mobile. Esso
	  viene usato nella routine BFGS di gretl per controllare se la norma
	  del gradiente è ragionevolmente prossima a zero quando il criterio
	  <lit>bfgs_toler</lit> è soddisfatto.  Se la norma eccede 1, viene
	  stampato un messaggio cautelativo; se la norma eccede
	  <lit>bfgs_maxgrad</lit>, questo viene considerato un vero e proprio
	  errore. Al momento il default è 5.0 (che è piuttosto permissivo).
	</para>
      </li>
      <li>
	<para><lit>bfgs_richardson</lit>: <lit>on</lit> or <lit>off</lit>
	  (il default). Usa l'estrapolazione di Richardsonper calcolare le
	  derivate numeriche nel contesto dell'ottimizzazione con BFGS.
	</para>
      </li>
      <li>
	<para><lit>initvals</lit>: una matrice
	  pre-specificata. Permette di inizializzare il vettore dei
	  parametri per certi comandi che usano algoritmi di
	  ottimizzazione numerica (<lit>arma</lit>, <lit>garch</lit>,
	  <lit>logit</lit> e <lit>probit</lit>, <lit>tobit</lit> e
	  <lit>intreg</lit>, <lit>biprobit</lit>,
	  <lit>duration</lit>), nonché quando vengono imposte certe
	  restrizioni associate ai VECM. A differenza di altri
	  settaggi, <lit>initvals</lit> non è persistente: dopo,
	  l'uso, viene automaticamente resettato.  Per i dettagli
	  legati alla stima di modelli ARMA, si veda <guideref
						       targ="chap:timeseries"/>.
	</para>
      </li>
      <li>
	<para><lit>lbfgs</lit>: <lit>on</lit> o <lit>off</lit> (valore
	  predefinito). Usa la versione a memoria limitata di BFGS, al posto
	  dell'algoritmo standard. Può essere vantaggioso quando la funzione da
	  massimizzare non è globalmente concava.
	</para>
      </li>
      <li>
	<para><lit>lbfgs_mem</lit>: un intero da 3 a 20 (il default
	  è 8). Determina il numero di correzioni usate nella matrice
	  di memoria limitata quando si usa il metodo L-BFGS-B.
	</para>
      </li>
      <li>
	<para>
	  <lit>nls_toler</lit>: un valore in virgola mobile (il valore
	  predefinito è pari alla precisione della macchina elevata alla potenza
	  3/4). Imposta la tolleranza usata per stabilire se è stata raggiunta
	  la convergenza nelle procedure iterative di stima con i minimi
	  quadrati non lineari usate dal comando <cmdref targ="nls"/>.
	</para>
      </li>
      <li>
	<para><lit>svd</lit>: <lit>on</lit> o <lit>off</lit> (valore
	  predefinito).  Usa la decomposizione SVD invece di quella di
	  Cholesky o della QR nel calcolo delle stime OLS. Questa
	  opzione si applica alla funzione <lit>mols</lit> e a vari
	  altri calcoli eseguiti internamente, ma non al comando
	  <cmdref targ="ols"/>.
	</para>
      </li>
      <li>
	<para>
	  <lit>force_qr</lit>: <lit>on</lit> oppure <lit>off</lit> (il
	  default). Si riferisce al comando <cmdref targ="ols"/>. Per
	  default, questo comando calcola le stime usando la scomposizione
	  di Cholesky, che è il metodo più rapido, passando alla
	  scomposizione QR solo nel caso di dati mal condizionati. Settando
	  <lit>force_qr</lit> a <lit>on</lit> il tentativo con Cholesky
	  viene saltato; in casi <quote>dubbi</quote> questo potrebbe
	  portare ad una maggiore accuratezza.
	</para>
      </li>
      <li>
	<para><lit>fcp</lit>: <lit>on</lit> o <lit>off</lit> (valore
	  predefinito). Usa l'algoritmo di Fiorentini, Calzolari e Panattoni
	  al posto del codice interno di gretl per  calcolare le stime GARCH.
	</para>
      </li>
      <li>
	<para><lit>gmm_maxiter</lit>: un intero, il numero massimo
	  di iterazioni per il comando <cmdref targ="gmm"/> con
	  l'opzione <opt>iterate</opt>. Il default è 250.
	</para>
      </li>
      <li>
	<para><lit>nadarwat_trim</lit>: un intero, il parametro di
	  taglio usato dalla funzione <fncref targ="nadarwat"/>.
	</para>
      </li>
      <li>
	<para><lit>fdjac_quality</lit>: un intero fra 0 e 2,
	corrsipondente all'algoritmo usato nella funzione <fncref
	targ="fdjac"/>.
	</para>
      </li>
 	<li>
	  <para><lit>gmp_bits</lit>: una potenza intera di 2 (valore
	  predefinito e minimo 256, massimo 8192). Controlla il numero
	  di bit utilizzati per rappresentare un numero in virgola
	  mobile quando viene chiamata GMP (GNU Multiple Precision
	  Arithmetic Library), principalmente tramite il comando
	  <lit>mpols</lit>. Valori più grandi forniscono una maggiore
	  precisione a costo di un tempo di elaborazione più
	  lungo. Questa impostazione può anche essere controllata
	  dalla variabile di ambiente <lit>GRETL_MP_BITS</lit>.
	  </para> </li>
   </ilist>

    <para>
      <emphasis>Generazione di numeri casuali</emphasis>
    </para>

    <ilist>
      <li>
	<para><lit>seed</lit>: un intero senza segno. Imposta il seme per il
	  generatore di numeri pseudo-casuali. Di solito il seme viene
	  impostato a partire dall'ora di sistema, ma se si intende
	  generare sequenze ripetibili di numeri casuali occorre impostare
	  il seme manualmente.
	</para>
      </li>
    </ilist>

    <para>
      <emphasis>Stima robusta</emphasis>
    </para>

    <ilist>
      <li>
	<para><lit>bootrep</lit>: un intero. Imposta il numero di replicazioni
	  per il comando <cmdref targ="restrict"/> con l'opzione <opt>bootstrap</opt>.
	</para>
      </li>
      <li>
	<para><lit>garch_vcv</lit>: <lit>unset</lit>, <lit>hessian</lit>,
	  <lit>im</lit> (matrice di informazione) , <lit>op</lit>
	  (matrice dei prodotti esterni), <lit>qml</lit> (stimatore QML),
	  <lit>bw</lit> (Bollerslev&ndash;Wooldridge). Specifica la
	  variante da usare per stimare la matrice di covarianza dei
	  coefficienti nei modelli GARCH.  Se si usa <lit>unset</lit>
	  (valore predefinito), viene usata l'Hessiana, a meno di
	  usare l'opzione <quote>robust</quote> col comando garch, nel
	  qual caso viene usato QML.
	</para>
      </li>
      <li>
	<para><lit>arma_vcv</lit>: <lit>hessian</lit> (predefinito) o
	  <lit>op</lit> (prodotto esterno). Specifica la variante
	  da usare per calcolare la matrice di covarianza per i modelli ARIMA.
	</para>
      </li>
      <li>
	<para><lit>force_hc</lit>: <lit>off</lit> (predefinito) o
	  <lit>on</lit>. Lo stimatore HAC viene usato in modo
	  predefinito con dati serie storiche e quando si usa
	  l'opzione <opt>robust</opt> di <lit>ols</lit>. Impostando
	  invece <lit>force_hc</lit> a <quote>on</quote>, si forza
	  l'uso della matrice di covarianza coerente con
	  l'eteroschedasticità (che non tiene conto
	  dell'autocorrelazione). Si noti che i VAR costituiscono un
	  caso particolare: con l'opzione <opt>robust</opt> il metodo
	  di default è lo HCCM, ma si può forzare l'uso di uno
	  stimatore HAC con l'opzione <opt>robust-hac</opt>.
	</para>
      </li>
      <li>
	<para><lit>robust_z</lit>: <lit>off</lit> (il default) oppure
	  <lit>on</lit>. Questo settaggio controlla la distribuzione usata per
	  calcolare i p-value basati s errori standard robusti, nel contesto
	  delle stime a minimi quadrati. Per default, gretl usa la
	  distribuzione t di Student <math>t</math>, ma se
	  <lit>robust_z</lit> è <quote>on</quote> viene usata la normale.
	</para>
      </li>
      <li>
	<para><lit>hac_lag</lit>: <lit>nw1</lit> (valore predefinito),
	<lit>nw2</lit>, <lit>nw3</lit>, o un intero.  Imposta il
	massimo valore di ritardo, o la larghezza di banda,
	<math>p</math>, usato nel calcolo degli errori standard HAC
	(Heteroskedasticity and Autocorrelation Consistent) con
	l'approccio Newey-West, per le serie storiche.  <lit>nw1</lit>
	e <lit>nw2</lit> rappresentano due varianti di calcolo
	automatico basate sulla dimensione del campione,
	<math>T</math>: per nw1,
	<equation status="inline"
		  tex="$p = 0.75 \times T^{1/3}$"
		  ascii="p = 0.75 * T^(1/3)"
		  graphic="nw1"/>, e per nw2,
	<equation status="inline"
		  tex="$p = 4 \times (T/100)^{2/9}$"
		  ascii="p = 4 * (T/100)^(2/9)"
		  graphic="nw2"/>.  <lit>nw3</lit> permette di selezionare la
	larghezza di banda basandosi sui dati.  Si veda anche
	<lit>qs_bandwidth</lit> e <lit>hac_prewhiten</lit>.
	</para>
      </li>
      <li>
	<para><lit>hac_kernel</lit>: <lit>bartlett</lit> (valore predefinito),
	  <lit>parzen</lit>, o <lit>qs</lit> (Quadratic Spectral). Imposta il
	  kernel, o struttura di pesi, usato nel calcolo degli errori standard
	  HAC.
	</para>
      </li>
      <li>
	<para><lit>hac_prewhiten</lit>: <lit>on</lit> o <lit>off</lit>
	  (valore predefinito). Usa le procedure di <quote>prewhitening</quote> e
	  <quote>re-coloring</quote> di Andrews-Monahan nel calcolo degli
	  errori standard HAC. Questo comporta anche la selezione della
	  larghezza di banda basata sui dati.
	</para>
      </li>
      <li>
	<para><lit>hac_missvals</lit>: <lit>es</lit> (il default),
	<lit>am</lit> or <lit>off</lit>. Imposta come debbano essere
	calcolati gli errori standard HAC in presenza di osservazioni
	incomplete: <lit>es</lit> imposta il metodo <quote>Equal
	Spacing</quote> di <cite key="datta-du12">Datta e Du
	(2012)</cite>; <lit>am</lit> seleziona il metodo
	<quote>Amplitude Modulation</quote> di <cite
	key="parzen63">Parzen (1963)</cite>; infine, <lit>off</lit> fa
	sì che gretl rifiuti di procedere. Si veda <guideref
	targ="chap:robust_vcv"/> per dettagli.
	</para>
      </li>	
      <li>
	<para>
	  <lit>hc_version</lit>: 0, 1, 2, 3 o 3a. Imposta la variante
	  da usare nel calcolo degli errori standard HAC
	  (Heteroskedasticity and Autocorrelation Consistent) con dati
	  di tipo cross section. Le prime quattro opzioni
	  corrispondono alle HC0, HC1, HC2 e HC3 discusse da Davidson
	  e MacKinnon nel capitolo 5 di
	  <book>Econometric Theory and Methods</book>.  HC0 produce
	  quelli che di solito vengono chiamati <quote>errori standard
	  di White</quote>. La variante 3a è la
	  procedura <quote>jackknife</quote> di
	  MacKinnon&ndash;White. Il valore di default è di norma 1, ma
	  può essere modificato nell'interfaccia grafica (GUI),
	  sotto <quote>Strumenti/Preferenze/Generale</quote>. Si noti
	  che il settaggio effettuato tramite la GUI persiste una
	  volta chiuso il programma, a differenza di quel che succede
	  col comando <lit>set</lit>.
	</para>
      </li>
      <li>
	<para><lit>pcse</lit>: <lit>off</lit> (impostazione predefinita) o
	  <lit>on</lit>.  Di solito, quando si stima un modello con pooled OLS
	  su dati panel usando l'opzione <opt>robust</opt>, viene usato lo
	  stimatore di Arellano per la matrice di covarianza. Se si imposta
	  <lit>pcse</lit> a <quote>on</quote>, verranno usati i Panel
	  Corrected Standard Errors (PCSE) di Beck e Katz, che non tengono
	  conto dell'autocorrelazione.
	</para>
      </li>
      <li>
	<para><lit>qs_bandwidth</lit>: larghezza di banda per la stima HAC
	  nel caso in cui si scelga il kernel "Quadratic Spectral" (a differenza
	  dei kernel Bartlett e Parzen, la larghezza di banda QS non deve essere
	  necessariamente un intero).
	</para>
      </li>
    </ilist>


    <para>
      <emphasis>Serie storiche</emphasis>
    </para>

    <ilist>
      <li>
	<para><lit>horizon</lit>: un intero (il valore predefinito
	  dipende dalla frequenza dei dati). Imposta l'orizzonte per
	  le funzioni impulso-risposta e per la decomposizione della
	  varianza nel contesto delle autoregressioni vettoriali.
	</para>
      </li>
      <li>
	<para><lit>vecm_norm</lit>: <lit>phillips</lit> (valore
	  predefinito), <lit>diag</lit>, <lit>first</lit> o
	  <lit>none</lit>. Usato nel contesto della stima VECM,
	  attraverso il comando <cmdref targ="vecm"/> per identificare
	  i vettori di cointegrazione. Si veda la Guida all'uso per i
	  dettagli.
	</para>
      </li>
	<li>
	  <para>
	    <lit>boot_iters</lit>: un intero, <math>B</math>. Imposta
	    il numero di iterazioni bootstrap utilizzate quando si
	    calcolano le IRF con intervalli di confidenza. Il valore
	    predefinito è 1999. Si consiglia che <math>B</math> + 1
	    sia divisibile per 100&alpha;/2, quindi ad esempio con
	    &alpha; = 0,1 <math>B</math> + 1 dovrebbe essere un
	    multiplo di 5. Il valore minimo accettabile è 499.
	    </para>
	</li>
    </ilist>

    <para>
      <emphasis>Interazione con R</emphasis>
    </para>

    <ilist>
      <li>
	<para><lit>R_lib</lit>: <lit>on</lit> (il default) or
	  <lit>off</lit>.  Quando vengono inviate istruzioni a R, il
	  settaggio <lit>on</lit> fa sì che di preferenza venga usata la
	  libreria di R, se disponibile, anziché l'eseguibile R.
	</para>
      </li>
      <li>
	<para><lit>R_functions</lit>: <lit>off</lit> (il default) oppure
	  <lit>on</lit>. Riconosce funzioni di Rcome se fossero funzioni
	  gretl (premettendo il prefisso <quote><lit>R.</lit></quote>). Si
	  veda <guideref targ="chap:gretlR"/> per dettagli su questo punto e
	  sul precedente.
	</para>
      </li>
    </ilist>
    
    <subhead>Varie</subhead>

    <ilist>
      <li>
	<para><lit>mpi_use_smt</lit>: <lit>on</lit> oppure
	  <lit>off</lit> (default). Questo settaggio influisce sul
	  numero di processi eseguiti in un blocco <lit>mpi</lit>
	  presente in uno script. Se è <lit>off</lit>, il numero di
	  processi di default è uguale al numero di <i>core</i> fisici
	  sulla macchina locale; se invece è <lit>on</lit>, il default
	  sarà dato dal numero massimo di thread, ossia il doppio dei
	  <i>core</i> fisici se essi supportano lo standard SMT
	  (Simultaneous MultiThreading, anche noto come
	  Hyper-Threading). Il settaggio si applica solo al caso in
	  cui l'utente non ha specificato il numero di processi, n
	  modo diretto o indiretto, attraverso il file
	  <lit>hosts</lit>.
	</para>
      </li>
      <li>
	<para>
	  <lit>graph_theme</lit>: una stringa fra
	  <lit>altpoints</lit>, <lit>classic</lit>, <lit>dark2</lit>
	  (il default attuale), <lit>ethan</lit>,
	  <lit>iwanthue</lit> o <lit>sober</lit>.  Imposta il
	  <quote>tema</quote> ustao per i grafici prodotti da
	  gretl. Con l'opzione <lit>classic</lit> si avrà il tema
	  usato fino alla versione 2020c.
	</para>
      </li>
    </ilist>


  </description>
</command>

<command name="setinfo" section="Dataset" label="Modifica degli attributi di una variabile">

  <usage>
    <arguments>
      <argument>nome-variabile</argument>
    </arguments>
    <options>
      <option>
	<flag>--description</flag>
	<optparm>stringa</optparm>
	<effect>imposta la descrizione</effect>
      </option>
      <option>
	<flag>--graph-name</flag>
	<optparm>stringa</optparm>
	<effect>imposta il nome per i grafici</effect>
      </option>
      <option>
	<flag>--discrete</flag>
	<effect>marca la variabile come discreta</effect>
      </option>
      <option>
	<flag>--continuous</flag>
	<effect>marca la variabile come continua</effect>
      </option>
      <option>
	<flag>--coded</flag>
	<effect>mark come codifica</effect>
      </option>
      <option>
	<flag>--numeric</flag>
	<effect>marca come numerica</effect>
      </option>
      <option>
	<flag>--midas</flag>
	<effect>mark come componente di dati ad alta frequenza</effect>
      </option>
    </options>
    <examples>
      <example>setinfo x1 --description "Descrizione di x1"</example>
      <example>setinfo y --graph-name="Nome nei grafici"</example>
      <example>setinfo z --discrete</example>
    </examples>
  </usage>

  <description context="cli">
    <para>
      Se sono usate le opzioni <opt>description</opt> o <opt>graph-name</opt>
      l'argomento deve essere una serie singola. Altrimenti, può
      essere una lista, nel qual caso il comando opera su ognuna
      delle variabile. Questo comando imposta fino a quattro
      attributi, come segue.
    </para>
    <para>
      Usando l'opzione <opt>description</opt> seguita da una stringa
      tra virgolette doppie, la stringa verrà usata come etichetta
      descrittiva per la variabile indicata, che viene mostrata dal
      comando <cmdref targ="labels"/> e anche nella finestra
      principale del programma.
    </para>
    <para>
      Usando l'opzione <opt>graph-name</opt> seguita da una stringa
      tra virgolette doppie, la stringa verrà usata nei grafici al
      posto del nome della variabile.
    </para>
    <para>
      Usando una delle opzioni <opt>discrete</opt> o
      <opt>continuous</opt>, viene impostato il carattere numerico
      della variabile.  In modalità predefinita, tutte le variabili
      sono considerate come continue; marcando una variabile come
      discreta, essa viene trattata in modo speciale in certi
      comandi e funzioni, come ad esempio <cmdref targ="freq"/> o
      <fncref targ="dummify"/> .
    </para>
    <para>
      Se viene data una fra le opzioni <opt>coded</opt> o
      <opt>numeric</opt>,lo stato della serie è impostato di
      conseguenza. L'impostazione di default è di trattare tutti i
      valori numerici come tali, per lo meno in un senso ordinale;
      se una variabile viene impostata come <lit>coded</lit>, i
      valori numerici sono considerati una codifica arbitraria di
      qualche caratteristica qualitativa.
    </para>
    <para>
      L'opzione <opt>midas</opt> imposta l'indicazione che una data
      serie contiene dati a frequenza più alta di quella base del
      dataset; per esempio, il dataset è trimestrale e la serie
      contiene valori per il mese 1, 2 o 3 del trimestre. (MIDAS =
      Mixed Data Sampling.)
    </para>
  </description>

  <description context="gui">

    <para>
    In questa finestra di dialogo è possibile:</para>

    <para>* Rinominare una variabile.</para>

    <para>* Aggiungere o modificare una descrizione della variabile,
    che appare accanto al nome della variabile nella finestra
    principale di gretl.</para>

    <para>* Aggiungere o modificare il "nome per i grafici" della
    variabile (se la variabile è una serie e non uno scalare).
    Questa stringa (lunga al massimo 19 caratteri) viene
    usata al posto del nome della variabile quando questa compare in
    un grafico. Così, ad esempio, è possibile associare una stringa
    più comprensibile come "Tariffe telefoniche" a un nome criptico
    come "tartel".</para>

    <para>* Impostare (se i dati sono serie storiche) il
    metodo di compattamento per la variabile, che verrà usato se si
    decide di ridurre la frequenza del dataset, o se si importa la
    variabile da un dataset che ha una frequenza maggiore di quella
    del dataset in uso.
    </para>

    <para>* Marcare una variabile come discreta (per serie che contengono
    solo valori discreti). In questo modo, essa viene
    trattata in modo speciale nei diagrammi di frequenza.
    </para>

  </description>

  <gui-access>
    <menu-path>/Variabile/Modifica attributi</menu-path>
    <other-access>Menù pop-up nella finestra principale</other-access>
  </gui-access>

</command>

<command name="setmiss" section="Dataset"
	 label="Codice dei valori mancanti">

  <usage>
    <arguments>
      <argument>valore</argument>
      <argument optional="true">lista-variabili</argument>
    </arguments>
    <examples>
      <example>setmiss -1</example>
      <example>setmiss 100 x2</example>
    </examples>
  </usage>

  <description>
    <para context="cli">
      Imposta il programma in modo da interpretare un dato valore
      numerico (il primo parametro indicato al comando) come codice
      per i <quote>valori mancanti</quote> nei dati importati. Se
      questo valore è l'unico parametro fornito, come nel primo degli
      esempi precedenti, l'interpretazione verrà applicata a tutte le
      serie del dataset. Se <repl quote="true">valore</repl> è seguito
      da una lista di variabili, indicate per nome o numero,
      l'interpretazione è limitata solo alle variabili specificate.
      Così, nel secondo esempio, il valore 100 è interpretato come
      codice per <quote>mancante</quote>, ma solo per la variabile
      <lit>x2</lit>.
    </para>

    <para context="gui">
      Imposta un valore numerico che verrà interpretato come
      "mancante" o "non applicabile", per una particolare serie (sotto
      il menù Variabile) o globalmente per l'intero dataset (sotto il
      menù Campione).</para>

      <para context="gui">
	Gretl ha un codice interno per i valori mancanti, che non sempre
	può coincidere con quello usato dai dati importati. Ad esempio, se
	una serie usa il valore -1 col significato di "non disponibile", è
	possibile selezionare "Imposta codice valori mancanti" nel menù
	Variabile e immettere il valore "-1" (senza le virgolette); gretl
	interpreterà quindi i valori -1 come osservazioni mancanti.</para>

      </description>

      <gui-access>
	<menu-path>/Campione/Imposta codice valori mancanti</menu-path>
      </gui-access>

    </command>

    <command name="setobs" section="Dataset" context="cli"
	     label="Frequenza e osservazione iniziale">

      <usage>
	<altforms>
          <altform>setobs <repl>periodicità</repl> <repl>oss-iniziale</repl></altform>
	  <altform>setobs <repl>variabile-unità</repl> <repl>variabile-periodi</repl></altform>
	</altforms>
	<options>
          <option>
	    <flag>--cross-section</flag>
	    <effect>interpreta come cross section</effect>
          </option>
          <option>
	    <flag>--time-series</flag>
	    <effect>interpreta come serie storiche</effect>
          </option>
          <option>
	    <flag>--special-time-series</flag>
	    <effect>vedi sotto</effect>
          </option>
          <option>
	    <flag>--stacked-cross-section</flag>
	    <effect>interpreta come panel</effect>
          </option>
          <option>
	    <flag>--stacked-time-series</flag>
	    <effect>interpreta come panel</effect>
          </option>
          <option>
	    <flag>--panel-vars</flag>
	    <effect>usa variabili indice (si veda oltre)</effect>
          </option>
          <option>
	    <flag>--panel-time</flag>
	    <effect>vedi sotto</effect>
          </option>
          <option>
	    <flag>--panel-groups</flag>
	    <effect>vedi sotto</effect>
          </option>
	</options>
	<examples>
          <example>setobs 4 1990:1 --time-series</example>
          <example>setobs 12 1978:03</example>
	  <example>setobs 1 1 --cross-section</example>
          <example>setobs 20 1:1 --stacked-time-series</example>
	  <example>setobs unita anno --panel-vars</example>
	</examples>
      </usage>

      <description>
	<para>
	  Forza il programma a interpretare il dataset in uso secondo la
          struttura specificata.
	</para>
	<para>
          Nella prima forma del comando, la <repl>periodicità</repl>, che deve
          essere un valore intero, nel caso delle serie storiche rappresenta la
          frequenza delle osservazioni (1 = annuale; 4 = trimestrale; 12 =
          mensile; 52 = settimanale; 5, 6, o 7 = giornaliera; 24 = oraria). Nel
          caso di dati panel, la periodicità è il numero di righe per ogni blocco
          di dati, ossia il numero di unità cross section se i dati sono
          organizzati come pila di dati cross section, o il numero di periodi se i
          dati sono organizzati come pila di serie storiche. Nel caso di semplici
          dati cross section, la periodicità dev'essere impostata a 1.
	</para>
	<para>
	  L'osservazione iniziale rappresenta la data iniziale nel caso
          delle serie storiche. Gli anni possono essere indicati con due
          o quattro cifre, mentre i sotto-periodi (ad esempio i trimestri
          o i mesi) devono essere separati dagli anni con un carattere "due punti".
	  Nel caso di dati panel, l'osservazione iniziale va indicata come
	  1:1, mentre nel caso di dati cross section come 1. L'osservazione
          iniziale per i dati giornalieri o settimanali va indicata nella forma
	  AA/MM/GG o AAAA/MM/GG (oppure semplicemente 1 per i dati non datati).
	</para>
	<para>
	  Alcune periodicità temporali hanno interpretazioni
	  convenzionali; ad esempio, 12 = mensile e 4 =
	  trimestrale. Se questa interpretazione non si applica alle
	  vostre serie storiche,si può usare l'opzione
	  <opt>special-time-series</opt>. In tal caso, gretl si
	  asterrà dall'indicare come (ad esempio) mensile una
	  periodicità pari a 12.
	</para>
	<para>
	  Se non viene data alcuna opzione esplicita per indicare la
	  struttura dei dati, il programma tenterà di desumerla dalle
	  informazioni in suo possesso.
	</para>
	<para>
	  La seconda forma del comando (che richiede l'uso
	  dell'opzione <opt>panel-vars</opt>) può essere usata per
	  imporre un'interpretazione panel dei dati, quando il dataset
	  contiene variabili che identificano in modo univoco le unità
	  cross section e i periodi. Il dataset verrà ordinato come
	  pila di serie storiche, per valori crescenti della variabile
	  che rappresenta le unità, <repl>variabile-unità</repl>.
	</para>
	<subhead>Opzioni specifiche per dati panel</subhead>
	<para>
	  Le opzioni <opt>panel-time</opt> e <opt>panel-groups</opt>
	  possono essere usate solo con dataset già impostati come
	  panel.
	</para>
	<para>
	  La scopo di <opt>panel-time</opt> è stabilire
	  informazioni extra sulla dimensione temporale del
	  panel. Essa deve essere indicata sul modello della proma
	  forma di <lit>setobs</lit> (vedi sopra). Ad esempio, il
	  compando seguente indica che la dimensione temporale del
	  panel è trimestrale, e comincia nel primo trimestre 1990.
	</para>
	<code>
	  setobs 4 1990:1 --panel-time
	</code>
	<para>
	  La funzione di <opt>panel-groups</opt> è di creare una serie
	  con valori stringa contentent i nomi delle unità
	  longitudinali nel panel. (Quest'informazione verrà,
	  eventualmente, usata nei grafici.) Con quest'opzione vanno
	  indicati uno o due argomenti, come segue.
	</para>
	<para>
	  Caso uno: l'unico argomento è il nome di una serie a valori
	  stringa. Se il numero di stringhe diverse eguaglia il numero
	  di unità nel panel, allora questi vengono usati come nomi
	  dei gruppi. Se necessario, il contenuto numerico della serie
	  sarà aggiustato per far sì che i valori siano tutti 1 per la
	  prima unità, 2 per la seconda eccetera. Se il numero di
	  valori stringa non corrisponde a quello delle unità, il
	  programma segnala un errore.
	</para>
	<para>
	  Caso due: il primo argomento è il nome di una serie e il
	  secondo è una stringa (o il nome di una variabile stringa)
	  con etichette per ciascuna unità. Se la serie non esiste,
	  verrà creata al momento. Nel secondo argomento, i nomi delle
	  unità vanno separati da spazi; se il nome stesso include
	  degli spazi, allora va racchiuso fra virgolette doppie. Se
	  no, il secondo argomento può essere un array di stringhe.
	</para>
	<para>
	  Ad esempio, il codice seguente creerò una serie di nome
	  <lit>paese</lit> in cui i nomi <lit>npaesi</lit> sono ripetuti
	  ognuno <math>T</math> volte, dove <math>T</math> è l'ampiezza
	  temporale del panel.
	</para>
	<code>
	  string npaesi = sprintf("Francia Germania Italia \"Regno Unito\"")
	  setobs paese npaesi --panel-groups
	</code>
      </description>

      <gui-access>
	<menu-path>Dati/Struttura dataset</menu-path>
      </gui-access>

    </command>

    <command name="setopt" section="Programming" context="cli"
	 label="Indica le opzioni per il comando seguente">

  <usage>
    <arguments>
      <argument>command</argument>
      <argument optional="true">action</argument>
      <argument>options</argument>
    </arguments>
    <examples>
      <example>setopt mle --hessian</example>
      <example>setopt ols persist --quiet</example>
      <example>setopt ols clear</example>
    </examples>
  </usage>

  <description>
    <para>
      Questo comando abilita la preselezione di opzioni per un
      dato comando. Di solito questo non è necessario, ma potrebbe
      essere utile per chi scrive funzioni in hansl, quando certe
      opzioni devono essere rese condizionali a un argomento fornito
      dal livello chiamante.
    </para>
    <para>
      Ad esempio, se una funnzione prevede un argomento booleano
      <quote><lit>quiet</lit></quote>, il cui effetto è sopprimere
      la stampa dei risultati di una regressione eseguita dentro la
      funzione, si può usare <cmd>setopt</cmd> come segue:
    </para>
    <code>
      if quiet
      setopt ols --quiet
      endif
      ols ...
    </code>
    <para>
      L'opzione <opt>quiet</opt> verrà applicata al comando
      <lit>ols</lit> seguente se e solo se la variabile
      <lit>quiet</lit> è non-zero.
    </para>
    <para>
      Di default, le opzioni specificate in questo modo si applicano
      solo alla prima invocazione del comando a cui si riferiscono;
      non sono persistenti. Tuttavia, usando <lit>persist</lit> come
      valore per <repl>action</repl>, le opzioni scelte saranno
      attive fino a nuovo ordine.  L'antidoto a <lit>persist</lit> è
      <lit>clear</lit>, che ha l'effetto di cancellare tutte le
      opzioni stabilite in precedenza.
    </para>
    <para>
      Si noti che le opzioni fissate con <lit>setopt</lit> si
      sommano a qualsiasi altra opzione data al comando
      direttamente. Per esempio, si può dare l'opzione
      <opt>hessian</opt> a un comando <lit>mle</lit>
      incondizionatamente e allo stesso tempo usare
      <lit>setopt</lit> per aggiungere <opt>quiet</opt>
      condizionalmente.
    </para>
  </description>
</command>

<command name="shell" section="Utilities"
	 label="Esegue comandi shell" context="cli">

  <usage>
    <arguments>
      <argument>comando-shell</argument>
    </arguments>
    <examples>
      <example>! ls -al</example>
      <example>! notepad</example>
      <example>launch notepad</example>
      <example>launch emacs myfile.txt</example>
    </examples>
  </usage>

  <description>
      <para>
	Di default, questo comando non è attivo. Vedi sotto per dettagli.
      </para>
      <para>
	Un <cmd>!</cmd> all'inizio di una riga di comando è
	interpretato come passaggio all'interprete di comandi (shell)
	usato dall'utente nel sistema operativo. In questo modo è
	possibile eseguire comandi shell arbitrari dall'interno di
	<program>gretl</program>. L'argomento
	<repl>comando-shell</repl> è passato a <lit>/bin/sh</lit> su
	sistemi di tipo unix come Linux e macOS, oppure a
	<lit>cmd.exe</lit> su Windows.  Il comando esterno viene
	eseguito in modalità sincrona: <program>gretl</program>
	aspetta il termine della sua esecuzione prima di procedere
	oltre. Se il comando produce un output di testo, questo viene
	mostrato nella console o nella finestra di output.
      </para>
      <para>
	In una variante della modalità sincrona, l'utente può salvare
	in una stringa il risultato del comando. Per fare ciò, bisogna
	racchiudere il comando fra parentesi, con un caratter
	<quote>dollaro</quote> all'inizio, come in
      </para>
      <code>
	string s = $(ls -l $HOME)
      </code>
      <para>
	Se invece si vuole avviare un programma esterno da dentro
	<program>gretl</program> in modalità asincrona (senza
	aspettare che abbia completato la sua esecuzione), si può
	usare il comando <cmd>launch</cmd>. Questa modalità è indicata
	per lanciare programmi in modo interattivo. Il programma da
	lanciare sarà cercato nel <lit>PATH</lit> dell'utente. Su
	Windows, il comando viene eseguito direttamente, e non passato
	a <lit>cmd.exe</lit> (e quiindi le variabili di ambiente non
	sono automaticamente espanse).
      </para>
      <subhead>Attivazione</subhead>
      <para>
	Per motivi di sicurezza, di default questa funzionalità è
	disabilitata. Per attivarla, occorre selezionare la casella
	<quote>Abilita comandi shell</quote> sotto
	Strumenti/Preferenze/Generali nel programma GUI. In questo
	modo, si renderanno disponibili i comandi shell anche nella
	modalità a riga di comando di <program>gretl</program> (questo
	è l'unico modo per farlo).
      </para>
    </description>

</command>

<command name="smpl" section="Dataset" label="Imposta l'intervallo del campione" context="cli">

  <!-- don't break the lines below or the text version will get messed
       up -->

  <usage>
    <altforms>
      <altform><lit>smpl</lit> <repl>oss-iniziale oss-finale</repl></altform>
      <altform><lit>smpl</lit> <repl>+i -j</repl></altform>
      <altform><lit>smpl</lit> <repl>variabile-dummy</repl> <lit>--dummy</lit></altform>
      <altform><lit>smpl</lit> <repl>condizione</repl> <lit>--restrict</lit></altform>
      <altform><lit>smpl</lit> <lit>--no-missing [ </lit><repl>lista-variabili</repl> <lit>]</lit></altform>
      <altform><lit>smpl</lit> <lit>--no-all-missing [ </lit><repl>lista-variabili</repl> <lit>]</lit></altform>
      <altform><lit>smpl</lit> <lit>--contiguous [ </lit><repl>lista-variabili</repl> <lit>]</lit></altform>
      <altform><lit>smpl</lit> <repl>n</repl> <lit>--random</lit></altform>
      <altform><lit>smpl full</lit></altform>
      <altform><lit>smpl</lit></altform>
    </altforms>
    <options>
      <option>
	<flag>--dummy</flag>
	<effect>l'argomento è una variabile dummy</effect>
      </option>
      <option>
	<flag>--restrict</flag>
	<effect>applica una restrizione booleana</effect>
      </option>
      <option>
	<flag>--replace</flag>
	<effect>rimpiazza tutte le restrizioni booleane preesistenti</effect>
      </option>
      <option>
	<flag>--no-missing</flag>
	<effect>restringi il campione alle osservazioni valide</effect>
      </option>
      <option>
	<flag>--no-all-missing</flag>
	<effect>ometti le osservazioni vuote (vedi oltre)</effect>
      </option>
      <option>
	<flag>--contiguous</flag>
	<effect>vedi oltre</effect>
      </option>
      <option>
	<flag>--random</flag>
	<effect>forma un sottocampione casuale</effect>
      </option>
      <option>
	<flag>--permanent</flag>
	<effect>vedi oltre</effect>
      </option>
      <option>
	<flag>--preserve-panel</flag>
	<effect>dati panel: vedi sotto</effect>
      </option>
      <option>
	<flag>--unit</flag>
	<effect>dati panel: opera nella dimensione longitudinale</effect>
      </option>
        <option>
	  <flag>--time</flag>
	  <effect>dati panel: opera nella dimensione temporale</effect>
        </option>
        <option>
	  <flag>--dates</flag>
	  <effect>interpreta i numeri delle osservazioni come date</effect>
        </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampare il sottocampione selezionato</effect>
	</option>
    </options>

    <examples>
      <example>smpl 3 10</example>
      <example>smpl 1960:2 1982:4</example>
      <example>smpl +1 -1</example>
      <example>smpl x &gt; 3000 --restrict</example>
      <example>smpl y &gt; 3000 --restrict --replace</example>
      <example>smpl 100 --random</example>
    </examples>
  </usage>

  <description>
    <para>
      Questo comando, usato senza argomenti, mostra l'intervallo
      corrente del campione, altrimenti lo reimposta. Il nuovo
      intervallo può essere definito in vari modi. Nel primo modo
      (corrispondente ai primi due esempi precedenti)
      <repl>oss-iniziale</repl> e <repl>oss-finale</repl> devono
      essere coerenti con la periodicità dei dati. Una delle due può
      essere sostituita da un punto e virgola per lasciare intatto il
      valore attuale. Nel secondo modo, gli interi <repl>i</repl> e
      <repl>j</repl> (che possono essere positivi o negativi e vanno
      indicati con il segno) sono presi come spostamenti relativi ai
      punti iniziale e finale del campione in uso. Nel terzo modo,
      <repl>variabile-dummy</repl> deve essere una variabile
      indicatrice che assume solo valori 0 o 1 e il campione verrà
      ristretto alle osservazioni per cui la variabile dummy vale 1.
      Il quarto modo, che usa <opt>restrict</opt>, limita il campione
      alle osservazioni che soddisfano la condizione booleana
      specificata secondo la sintassi del comando <cmdref
      targ="genr"/>.
    </para>
    <para>
      Le opzioni <lit>no-missing</lit> e <lit>no-all-missing</lit>
      possono essere usate per escludere dal campione dati
      mancanti. La prima variante esclude le osservazioni in cui
      almeno una variabile è mancante, mentre la seconda esclude
      solo le osservazioni per cui <emphasis>tutte</emphasis> le
      variabili hanno valori validi (non mancanti).  In ambedue i
      casi, il test è limitato alle variabili in
      <repl>lista-variabili</repl> se l'opzione ha un argomento; se
      no, viene applicato a tutte le serie nel dataset; a parte che
      nel caso <opt>no-all-missing</opt> senza un'esplicita
      <repl>lista-variabili</repl>, le variaili generiche
      <lit>index</lit> e <lit>time</lit> vengono ignorate.
    </para>
    <para>
      La forma <opt>contiguous</opt> viene usata nei dataset di
      serie storiche.  L'effetto è quello di tagliare il campione
      all'inizio e alla fine finché vengano trovate osservazioni con
      valori mancanti (per la lista specificata, o per tutte le
      serie se <repl>lista-variabili</repl> non è specificata).
      Dopodiché viene effettuato un controllo per vedere se nel
      sottocampione risultante rimangono valori mancanti, nel qual
      caso, viene segnalato un errore.
    </para>
    <para>
      Con la forma <opt>random</opt>, viene estratto casualmente dal
      dataset il numero indicato di osservazioni. Per essere in grado di
      replicare questa selezione, occorre per prima cosa impostare il seme
      del generatore di numeri casuali (si veda il comando
      <cmdref targ="set"/>).
    </para>
    <para>
      La forma finale, <lit>smpl full</lit>, ripristina
      l'intervallo completo del campione.
    </para>
    <para>
	Si noti che i vincoli sul campione sono, per default,
	cumulativi: il valore di riferimento di ogni comando
	<lit>smpl</lit> è il campione attuale, così che ogni vincolo si
	aggiunge a quelli già impostati. Se si vuole che il comando
	funzioni sostituendo i vincoli esistenti, occorre usare
	l'opzione <opt>replace</opt> alla fine del comando. (Questa
	opzione non è compatibile con l'opzione  <opt>contiguous</opt>).
    </para>

    <para>
      La variabile interna <lit>obs</lit> può essere usata con la
      forma <opt>restrict</opt> di <lit>smpl</lit> per escludere
      particolari osservazioni dal campione. Ad esempio,
    </para>
    <code>
      smpl obs!=4 --restrict
    </code>
    <para>
      scarterà la quarta osservazione. Se le osservazioni sono
      identificate da etichette,
    </para>
    <code>
      smpl obs!="USA" --restrict
    </code>
    <para>scarterà l'osservazione a cui è associata l'etichetta
    <quote>USA</quote>.
    </para>

    <para>
      Per le forme <opt>dummy</opt>, <opt>restrict</opt> e
      <opt>no-missing</opt> di <lit>smpl</lit>, occore tenere presente
      che tutte le informazioni <quote>strutturali</quote> contenute
      nel file dei dati (a proposito della struttura di serie storiche
      o di panel dei dati) vengono perse. È possibile reimpostare la
      struttura originale con il comando <cmdref
      targ="setobs"/>. Un'opzione rilevante, per l'uso coi dati panel,
      è l'opzione <opt>preserve-panel</opt>, descritta più sotto.
    </para>

    <subhead>Date contro indici sequenziali</subhead>
    <para>
      L'opzione <opt>dates</opt> può essere utilizzata per risolvere
      una potenziale ambiguità nell'interpretazione di
      <repl>startobs</repl> e <repl>endobs</repl> nel caso di dataset
      annuali.  Ad esempio, <lit>1997</lit> dovrebbe essere inteso
      come riferimento all'anno 1997 o alla
      millenovecentonovantasettesima osservazione? Nella maggior parte
      dei casi gretl risolve la cosa automaticamente, ma si può
      forzare l'interpretazione della data se necessario. Questa
      opzione può essere utilizzata anche con dati giornalieri, per
      forzare <lit>smpl</lit> ad interpretare, ad esempio, 20100301
      come il primo marzo 2010 anziché un semplice indice
      sequenziale. Nota che questa ambiguità non si verifica con
      frequenze di serie temporali diverse da quelle annuali e
      giornaliere; date come 1980:3 (terzo trimestre del 1980) e
      2020:03 (marzo 2020) non possono essere confuse con indici
      semplici.
    </para>

    <subhead>Opzione specifiche per dataset panel</subhead>
    <para>
	Le opzioni <opt>unit</opt> e <opt>time</opt> sono specifiche
	ai dataset panel, e permettono di specificare rispettivamente
	un intervallo di unità o di tempo. Per esempio:
      </para>
      <code>
	# limita il campione alle prime 50 unità
	smpl 1 50 --unit
	# limita il campione ai periodi tra 2 e 20
	smpl 2 20 --time
      </code>
      <para>
	Se la dimensione temporale del dataset è stato specificato per
	mezzo del comando <cmdref targ="setobs"/> con l'opzione
	<opt>panel-time</opt>, <lit>smpl</lit> con l'opzione
	<opt>time</opt> può anche essere espresso in termini di date
	anziché numeri progressivi. Ad esempio:
      </para>
      <code>
	# indica che il panel è trimestrale, a partire da 1990Q1
	setobs 4 1990:1 --panel-time
	# limita il campione da 2000:1 a 2007:1
	smpl 2000:1 2007:1 --time
      </code>
      <para>
	In gretl, un dataset panel deve essere sempre
	<quote>nominalmente bilanciato</quote>: vale a dire che per
	ogni unità deve esserci lo stesso numero di osservazioni,
	anche se tutti i dati sono <lit>NA</lit>. Limitare il campione
	con le opzioni <opt>restrict</opt> o <opt>dummy</opt> potrebbe
	far sì che questo non sia più vero. In tal caso, si può usare
	l'opzione <opt>preserve-panel</opt> per far sì che venga
	preservata una struttura nominalmente bilanciata attraverso
	l'inserimento di <quote>righe vuote</quote> se necessario.
      </para>

      <subhead>Sottocoampionamento permanente</subhead>
      <para>
	Di default, le restrizioni sul campione attivo sono
	reversibili: col comando <lit>smpl full</lit> si ritorna al
	dataset completo. Tuttavia, con l'opzione <opt>permanent</opt>
	il dataset ridotto rimpiazza quello originale. L'opzione
	<opt>permanent</opt> senza altri argomenti o opzioni ha
	l'effetto di ridurre il dataset all'intervallo di
	campionamento corrente.
    </para>

    <para>
      Si veda <guideref targ="chap:sampling"/> per ulteriori
      dettagli.
    </para>

  </description>

  <gui-access>
    <menu-path>/Campione</menu-path>
  </gui-access>

</command>

<command name="spearman" section="Statistics"
	 label="Correlazione di rango di Spearman">

  <usage>
    <arguments>
      <argument>x</argument>
      <argument>y</argument>
    </arguments>
    <options>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dati ordinati</effect>
      </option>
    </options>
  </usage>

  <description>
    <para context="cli">
      Mostra il coefficiente di correlazione di rango di Spearman per
      le variabili <math>x</math> e <math>y</math>. Le
      variabili non devono essere state ordinate manualmente in
      precedenza, se ne occupa la funzione.
    </para>

    <para context="gui">
      Mostra il coefficiente di correlazione di rango di Spearman
      per una coppia di variabili.  Le variabili non devono essere
      state ordinate manualmente in precedenza, se ne occupa la
    funzione.</para>

    <para>
      L'ordinamento automatico è dal massimo al minimo (ossia il
      valore massimo nei dati assume il rango 1). Se occorre invertire
      l'ordinamento, creare una variabile che è il negativo della
      variabile originale, ad esempio:
    </para>

    <code>
      genr altx = -x
      spearman altx y
    </code>
  </description>

  <gui-access>
    <menu-path>/Modello/Stima robusta/SPEARMAN - Correlazione di rango</menu-path>
  </gui-access>

</command>

<command name="square" section="Transformations" label="Crea quadrati delle variabili" context="cli">

  <usage>
    <arguments>
      <argument>lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--cross</flag>
	<effect>genera anche i prodotti incrociati, oltre ai quadrati</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Genera nuove variabili che sono i quadrati delle variabili nella
      <repl>lista-variabili</repl> (con anche i prodotti incrociati,
      se si usa l'opzione <opt>cross</opt>). Ad esempio, <cmd>square
	x y</cmd> genera <lit>sq_x</lit> = <lit>x</lit> al quadrato,
      <lit>sq_y</lit> = <lit>y</lit> al quadrato e (opzionalmente)
      <lit>x_y</lit> = <lit>x</lit> per <lit>y</lit>.
      Se una particolare variabile è una dummy, non ne viene fatto il
      quadrato, visto che si otterrebbe la stessa variabile.
    </para>
  </description>

  <gui-access>
    <menu-path>/Aggiungi/Quadrati delle variabili selezionate</menu-path>
  </gui-access>

</command>

<command name="stdize" section="Transformations"
	 label="Standardize series">

  <usage>
    <arguments>
      <argument>varlist</argument>
    </arguments>
    <options>
      <option>
	<flag>--no-df-corr</flag>
	<effect>non effettua correzioni per gradi di libertà</effect>
      </option>
      <option>
	<flag>--center-only</flag>
	<effect>non divide per lo sqm</effect>
      </option>
    </options>
  </usage>

  <description context="gui">
    <para>
      Per impostazione predefinita, quest'azione aggiunge al dataset
      come nuove serie la versione standardizzata di quelle
      originali, col prefisso <lit>s_</lit>. Ad esempio,
      <lit>s_x</lit> viene formata sottraendo da
      <lit>x</lit> la sua media, dopodiché il risultato viene diviso
      per il suo scarto quadratico medio (con una correzione per
      gradi di libertà pari a 1). Tuttavia, è anche possibile usare
      come divisore la deviazione standard senza correzione per
      gradi di libertà (il cosiddetto stimatore ML).
    </para>
    <para>
      Volendo, si possono costruire serie che sono soltanto centrate
      (la media viene sottratta ma i dati non vengono scalati).  In
      questo caso, il prefisso sarà <lit>c_</lit> anziché
      <lit>s_</lit>.
    </para>
  </description>

  <description context="cli">
    <para>
      Per impostazione predefinita, questo comando aggiunge al
      dataset come nuove serie la versione standardizzata di quelle
      originali, col prefisso <lit>s_</lit>. Ad esempio, <cmd>stdize
	x y</cmd> crea le nuove serie <lit>s_x</lit> e <lit>s_y</lit>,
      <lit>s_x</lit> ognuna delle quali viene formata sottraendo la
      rispettiva media, dopodiché il risultato viene diviso per il
      suo scarto quadratico medio (con una correzione per gradi di
      libertà pari a 1).
    </para>
    <para>
      Con l'opzione <opt>no-df-corr</opt> non si ha la correzione
      per gradi di libertà, e si usa il cosiddetto stimatore ML.
      Con l'opzione <opt>center-only</opt> verranno prodotte serie
      che sono soltanto centrate (la media viene sottratta ma i dati
      non vengono scalati).  In questo caso, il prefisso sarà
      <lit>c_</lit> anziché <lit>s_</lit>.
    </para>
    <para>
      La funzione <fncref targ="stdize"/> produce lo stesso
      risultato, ma la sua sintassi è un po' più flessibile.
    </para>
  </description>

  <gui-access>
    <menu-path>/Aggiungi/Standardizza le variabili selezionate</menu-path>
  </gui-access>

</command>

<command name="store" section="Dataset" label="Salvataggio dei dati">

  <usage>
    <arguments>
      <argument>file-dati</argument>
      <argument optional="true">lista-variabili</argument>
    </arguments>
    <options>
      <option>
	<flag>--omit-obs</flag>
	<effect>si veda oltre, a proposito del formato CSV</effect>
      </option>
      <option>
	<flag>--no-header</flag>
	<effect>si veda oltre, a proposito del formato CSV</effect>
      </option>
      <option>
	<flag>--gnu-octave</flag>
	<effect>usa il formato GNU Octave</effect>
      </option>
      <option>
	<flag>--gnu-R</flag>
	<effect>usa il formato GNU R</effect>
      </option>
      <option>
	<flag>--gzipped</flag>
	<optparm optional="true">livello</optparm>
	<effect>comprime con gzip</effect>
      </option>
      <option>
	<flag>--jmulti</flag>
	<effect>usa il formato ASCII di JMulti</effect>
      </option>
      <option>
	<flag>--dat</flag>
	<effect>usa il formato ASCII di PcGive</effect>
      </option>
      <option>
	<flag>--decimal-comma</flag>
	<effect>usa la virgola come separatore decimale</effect>
      </option>
      <option>
	<flag>--database</flag>
	<effect>usa il formato database di gretl</effect>
      </option>
      <option>
	<flag>--overwrite</flag>
	<effect>cfr oltre, a proposito del formato dei database</effect>
      </option>
      <option>
	<flag>--comment</flag>
	<optparm>string</optparm>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--matrix</flag>
	<optparm>nome-matrice</optparm>
	<effect>vedi sotto</effect>
      </option>
      <option>
        <flag>--compat</flag>
        <effect>compatibilità gdtb, vedi sotto</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Salva i dati nel file <repl>filename</repl>. Per default,
      vengono salvate tutte le serie attualmente definite, ma usando
      l'argomento opzionale <repl>varlist</repl> è possibile
      salvarne solo una parte. Se il dataset è sottocampionato,
      verranno salvate solo le osservazioni attualmente attive.
    </para>
    <para>
      Il file di output verrà scritto nella directory corrispondente
      al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
      di file contenga un percorso completo.
    </para>
    <para>
      Il comando <lit>store</lit> funziona in modo speciale se è
      compreso in un <quote>progressive loop</quote>.  Vedi
      <guideref targ="chap:looping"/> per dettagli.
    </para>
    <subhead>Formati nativi</subhead>
    <para>
      Se <repl>file-dati</repl> ha estensione <lit>.gdt</lit> o
      <lit>.gtdb</lit>, il salvataggio avverrà in uno dei formati
      nativi di gretl. Se non viene specificata alcuna estensione, si
      dà <lit>.gdt</lit> come scelta implicita e il suffisso viene
      aggiunto automaticamente. Il formato <lit>gdt</lit> è XML, con
      compressione gzip opzionale, mentre il formato <lit>gdtb</lit>
      è binario. Il primo è la scelta tipica per dati di dimensione
      moderata (fino a qualche centinaio di kilobyte); per dataset
      grandi, il formato binario è molto più efficiente.
    </para>
    <para>
      A partire dalla versione 2021a, il formato <lit>gdtb</lit> è
      stato modificato in modo da velocizzare la lettura e scrittura
      di file molto grandi. Per salvare col vecchio formato, così che
      il file sia leggibile con versioni precedenti di gretl, si deve
      usare l'opzione <opt>compat</opt>.
    </para>
    <para>
      Quando si salva in formato nativo, l'opzione
      <opt>gzipped</opt> abilita la compressione, cosa che può
      essere utile per grandi dataset. Pewr questa opzione, il
      parametro opzione controla il livello di compressione (da 0 a
      9): livelli più alti producono file più piccoli, ma in tempi
      più lunghi. Il valore di default è 1; col livello 0 non c'è
      alcuna compressione.
    </para>
    <subhead>Altri formati</subhead>
    <para>
      Il formato in cui i dati vengono salvati è controllato, in
      primo luogo dall'estensione di <repl>filename</repl>, come segue:
    </para>
    <ilist>
      <li>
	<para>
	  <lit>.csv</lit>: testo separato da virgole (CSV).
	</para>
      </li>
      <li>
	<para>
	  <lit>.txt</lit> o <lit>.asc</lit>: testo separato da
	  spazi.
	</para>
      </li>
      <li>
	<para>
	  <lit>.m</lit>: formato GNU Octave.
	</para>
      </li>
      <li>
	<para>
	  <lit>.dta</lit>: formato Stata (version 113).
	</para>
      </li>
    </ilist>
    <para>
      Le opzioni di formato mostrate sopra possono essere usate per
      forzare un certo formato indipendentemente dall'estensione
      data al file, o per generare un file di formato PcGive o JMulTi
    </para>
    <para>
      Le opzioni <opt>omit-obs</opt> e <opt>no-header</opt> sono
      applicabile solo quando si salvano dati in formato CSV. In
      modalità predefinita, se i dati sono serie storiche o panel, o
      se il dataset include marcatori per osservazioni specifiche,
      il file CSV comprende una prima colonna che identifica le
      osservazioni (ad esempio per data). Se si usa
      <opt>omit-obs</opt>, questa colonna verrà omessa e verranno
      salvati solo i dati effettivi.  L'opzione <opt>no-header</opt>
      fa sì che venga omessa la stampa dei nomi di variabile in cima
      al file.
    </para>
    <para>
      L'opzione <opt>decimal-comma</opt> è anch'essa specifica al
      salvgataggio in formato CSV, e fa sì che venga usata la
      virgola come separatore decimale e il punto e virgola come
      separatore di campo.
    </para>
    <subhead>Salvataggio in formato database</subhead>
    <para>
      L'opzione di salvataggio in formato database di gretl è
      indicata se occorre costruire dei grandi dataset di serie,
      magari con frequenze diverse e diversi intervalli di
      osservazioni. Al momento questa opzione è disponibile solo per
      dati in serie storiche annuali, trimestrali o mensili, oppure
      per dati cross-sezionali. Un database gretl 
      consiste di due file: uno con estensione <lit>.bin</lit>
      che contiene i dati in formato binario e un file di testo
      con estensione <lit>.idx</lit> per i metadati.  Quando si
      salva il file dalla linea di comando l'estensione deve essere
      <lit>.bin</lit> oppure omessa.
    </para>
    <para>
      Salvando su un file che esiste già, il comportamento
      predefinito è quello di accodare le nuove serie al contenuto
      del database preesistente. In questo contesto, se una o più
      delle variabili da salvare hanno lo stesso nome di una delle
      variabili già presenti nel database si avrà un messaggio di
      errore. L'opzione <opt>overwrite</opt> permette invece di
      sovrascrivere eventuali variabili del dataset che hanno lo
      stesso nome delle nuove variabili, in modo che queste ultime
      rimpiazzino le variabili preesistenti.
    </para>
    <para>
      L'opzione <opt>comment</opt> è disponibile quando si salva
      come database o come CSV. Il parametro richiesto consta di una
      linea, racchiusa da virgolette doppie, passata all'opzone dopo
      un segno di uguale. Tale stringa verrà inserita come commento
      nel file indice del database o all'inizio del file CSV.
    </para>
    <subhead>Salvare una matrice come dataset</subhead>
    <para>
      L'opzione <opt>matrix</opt> richiede, come parametro, il nome
      di una matrice non vuota. L'effetto del comando
      <lit>store</lit> sarà quello di trasformare la matrice in un
      dataset <quote>dietro le quinte</quote> e salvarlo su file
      come tale. Le colonne della matrice diventano serie, e i loro
      nomi sono dati dai nomi di colonn, se presenti; altrimenti,
      saranno dati da <lit>v1</lit>, <lit>v2</lit> e così via. Se la
      matrice ha nomi di riga, questi verranno convertiti in
      <quote>etichette di osservazione</quote>.
    </para>
    <para>
      Si noti che la funzione <fncref targ="mwrite"/> permette di
      salvare su file matrici in quanto tali, ma a volte può essere
      più utile salvarle come dataset.
    </para>
  </description>

  <gui-access>
    <menu-path>/File/Salva dati; /File/Esporta dati</menu-path>
  </gui-access>

</command>

<command name="summary" section="Statistics" label="Statistiche descrittive" context="cli">

  <usage>
    <altforms>
      <altform><lit>summary [</lit> <repl>lista</repl> ]</altform>
      <altform><lit>summary --matrix=</lit><repl>nomematrice</repl></altform>
    </altforms>
    <options>
      <option>
	<flag>--simple</flag>
	<effect>solo statistiche di base</effect>
      </option>
      <option>
	<flag>--weight</flag>
	<optparm>wvar</optparm>
	<effect>variabile peso</effect>
      </option>
      <option>
	<flag>--by</flag>
	<optparm>byvar</optparm>
	<effect>vedi sotto</effect>
      </option>
    </options>
    <examples>
      <demos>
	<demo>frontier.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>
    <para>
      Nella prima forma, mostra le statistiche descrittive per le
      variabili nella <repl>lista-variabili</repl>, o per tutte le
      variabili nel dataset, se non si indica una
      <repl>lista-variabili</repl>.  L'output comprende media,
      scarto quadratico medio, coefficiente di variazione (= scarto
      quadratico medio / media), mediana, minimo, massimo,
      coefficiente di asimmetria, curtosi in eccesso, 5&deg; e
      95&deg; percentile, range interquartile e numero di
      osservazioni mancanti. Con l'opzione <opt>simple</opt>, si
      avranno soltanto media, minimo, massimo e scarto quadratico
      medio.
    </para>
    <para>
      Con l'opzione <opt>weight</opt>, dove il parametro
      parameter <repl>wtvar</repl> deve essere una serie contenente
      i pesi per osservazione, le statistiche saranno ponderate.
    </para>
    <para>
      L'opzione <opt>by</opt> (dove il parametro
      <repl>byvar</repl> dev'essere il nome di una variabile
      discreta), provoca la stampa delle statistiche per
      sottocampioni definiti dai diversi valori di
      <repl>byvar</repl>.  Ad esempio, se <repl>byvar</repl> è una
      variabile binaria (dummy), verranno riportate separatamente le
      statistiche relative ai sottocampioni definitia dai due casi
      <lit>byvar=0</lit> e <lit>byvar=1</lit>. Nota: al momento,
      questa opzione è incompatibile con l'altra opzione
      <opt>weight</opt>.
    </para>
    <para>
      Se si usa la forma alternativa in cui il parametro è una
      matrice, allora le statistiche descrittive sono calcolate per
      le colonne della matrice. L'opzione <opt>by</opt> non è
      disponibile per questo caso. 
    </para>
    <para>
      La tavola prodotta dal comando <lit>summary</lit> è
      disponibile sotto forma di matrice con l'accessore <fncref
      targ="$result"/>. Con l'opzione <opt>by</opt>, questo accessore
      viene prodotto soltanto se  <repl>varlist</repl> è una serie singola.
    </para>
    <para>
      Vedi anche la funzione <fncref targ="aggregate"/> per produrre
      statistiche <quote>fattorizzate</quote> in modo più flessibile.
    </para>
  </description>

  <gui-access>
    <menu-path>/Visualizza/Statistiche descrittive</menu-path>
    <other-access>Menù pop-up nella finestra principale</other-access>
  </gui-access>

</command>

<command name="system" section="Estimation" label="Sistemi di equazioni">

  <usage>
    <altforms>
      <altform><lit>system method=</lit><repl>stimatore</repl></altform>
      <altform><repl>nome-sistema</repl><lit> &lt;- system</lit></altform>
    </altforms>
    <examples>
      <example>"Klein Model 1" &lt;- system</example>
      <example>system method=sur</example>
      <example>system method=3sls</example>
      <demos>
	<demo>klein.inp</demo>
	<demo>kmenta.inp</demo>
	<demo>greene14_2.inp</demo>
      </demos>
    </examples>
  </usage>

  <description>

    <para context="gui">
      In questa finestra, è possibile stimare sistemi di
      equazioni e scegliere uno stimatore per il sistema. È possibile indicare
      i seguenti quattro tipi di comandi:
    </para>

    <para context="cli">
      Inizia un sistema di equazioni. Esistono due versioni del comando,
      a seconda che si voglia salvare il sistema per poterlo stimare in
      più modi diversi, oppure stimare il sistema una volta sola.
    </para>

    <para context="cli">
      Per salvare il sistema occorre dargli un nome, come nel primo esempio
      proposto (se il nome contiene spazi, occorre racchiuderlo tra virgolette).
      In questo caso, è possibile stimare il sistema con il comando
      <cmdref targ="estimate"/>. Una volta che il sistema è stato salvato, è
      possibile imporre dei vincoli su di esso (compresi vincoli incrociati
      tra equazioni) usando il comando <cmdref targ="restrict"/>.
    </para>

    <para context="cli">
      In alternativa, è possibile indicare uno stimatore per il sistema
      usando <lit>method=</lit> seguito da una stringa che identifica uno
      degli stimatori supportati: <cmd>ols</cmd> (ordinary least squares -
      minimi quadrati ordinari), <cmd>tsls</cmd> (two-stage least squares -
      minimi quadrati a due stadi), <cmd>sur</cmd> (seemingly unrelated
      regressions - regressioni apparentemente non collegate), <cmd>3sls</cmd>
      (three-stage least squares - minimi quadrati a tre stadi),
      <cmd>fiml</cmd> (full information maximum likelihood - massima
      verosimiglianza con informazione completa) o <cmd>liml</cmd> (limited
      information maximum likelihood - massima verosimiglianza con
      informazione limitata). In questo caso, il sistema viene stimato appena
      completata la sua definizione.
    </para>

    <para context="cli">
      Un sistema di equazioni termina con la riga
      <cmd>end system</cmd>.  All'interno del sistema possono essere
      definiti i quattro tipi di istruzioni seguenti.
    </para>

    <ilist>
      <li><para><cmdref targ="equation"/>: specifica un'equazione del sistema.
	  Occorre indicarne almeno due.</para>
      </li>
      <li><para><cmd>instr</cmd>: per i sistemi da stimare con i minimi
	  quadrati a tre stadi, indica la lista degli strumenti (indicati
	  dal nome o dal numero della variabile). In alternativa, è possibile
	  fornire questa informazione nella riga <cmd>equation</cmd> usando la
	  stessa sintassi accettata dal comando <cmdref targ="tsls"/>.</para>
      </li>
      <li><para><cmd>endog</cmd>: per i sistemi di equazioni
	  simultanee, indica la lista delle variabili endogene. È
	  indicato principalmente per la stima FIML, ma può essere usato
	  anche nella stima minimi quadrati a tre stadi al posto
	  dell'istruzione <cmd>instr</cmd>: in questo modo tutte le
	  variabili non identificate come endogene verranno usate come
	  strumenti.</para>
      </li>
      <li><para><cmd>identity</cmd>: per la stima FIML, un'identità
	  che collega due o più variabili del sistema. Questo tipo di
	  istruzione è ignorata se viene usato uno stimatore diverso da
	  FIML.
	</para>
      </li>
    </ilist>

    <para context="cli">
      Dopo la stima eseguita con i comandi <cmd>system</cmd> o
      <cmd>estimate</cmd> è possibile recuperare informazioni aggiuntive dalle
      seguenti variabili accessorie:
    </para>

    <ilist context="cli">
      <li>
        <para><fncref targ="$uhat"/>: la matrice dei residui, una colonna per
          equazione.
	</para>
      </li>
      <li>
        <para><fncref targ="$yhat"/>: la matrice dei valori stimati, una colonna
          per equazione.
	</para>
      </li>
      <li>
        <para><fncref targ="$coeff"/>: il vettore colonna dei coefficienti
          (tutti i coefficienti della prima equazione, seguiti da
          quelli della seconda equazione, e così via).
	</para>
      </li>
      <li>
        <para><fncref targ="$vcv"/>: la matrice di covarianza dei coefficienti.
          Se il vettore <fncref targ="$coeff"/> ha <math>k</math> elementi,
          questa matrice ha dimensione <math>k</math> per <math>k</math>.
	</para>
      </li>
      <li>
        <para><fncref targ="$sigma"/>: la matrice di covarianza dei residui
          incrociata tra equazioni.
	</para>
      </li>
      <li><para><fncref targ="$sysGamma"/>, <fncref targ="$sysA"/> e
	  <fncref targ="$sysB"/>: matrici dei coefficienti in forma
	  strutturale (si veda oltre).
	</para>
      </li>
    </ilist>

    <para context="cli">
      Se si vuole salvare i residui o i valori stimati per una specifica
      equazione come serie di dati, basta selezionare la colonna dalla matrice
      <fncref targ="$uhat"/> o <fncref targ="$yhat"/> e assegnarla a una serie, come in
    </para>
    <code context="cli">
      series uh1 = $uhat[,1]
    </code>

    <para context="cli">
      Le matrici in forma strutturale corrispondono alla seguente
      rappresentazione di un modello ad equazioni simultanee:
      <equation status="display"
		tex="\[\Gamma y_t=Ay_{t-1}+Bx_t+\epsilon_t\]"
		ascii="Gamma y(t) = A y(t-1) + B x(t) + e(t)"
		graphic="structural"/> Se ci sono <math>n</math> variabili endogene e
      <math>k</math> variabili esogene,
      <equation status="inline"
		tex="$\Gamma$"
		ascii="Gamma"
		graphic="Gamma"/> è una matrice <by r="n" c="n"/> e <math>B</math> è
      <by r="n" c="k"/>. Se il sistema non contiene ritardi delle variabili
      endogene, la matrice <math>A</math> non è presente. Se il massimo
      ritardo di un regressore endogeno è <math>p</math>, la matrice
      <math>A</math> è <by r="n" c="np"/>.
    </para>

  </description>

  <gui-access>
    <menu-path>/Modello/Equazioni simultanee</menu-path>
  </gui-access>

</command>

<command name="tabprint" section="Printing" label="Stampa modelli in forma
						   tabulare" context="cli">

  <usage>
    <options>
      <option>
	<flag>--format="f1|f2|f3|f4"</flag>
	<effect>Specifica un formato personalizzato</effect>
      </option>
      <option>
	<flag>--output</flag>
	<optparm>filename</optparm>
	<effect>invia l'output al file specificato</effect>
      </option>
    </options>
  </usage>
  
  <description>
    <para>
      Va eseguito dopo la stima di un modello.  Stampa il modello
      stimato sotto forma di tabella, in formato &latex; o in
      formato RTF o CSV, se viene usata l'opzione corrispondente.
      Se viene specificato un nome di file dopo l'opzione
      <opt>output</opt>, l'output viene scritto nel file, altrimenti
      viene scritto in un file col nome
      <filename>model_N.tex</filename> (o
      <filename>model_N.rtf</filename>), dove <lit>N</lit> è il
      numero dei modelli stimati finora nella sessione in corso.
    </para>
    <para>
      Il file di output verrà scritto nella directory corrispondente
      al valore corrente di <cmdref targ="workdir"/>, a meno che il nome
      di file contenga un percorso completo.
    </para>
    <para>
      Selezionando il formato CSV, i valori sono separati da
      virgole, a meno che il delimitatore decimale non sia esso
      stesso la virgola, nel qual caso viene usato il punto e
      virgola. Si noti che l'output in CSV potrebbe essere meno
      completo degli altri formati.
    </para>
    <para>
      Le opzioni illustrate di seguito sono disponibili solo per il
      formato &latex;.
    </para>
    <para>
      Usando l'opzione <opt>complete</opt>, il file &latex; è un
      documento completo, pronto per essere processato; altrimenti
      il file va incluso in un documento.
    </para>
    <para>
      Se si intende modificare lo stile del formato tabulare, è
      possibile specificare un formato personalizzato usando
      l'opzione <opt>format</opt>, seguita da una stringa di
      formato. La stringa di formato va inclusa tra virgolette
      doppie e deve essere unita all'opzione con un segno di
      uguale. La composizione della stringa di formato è la
      seguente: ci sono quattro campi, che rappresentano il
      coefficiente, l'errore standard, il rapporto <math>t</math> e
      il p-value. Questi campi vanno separati usando barre verticali
      e possono contenere una specificazione di formato per valori
      numerici nello stile della funzione <lit>printf</lit>, oppure
      possono essere lasciati in bianco, in modo da sopprimere la
      visualizzazione del campo nella rispettiva colonna dela
      tabella (con l'unico vincolo che non è possibile lasciare in
      bianco tutti i campi).  Ecco alcuni esempi:
    </para>
    <code>
      --format="%.4f|%.4f|%.4f|%.4f"
      --format="%.4f|%.4f|%.3f|"
      --format="%.5f|%.4f||%.4f"
      --format="%.8g|%.8g||%.4f"
    </code>
    <para>
      La prima specificazione stampa i valori di tutte le colonne usando 4
      cifre decimali. La seconda sopprime il p-value e mostra il rapporto
      <math>t</math> con 3 cifre decimali. La terza omette il rapporto
      <math>t</math>, mentre l'ultima omette il rapporto
      <math>t</math> e mostra sia il coefficiente che l'errore standard
      con 8 cifre significative.
    </para>
    <para>
      Una volta che si imposta un formato in questo modo, esso viene ricordato
      e usato per tutta la sessione di lavoro. Per tornare ad usare il formato
      predefinito, basta usare la parola chiave <lit>--format=default</lit>.
    </para>
  </description>

  <gui-access>
    <menu-path>Finestra del modello, /LaTeX</menu-path>
  </gui-access>

</command>

  <command name="tdisagg" section="Dataset" label="Disaggregazione temporale"
	   context="gui">
    <description>
      <para>
	Queste sono le opzioni disponibili nella finestra di dialogo
	per la disaggregazione temporale. Per un'esposizione
	dettagliata si veda <guideref targ="chap:tdisagg"/>.
      </para>
      <ilist>
	<li>
	  <para>
	    Nome di output: Qui si sceglie se sovrascrivere una serie
	    esistente con i dati disaggregati o crearne una nuova.
	  </para>
	</li>
	<li>
	  <para>
	    Tipo di aggregazione: Se si andasse nella direzione
	    opposta, (aggregando anziché disaggregando) come sarebbe
	    definita la serie a bassa frequenza? La scelta
	    <lit>sum</lit> è appropriata se la serie a bassa frequenza
	    risulta dalla somma dei valori ad alta frequenza
	    (variabili flusso, come ad esempio il PIL).
	    Scegliendo <lit>avg</lit> si assume che la serie ad alta
	    frequenza sia uguale in media al valore a bassa frequenza
	    (numeri indice, rapporti, o variabili flusso <quote>a
	    tassi annuali</quote>). La scelta <lit>last</lit> o
	    <lit>first</lit> va usata per serie di tipo stock, come ad
	    esempio lo stock di moneta.
         </para>
       </li>
       <li>
	 <para>
	   Basato su regressione o Denton: La prima opzione è quella
	   generalmente consigliabile. In questo caso, si può
	   selezionare il metodo di Fernández se si pensa che la serie
	   contenga una radice unitaria; altrimenti, si può usare
	   Chow&ndash;Lin. L'so del metodo di Denton è consigliato a
	   chi sa cosa sta facendo. I metodi Denton sono in differenze
	   prime, secondo la modifica di Cholette.
        </para>
      </li>
    </ilist>
  </description>

  </command>

  <command name="textplot" section="Graphs" label="Grafici ASCII" context="cli">
    <usage>
      <arguments>
<argument>lista-variabili</argument>
</arguments>
<options>
      <option>
	<flag>--time-series</flag>
	<effect>disegna per osservazione</effect>
      </option>
      <option>
	<flag>--one-scale</flag>
	<effect>forza l'uso di un'unica scala</effect>
      </option>
      <option>
	<flag>--tall</flag>
	<effect>usa 40 linee</effect>
      </option>
    </options>
  </usage>

  <description>
    <para>
      Grafica ASCII nuda e cruda. Senza l'opzione
      <opt>time-series</opt>, <repl>varlist</repl> deve contenere
      almeno due serie, l'ultima delle quali va sull'asse delle
      ascisse, e verrà prodotto un diagramma a dispersione. In
      questo caso, si può usare l'opzione <opt>tall</opt> per
      produrre un grafico in cui l'asse <math>y</math> è
      rappresentato da 40 righe di caratteri (il default è 20
      righe).
    </para>
    <para>
      Con l'opzione <opt>time-series</opt>, viene prodotto un
      grafico per osservazione.  In questo caso, l'opzione
      <opt>one-scale</opt> forza l'uso di una scala singola;
      altrimenti, se <repl>varlist</repl> contiene più di una serie
      i dati potrebbero essere riscalati. Ogni riga rappresenta
      un'osservazione, con i dati disegnati orizzontalmente.
    </para>
    <para>
      Vedi anche <cmdref targ="gnuplot"/>.
    </para>
  </description>

  </command>
  <command name="tobit" section="Estimation" label="Stima Tobit">

    <usage>
      <arguments>
        <argument>variabile-dipendente</argument>
        <argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--llimit</flag>
	<optparm>lval</optparm>
	<effect>specifica il limite sinistro</effect>
      </option>
      <option>
	<flag>--rlimit</flag>
	<optparm>rval</optparm>
	<effect>specifica il limite destro</effect>
      </option>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>standard error robusti</effect>
      </option>
      <option>
	<flag>--opg</flag>
	<effect>vedi sotto</effect>
      </option>
      <option>
	<flag>--cluster</flag>
	<optparm>clustvar</optparm>
	<effect>vedi <cmdref targ="logit"/> per una spiegazione</effect>
      </option>
      <option>
	<flag>--verbose</flag>
	<effect>mostra i dettagli delle iterazioni</effect>
      </option>
        <option>
	  <flag>--quiet</flag>
	  <effect>non stampa i risultati</effect>
        </option>
    </options>
  </usage>

  <description>
    <para>
      Stima un modello Tobit. Il modello può essere appropriato
      quando la variabile dipendente è <quote>censurata</quote>. Ad
      esempio, vengono osservati valori positivi o nulli della spesa
      dei consumatori per beni durevoli, ma non valori negativi;
      tuttavia le decisioni di spesa possono essere pensate come
      derivanti da una propensione al consumo, sottostante e non
      osservata, che può anche essere negativa in alcuni casi.
    </para>
    <para context="cli">
      Si assume, di default, che la variabile dipendente si
      censurata a 0 sulla sinistra e non censurata a destra.
      Tuttavia, usando le opzioni <opt>llimit</opt> e
      <opt>rlimit</opt> si può specificare uno schema di censura
      diverso.  Se si specifica soltanto un limite destro, si assume
      che la variabile dipendente sia non limitata a sinistra.
    </para>
    <para context="gui">
      Si assume, di default, che la variabile dipendente si
      censurata a 0 sulla sinistra e non censurata a destra.
      Tuttavia, usando le opzioni <opt>llimit</opt> e
      <opt>rlimit</opt> si può specificare uno schema di censura
      diverso.  Inserire un valore numerico oppure <lit>NA</lit> per
      specificare l'assenza di censura.
    </para>
    <para>
      Il modello Tobit è un caso particolare della regressione ad
      intervallo. Si veda la documentazione del comando <cmdref
      targ="intreg"/> per una descrizione delle opzioni
      <opt>robust</opt> e <opt>opg</opt>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Modello/Modelli non lineari/Tobit</menu-path>
  </gui-access>

</command>

<command name="transpos" section="Dataset" label="Trasposizione dei dati"
	 context="gui">

  <description>
    <para>
      Traspone il dataset attuale, ossia, ogni osservazione (riga) del
      dataset attuale verrà trattata come una variabile (colonna) e
      ogni variabile come un'osservazione. Questo comando è utile se
      sono stati importati da una fonte esterna dati in cui le righe
      rappresentano variabili e le colonne osservazioni.
    </para>
    <para>
      Si veda anche <cmdref targ="dataset"/>.
    </para>
  </description>

  <gui-access>
    <menu-path>/Dati/Trasponi dati</menu-path>
  </gui-access>

</command>

  <command name="tsls" section="Estimation"
	   label="Stima minimi quadrati a due stadi">
    <usage>
      <arguments>
	<argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
	<argument separated="true">strumenti</argument>
      </arguments>
      <options>
	<option>
	  <flag>--no-tests</flag>
	  <effect>omette i test diagnostici</effect>
	</option>
	<option>
	  <flag>--vcv</flag>
	  <effect>mostra la matrice di covarianza</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>non stampare i risultati</effect>
	</option>
	<option>
	  <flag>--no-df-corr</flag>
	  <effect>omette la correzione per gradi di libertà</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
	</option>
	<option>
	  <flag>--cluster</flag>
	  <optparm>clustvar</optparm>
	  <effect>standard error clusterizzati</effect>
	</option>
	<option>
 	  <flag>--liml</flag>
 	  <effect>usa massima verosimiglianza a informazione limitata</effect>
	</option>
	<option>
 	  <flag>--gmm</flag>
 	  <effect>usa il metodo generalizzato dei momenti</effect>
	</option>
      </options>
      <examples>
	<example>tsls y1 0 y2 y3 x1 x2 ; 0 x1 x2 x3 x4 x5 x6</example>
	<demos>
	  <demo>penngrow.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Calcola le stime con variabili strumentali, per impostazione predefinita
	usando i minimi quadrati a due stadi (TSLS), ma è possibile scegliere
	altre opzioni. Occorre specificare la <repl>variabile-dipendente</repl>,
	la lista di <repl>variabili-indipendenti</repl> (che si intende includere
	alcuni regressori endogeni), e infine gli <repl>strumenti</repl>, la lista
	completa delle variabili esogene e predeterminate. Se la lista degli
	<repl>strumenti</repl> non è lunga almeno quanto quella delle
	<repl>variabili-indipendenti</repl>, il modello non è
	identificato.
      </para>

      <para context="cli">
	Nell'esempio precedente, le <lit>y</lit> sono le variabili
	endogene e le <lit>x</lit> sono le variabili esogene e
	predeterminate. Si noti che eventuali regressori esogeni devono essere
	inclusi in entrambe le liste.
      </para>
      <para context="cli">
	Per dettagli sull'effetto delle opzioni <opt>robust</opt> e
	<opt>cluster</opt> si veda la documentazione per il comando
	<cmdref targ="ols"/>.
      </para>

      <para context="gui">
	Questo comando richiede la scelta di due liste di variabili;
	le variabili indipendenti che appaiono nel modello e un elenco
	di strumenti. Si noti che eventuali regressori esogeni devono
	essere inclusi in entrambe le liste.
      </para>
      <subhead>Test specifici per la stima a due stadi</subhead>
      <para>
	L'output delle stime TSLS comprende il test di Hausman e, se
	il modello è sovra-identificato, il test di Sargan per la
	sovra-identificazione. Per una spiegazione accurata ed
	esauriente di questi test si veda il capitolo 8 di <cite key="davidson-mackinnon04">Davidson and
	MacKinnon (2004)</cite>.
      </para>
      <para>
	Nel test di Hausman, l'ipotesi nulla è che le stime OLS siano
	consistenti, o in altre parole che non sia richiesta la stima
	per mezzo di variabili strumentali. Per impostazione
	predefinita, questo test è implementato con una regressione
	ausiliaria, ma se viene fornita l'opzione
	<opt>matrix-diff</opt> viene utilizzato il metodo di <cite
	key="papadopoulos23">Papadopoulos (2023)</cite>. In entrambi i
	casi viene impiegata una variante robusta se viene fornita
	anche l'opzione <opt>robust</opt>.
      </para>
      <para>
	Un modello di questo tipo è sovra-identificato se ci sono più
	strumenti di quelli strettamente necessari. Il test di Sargan
	<cite key="sargan58" p="true">(Sargan, 1958)</cite> è basato
	su una regressione ausiliaria dei residui del modello minimi
	quadrati a due stadi sull'intera lista degli
	strumenti. L'ipotesi nulla è che tutti gli strumenti siano
	validi, cosa di cui si dovrebbe dubitare se la regressione
	ausiliaria ha un significativo potere esplicativo. 
      </para>
      <para>
	Queste due statistiche sono disponibili, una volta completato
	con successo il comando, sotto i nomi <fncref
	targ="$hausman"/> e <fncref targ="$sargan"/>, rispettivamente.
      </para>
      <subhead>Strumenti deboli</subhead>
      <para>
	Per gli stimatori TSLS e LIML, viene mostrata una statistica
	aggiuntiva se il modello è stimato senza l'opzione
	<opt>robust</opt>, che riguarda la presenza di strumenti
	deboli. Con sttrumenti deboli, possono esserci seri problemi
	inferenziali: stime distorte e/o livelli di significatività
	sbagliati per le statistiche test basate sulla matrice di
	covarianze, con tassi di rifiuto ben più grandi del livello di
	significatività nominale <cite key="stock-wright-yogo02"
	p="true">(Stock, Wright and Yogo, 2002)</cite>.  La statistica
	è la <math>F</math> di primo stadio se il modello contiene un
	solo regressore endogeno, o il più piccolo autovalore della
	matrice corrispondente in caso contrario. Quando disponibili,
	sono mostrati i valori critici derivati dall'analisi di Monte
	Carlo contenuta in <cite key="stock-yogo03">Stock e Yogo
	(2003)</cite>.
      </para>
      <subhead>R-quadro</subhead>
      <para>
	Il valore R-quadro mostrato i modelli stimati con i minimi quadrati a
	due stadi è il quadrato della correlazione tra la variabile dipendente
	e i valori stimati.
      </para>

      <subhead>Stimatori alternativi</subhead>
      <para context="cli">
	In alternativa al metodo TSLS, il modello può essere stimato
	usando la massima verosimiglianza a informazione limitata
	(opzione <opt>liml</opt>) o il metodo generalizzato dei
	momenti (opzione <opt>gmm</opt>). Si noti che se il modello è
	esattamente identificato, questi metodi dovrebbero produrre
	gli stessi risultati del metodo TSLS, ma se il modello è
	sovraidentificato, i risultati saranno in genere diversi.
      </para>

      <para context="cli">
	Se si usa la stima GMM, è possibile usare le seguenti opzioni aggiuntive:
      </para>

      <ilist>
	<li>
	  <para>
	    <opt>two-step</opt>: esegue la stima GMM in due passi, invece che
            in un passo solo.
	  </para>
	</li>
	<li>
	  <para>
	    <opt>iterate</opt>: itera il GMM fino alla convergenza.
	  </para>
	</li>
	<li>
	  <para>
	    <opt>weights=</opt><repl>Pesi</repl>: specifica una
	    matrice quadrata di pesi da usare nel calcolo della
	    funzione criterio del GMM. La dimensione di questa matrice
	    deve essere pari al numero di strumenti. L'impostazione
	    predefinita consiste nell'usare una matrice identità di
	    dimensione opportuna.
	  </para>
	</li>
      </ilist>

    </description>

    <gui-access>
      <menu-path>/Modello/TSLS - Minimi quadrati a due stadi</menu-path>
    </gui-access>

  </command>


  <command name="tsplots" section="Graphs"
	   label="Multiple time-series plots">
    <usage>
      <arguments>
        <argument>lista-var</argument>
      </arguments>
      <options>
        <option>
	  <flag>--matrix</flag>
	  <optparm>nome</optparm>
	  <effect>plotta colonne della matrice</effect>
        </option>
        <option>
	  <flag>--output</flag>
	  <optparm>nomefile</optparm>
	  <effect>manda l'output al file specificato</effect>
        </option>
      </options>
      <examples>
        <example>tsplots 1 2 3 4</example>
        <example>tsplots 1 2 3 4 --matrix=X</example>
      </examples>
    </usage>

    <description>
      <para context="cli">
	Fornisce un modo semplice per plottare più serie temporali
	(fino a un massimo di 16) su un unico grafico. L'argomento
	<repl>lista-var</repl> può essere fornito come un elenco di
	numeri ID o nomi di serie, o come numeri di colonna nel caso
	in cui l'input sia una matrice.
       </para>
       <para contesto="cli">
	 Vedi anche <cmdref targ="scatters"/> per produrre grafici a
	 dispersione multipli, e <cmdref targ="gridplot"/> per un modo
	 più flessibile di combinare grafici in una griglia.
       </para>
       <para context="gui">
	Fornisce un modo semplice per plottare più serie temporali
	(fino a un massimo di 16) su un unico grafico. Vedi anche
	<cmdref targ="scatters"/> per produrre grafici a dispersione
	multipli, e <cmdref targ="gridplot"/> per un modo più
	flessibile di combinare grafici in una griglia.
      </para>
    </description>

    <gui-access>
      <menu-path>/View/Multiple graphs/Time series</menu-path>
    </gui-access>
  </command>

  <command name="var" section="Estimation"
	   label="Autoregressione vettoriale">

    <usage>
      <arguments>
	<argument>ordine</argument>
	<argument>lista-variabili</argument>
	<argument separated="true" optional="true">lista-esogene</argument>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>non include una costante</effect>
	</option>
	<option>
	  <flag>--trend</flag>
	  <effect>include un trend</effect>
	</option>
	<option>
	  <flag>--seasonals</flag>
	  <effect>include variabili dummy stagionali</effect>
	</option>
	<option>
	  <flag>--robust</flag>
	  <effect>errori standard robusti</effect>
	</option>
        <option>
	  <flag>--robust-hac</flag>
	  <effect>errori standard HAC</effect>
        </option>
	<option>
	  <flag>--quiet</flag>
	  <effect>omette l'output delle singole equazioni</effect>
	</option>
	<option>
	  <flag>--silent</flag>
	  <effect>non stampa nulla</effect>
	</option>
	<option>
	  <flag>--impulse-responses</flag>
	  <effect>mostra le risposte di impulse</effect>
	</option>
	<option>
	  <flag>--variance-decomp</flag>
	  <effect>mostra scomposizioni della varianza</effect>
	</option>
	<option>
	  <flag>--lagselect</flag>
	  <effect>mostra i criteri di informazione per la selezione dei ritardi</effect>
	</option>
        <option>
         <flag>--minlag</flag>
         <optparm>ritardo minimo</optparm>
         <effect>solo per la selezione dei ritardi, vedi sotto</effect>
        </option>
      </options>
      <examples>
	<example>var 4 x1 x2 x3 ; time mydum</example>
	<example>var 4 x1 x2 x3 --seasonals</example>
	<example>var 12 x1 x2 x3 --lagselect</example>
	<demos>
	  <demo>sw_ch14.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>

      <para context="gui">
	Questo comando richiede la specificazione dei seguenti elementi:
      </para>
      <ilist context="gui">
	<li><para context="gui">- L'ordine di ritardi, ossia il numero
	di ritardi di ogni variabile presente nel sistema;</para>
	</li>
	<li><para context="gui">- Eventuali termini esogeni (ma si
	noti che una costante viene inclusa automaticamente, a meno
	che non si richieda altrimenti; inoltre è possibile includere
	variabili dummy stagionali con l'apposita casella); e
      </para>
	</li>
	<li><para context="gui">- Una lista di variabili endogene,
	i cui ritardi saranno inclusi a destra delle equazioni (nota:
	non includere variabili ritardate in questa lista, verranno
	aggiunte automaticamente).</para>
	</li>
      </ilist>
      <para context="gui">
	Viene calcolata una regressione separata per ogni variabile
	del sistema; i risultati comprendono i test F per i vincoli di
	uguaglianza a zero su tutti i ritardi della variabili e un
	test F per il ritardo massimo, oltre (opzionalmente) alla
	scomposizione della varianza della previsione e alle funzioni
	di impulso-risposta.
      </para>

      <para context="cli">
	Imposta e stima (usando OLS) un'autoregressione vettoriale
	(VAR).  Il primo argomento specifica l'ordine di ritardo (o il
	massimo ordine di ritardi se è stata usata l'opzione
	<opt>lagselect</opt>). L'ordine può essere indicato
	numericamente o con il nome di una variabile scalare
	preesistente.  Quindi segue l'impostazione della prima
	equazione. Non occorre includere i ritardi tra gli elementi
	della <repl>lista-variabili</repl>: verranno aggiunti
	automaticamente. Il punto e virgola separa le variabili
	stocastiche, per cui verrà incluso un numero di ritardi pari a
	<repl>ordine</repl>, dai termini deterministici o esogeni
	presenti nella <repl>lista-esogene</repl>. Si noti che viene
	inclusa automaticamente una costante, a meno che non si usi
	l'opzione <opt>nc</opt>; inoltre è possibile aggiungere un
	trend con l'opzione <opt>trend</opt> e variabili dummy
	stagionali con l'opzione <opt>seasonals</opt>.
      </para>

      <para context="cli">
	Benché normalmente un VAR comprenda tutti i ritardi da 1 a un
	dato ordine, è possibile selezionare un set di ritardi
	specifico. Per farlo, occorre sostituire l'argomento scalare
	<repl>order</repl> col nome di un vettore predefinito o con
	una lista di ritardi separati da virgole, racchiusi da
	parentesi graffe. Qui di seguito, mostriamo due modi per
	specificare un VAR contenente i ritardi 1, 2 e 4 (ma non il
	3):
      </para>
      <code context="cli">
	var {1,2,4} ylist
	matrix p = {1,2,4}
	var p ylist
      </code>

      <para context="cli">
	Viene stampata una regressione separata per ognuna delle
	variabili nella <repl>lista-variabili</repl>. Il risultato di
	ogni equazione include i test <math>F</math> per i vincoli
	di uguaglianza a zero su tutti i ritardi delle variabili, un
	test <math>F</math> per la significatività del ritardo massimo e,
	se è stata usata l'opzione <opt>impulse-responses</opt>, la
	scomposizione della varianza della previsione e le funzioni di
	impulso-risposta.
      </para>

      <para>
	Le scomposizioni della varianza della previsione e le funzioni
	di risposta di impulso sono basate sulla decomposizione di
	Cholesky della matrice di covarianza contemporanea, e in
	questo contesto l'ordine in cui vengono date le variabili
	stocastiche conta.  La prima variabile nella lista viene
	considerata come la <quote>più esogena</quote> all'interno del
	periodo. L'orizzonte per le decomposizioni della varianza e le
	funzioni di impulso-risposta può essere impostato usando il
	comando <cmdref targ="set"/>. Per salvare una specifica
	risposta di impulso sotto forma di matrice, si veda la
	funzione <fncref targ="irf"/>.
      </para>

      <para context="cli">
	Con l'opzione <opt>robust</opt> gli errori standard sono
	corretti per l'eteroschedsasticità. In alternativa, l'opzione
	<opt>robust-hac</opt> produce errori standard HAC, cioè
	robusti tanto all'eteroschedasticità che
	all'autocorrelazione. In generale, la seconda opzione non
	dovrebbe essere necessaria se il modello include abbastanza
	ritardi.
      </para>

      <subhead context="cli">Lag selection</subhead>
      <para context="cli">
	Se si usa l'opzione <opt>lagselect</opt>, non viene presentato
	in normale output del comando. Il primo parametro del comando
	<lit>var</lit> viene interpretato come il
	<emphasis>massimo</emphasis> ordine di ritardo e viene
	prodotta una tabella che mostra valori comarativi dal VAR di
	ordine 1 fino al massimo specificato. La tavola include la
	log-verosimiglianza e un <math>P</math>-value + per un test
	Likelihood Ratio (LR), seguiti dai criteri di informazione di
	Akaike (AIC), Schwartz (BIC) e Hannan&ndash;Quinn (HQC). Il
	test LR confronta la specificazione di ogni riga con qualla
	precedente, sotto l'ipotesi che i parametri dell'ultimo
	ritardo siano tutti 0. La tabella coi risultati è disponibile
	tramite l'accessore <fncref targ="$test"/>.
      </para>
      <para>
	In questo contesto, l'opzione <opt>minlag</opt> serve a
	stabilire l'ordine minimo. Usando il valore 0 si ammette la
	possibilità che il ritardo ottimale sia nullo, e che in realtà
	il modello non sia affatto un VAR. Al contrario, se si dà per
	scontato che l'ordine minimo sia 4, con <opt>minlag=4</opt> si
	risparmia qualche millisecondo.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/VAR - Autoregressione vettoriale</menu-path>
    </gui-access>

  </command>

  <command name="VAR-lagselect" section="Tests" context="gui"
	   label="Scelta dell'ordine di ritardi in un VAR">

    <description>
      <para>
	In questa finestra di dialogo si specifica un VAR come al
	solito, ma con l'apposito controllo si setta il numero massimo
	di ritardi da testare.
      </para>
      <para>
	Il risultato consiste in una tabella che mostra la
	log-verosimiglianza e un <math>P</math>-value + per un test
	Likelihood Ratio (LR), seguiti dai criteri di informazione di
	Akaike (AIC), Schwartz (BIC) e Hannan&ndash;Quinn (HQC). Il
	test LR confronta la specificazione di ogni riga con qualla
	precedente, sotto l'ipotesi che i parametri dell'ultimo
	ritardo siano tutti 0.
      </para>
      <para>
	L'idea è che questa tabella possa aiutare nella scelta
	ottimale del numero di ritardi.
      </para>
    </description>

  </command>

  <command name="VAR-omit" section="Tests" context="gui"
	   label="Test per variabili esogene in un VAR">

    <description>
      <para>
	In questa finestra di dialogo è possibile testare l'omissione
	da un VAR di un gruppo di variabili esogene.
      </para>
      <para>
	Viene calcolato un test del rapporto di verosimiglianza sotto
	l'ipotesi nulla che i coefficienti delle variabili indicate
	valgano zero in tutte le equazioni del VAR. Il test si basa
	sulla differenza tra il log-determinante della matrice di
	varianza per il modello non vincolato e per il modello con il
	vincolo che i coefficienti delle variabili indicate valgano
	zero.
      </para>
    </description>

  </command>

  <command name="varlist" section="Dataset" label="Elenca variabili" context="cli">

    <usage>
      <options>
	<option>
	  <flag>--type</flag>
	  <optparm>nometipo</optparm>
	  <effect>tipo di oggetto mostrato</effect>
	</option>
      </options>
    </usage>

    <description>
      <para>
	Di default, mostra un elenco delle variabili disponibili nel
	dataset.  <cmd>list</cmd> e <cmd>ls</cmd> sono sinonimi.
      </para>
      <para>
	L'opzione <opt>type</opt> deve essere seguita dal segno di
	uguale e da una delle seguenti parole chiave:
	<lit>series</lit>, <lit>scalar</lit>, <lit>matrix</lit>,
	<lit>list</lit>, <lit>string</lit>, <lit>bundle</lit> or
	<lit>accessor</lit>. L'effetto è di stampare i nomi di tutti
	gli oggetti di quel certo tipo attualmente definiti.
      </para>
      <para>
	Un caso particolare è dato quando il tipo è
	<lit>accessor</lit>: in questo caso, verrà stampato l'elenco
	delle variabili interne di tipo <quote>accessore</quote>, come
	ad esempio <fncref targ="$nobs"/> e <fncref targ="$uhat"/>
	(indipendentemente dal tipo).
      </para>
    </description>

  </command>

<command name="vartest" section="Tests" label="Differenza delle varianze">

  <usage>
    <altforms>
      <altform><lit>vartest</lit> <repl>x</repl> <repl>y</repl> </altform>
      <altform><lit>vartest</lit> <repl>x</repl> <lit>--split-by=</lit><repl>dummy</repl></altform>
    </altforms>
    <options>
      <option>
	<flag>--quiet</flag>
	<effect>sopprime la stampa dell'output</effect>
      </option>
      <option>
	<flag>--robust</flag>
        <optparm>metodo</optparm>
	<effect>vedi sotto</effect>
      </option>
    </options>
    <examples>
      <example>vartest x y</example>
      <example>meantest x --split-by=d</example>
      <example>meantest x y --robust=median</example>
        <example>meantest x y --robust=trimmed,5</example>
    </examples>
  </usage>

  <description>
    <para context="cli">
      Come uso principale, calcola la statistica <math>F</math> per
      l'ipotesi nulla che le varianze della popolazione per le
      variabili <repl>var1</repl> e <repl>var2</repl> siano uguali e
      mostra il p-value. La statistica test e il p-value sono
      disponibili tramite gli accessori <fncref targ="$test"/> e
      <fncref targ="$pvalue"/>.
    </para>
    <para>
      Ad esempio, il codice seguente
    </para>
    <code>
      open AWM18.gdt
      vartest EEN EXR
      eval $test
      eval $pvalue
    </code>
    <para>
      calcola il test e mostra come usare gli accessori:
    </para>
    <code>
      Equality of variances test
      
      EEN: Number of observations = 192
      EXR: Number of observations = 188
      Ratio of sample variances = 3.70707
      Null hypothesis: The two population variances are equal
      Test statistic: F(191,187) = 3.70707
      p-value (two-tailed) = 1.94866e-18
      
      3.7070716
      1.9486605e-18
    </code>
    <para context="cli">
      Nella sua forma alternativa, con l'opzione <opt>split-by</opt>,
      i campioni le cui varianze vengono testate per l'uguaglianza
      sono due sottoinsiemi della serie <repl>x</repl>, per i quali la
      serie <repl>dummy</repl> assume rispettivamente i valori 0 e 1.
    </para>

    <subhead context="cli">Test robusti</subhead>
    <para context="cli">
      Il test <math>F</math> standard si basa sull'ipotesi di
      normalità e può sovra-rifiutare sostanzialmente se tale
      assunzione è falsa. L'opzione <opt>robust</opt> offre tre
      alternative, come segue:
    </para>
    <ilist context="cli">
      <li>
	<para>
	  Quando <repl>metodo</repl> è uguale a <lit>mean</lit>, si
	  usa il test definito da <cite key="levene60">Levene
	  (1960)</cite>. Si tratta in effetti di un'analisi ANOVA a
	  una via che utilizza le deviazioni assolute dalle rispettive
	  medie campionarie dei dati originali.
	</para>
      </li>
      <li>
	<para>
	  Quando <repl>metodo</repl> è <lit>median</lit>, si usa una
	  variante del test di Levene suggerita da <cite
	  key="brown-forsythe">Brown e Forsythe (1974)</cite>, in cui
	  la centratura iniziale utilizza la mediana campionaria
	  anziché la media. Questa opzione è consigliata se i dati
	  sono fortemente asimmetrici. </para>
      </li>
      <li>
	<para>
	  Quando <repl>metodo</repl> è <lit>trimmed</lit>, si usa una
	  seconda variante dovuta a Brown e Forsythe, in cui il
	  centraggio è relativo a una media <i>trimmed</i>. Questa
	  opzione può essere preferibile se i dati sono leptocurtici
	  ma abbastanza simmetrici. Per default, si utilizza un
	  <i>trimming</i> del 10 per cento (ovvero, il 10 per cento
	  più piccolo e il 10 per cento più grande delle osservazioni
	  vengono omessi quando si calcola la media), ma questo può
	  essere regolato aggiungendo una virgola e un valore intero,
	  come in <opt>robust=trimmed,5</opt> che specifica il taglio
	  del 5 percento.
	</para>
      </li>
    </ilist>    
    <para context="gui">
	Calcola la statistica <math>F</math> per l'ipotesi nulla
	che le varianze della popolazione per le variabili selezionate
	siano uguali e mostra il p-value.
      </para>
    </description>

    <gui-access>
      <menu-path>/Strumenti/Calcola test</menu-path>
    </gui-access>

  </command>

  <command name="vecm" section="Estimation"
	   label="Modello vettoriale a correzione d'errore">

    <usage>
      <arguments>
	<argument>ordine</argument>
	<argument>rango</argument>
	<argument>lista-y</argument>
	<argblock optional="true" separated="true">
	  <argument>lista-x</argument>
	</argblock>
	<argblock optional="true" separated="true">
	  <argument>lista-rx</argument>
	</argblock>
      </arguments>
      <options>
	<option>
	  <flag>--nc</flag>
	  <effect>senza costante</effect>
	</option>
	<option>
	  <flag>--rc</flag>
	  <effect>costante vincolata</effect>
	</option>
        <option>
	  <flag>--uc</flag>
	  <effect>costante non vincolata</effect>
        </option>
	<option>
	  <flag>--crt</flag>
	  <effect>costante e trend vincolato</effect>
	</option>
	<option>
	  <flag>--ct</flag>
	  <effect>costante e trend non vincolato</effect>
	</option>
	<option>
	  <flag>--seasonals</flag>
	  <effect>include dummy stagionali centrate</effect>
	</option>
        <option>
	  <flag>--quiet</flag>
	  <effect>omette l'output delle singole equazioni</effect>
        </option>
        <option>
	  <flag>--silent</flag>
	  <effect>non stampa nulla</effect>
        </option>
	<option>
	  <flag>--impulse-responses</flag>
	  <effect>mostra impulso-risposta</effect>
	</option>
	<option>
	  <flag>--variance-decomp</flag>
	  <effect>mostra decomposizioni della varianza delle previsioni</effect>
	</option>
      </options>
      <examples>
	<example>vecm 4 1 Y1 Y2 Y3</example>
	<example>vecm 3 2 Y1 Y2 Y3 --rc</example>
	<example>vecm 3 2 Y1 Y2 Y3 ; X1 --rc</example>
	<demos>
	  <demo>denmark.inp</demo>
	  <demo>hamilton.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Un VECM è un tipo di autoregressione vettoriale, o VAR (si
	veda <cmdref targ="var"/>), applicabile quando le variabili
	del modello sono individualmente integrate di ordine 1 (ossia,
	sono <quote>random walk</quote> con o senza deriva), ma
	esibiscono cointegrazione. Questo comando è strettamente
	connesso al test di Johansen per la cointegrazione (si veda
	<cmdref targ="johansen"/>).
      </para>
      <para context="cli">
	Il parametro <repl>ordine</repl> rappresenta l'ordine di ritardo del
	sistema VAR. Il numero di ritardi nel VECM (dove la variabile dipendente
	è data da una differenza prima) è pari a <repl>ordine</repl> meno uno.
      </para>
      <para context="gui">
	L'ordine di ritardo selezionato nella finestra di dialogo del VECM è
	quello del sistema VAR.  Per ottenere il numero di ritardi nel VECM
	(dove la variabile dipendente è data da una differenza prima) occorre
	sottrarre uno da questo numero.
      </para>
      <para context="cli">
	Il parametro <repl>rango</repl> rappresenta il rango di cointegrazione,
	o in altre parole il numero di vettori di cointegrazione. Questo deve
	essere maggiore di zero e minore o uguale (in genere minore) al numero
	di variabili endogene contenute nella <repl>lista-y</repl>.
      </para>
      <para context="gui">
	Il <quote>rango di cointegrazione</quote> rappresenta il numero di
	vettori di cointegrazione. Questo deve essere maggiore di zero e minore
	o uguale (in genere minore) al numero di variabili endogene selezionate.
      </para>
      <para context="cli">
	La <repl>lista-y</repl> rappresenta l'elenco delle variabili
	endogene, nei livelli. L'inclusione di trend deterministici nel modello
	è controllata dalle opzioni del comando. Se non si indica alcuna
	opzione, viene inclusa una <quote>costante non vincolata</quote>, che
	permette la presenza di un'intercetta diversa da zero nelle relazioni di
	cointegrazione e di un trend nei livelli delle variabili endogene. Nella
	letteratura originata dal lavoro di Johansen (si veda ad esempio il suo
	libro del 1995), si fa riferimento a questo come al <quote>caso
	3</quote>.  Le prime quattro opzioni mostrate sopra, che sono
	mutualmente esclusive, producono rispettivamente i casi 1, 2, 4 e 5. Il
	significato di questi casi e i criteri per scegliere tra di essi sono
	spiegati nel<guideref targ="chap:vecm"/>.
      </para>
      <para context="cli">
	Le liste opzionali <repl>xlist</repl> e <repl>rxlist</repl>
	permottoni di specificare delle variabili esogene che entrano
	nel modello senza vincoli (<repl>xlist</repl>) o solo nello
	spazio di cointegrazione (<repl>rxlist</repl>). Queste liste
	sono separate da <repl>ylist</repl> e fra loro tramite punto e
	virgola.
      </para>
      <para context="gui">
	Nel riquadro <quote>Variabili endogene</quote>, è possibile selezionare
	il vettore delle variabili endogene, in livelli. L'inclusione di trend
	deterministici nel modello è controllata dai pulsanti opzionali.  Se non
	si seleziona alcuna opzione, viene inclusa una <quote>costante non
	vincolata</quote>, che permette la presenza di un'intercetta diversa da
	zero nelle relazioni di cointegrazione e di un trend nei livelli delle
	variabili endogene. Nella letteratura originata dal lavoro di Johansen
	(si veda ad esempio il suo libro del 1995), si fa riferimento a questo
	come al <quote>caso 3</quote>.  Le altre quattro opzioni producono
	rispettivamente i casi 1, 2, 4 e 5. Il significato di questi casi e i
	criteri per scegliere tra di essi sono spiegati nel<guideref
	targ="chap:vecm"/>.
      </para>
      <para context="gui">
	Nel riquadro <quote>Variabili esogene</quote> è possibile aggiungere
	specifiche variabili esogene. Per impostazione predefinita, le variabili
	vengono aggiunte al modello in forma non vincolata (indicata da una
	lettera <lit>N</lit> vicino al nome della variabile). Se si vuole che
	una certa variabile esogena sia vincolata allo spazio di cointegrazione,
	basta fare clic col tasto destro e selezionare <quote>Vincolata</quote>
	dal menu pop-up. Il simbolo vicino alla variabile diventerà una V.
      </para>
      <para context="cli">
	L'opzione <opt>seasonals</opt>, che può accompagnare una qualsiasi
	delle altre opzioni, specifica l'inclusione di un gruppo di variabili
	dummy stagionali centrate. Questa opzione è disponibile solo per dati
	trimestrali o mensili.
      </para>
      <para context="gui">
	Se i dati sono trimestrali o mensili, è presente anche una casella che
	permette di includere un gruppo di variabili dummy stagionali centrate.
	In tutti i casi, la casella <quote>Mostra dettagli</quote> permette di
	vedere il risultato delle regressioni ausiliarie che sono il punto di
	partenza per la procedura di stima di massima verosimiglianza di
	Johansen.
      </para>
      <para context="cli">
	Il primo degli esempi mostrati sopra specifica un VECM con ordine di
	ritardo pari a 4 e un unico vettore di cointegrazione. Le variabili
	endogene sono <lit>Y1</lit>, <lit>Y2</lit> e <lit>Y3</lit>. Il secondo
	esempio usa le stesse variabili ma specifica un ritardo di ordine 3 e
	due vettori di cointegrazione, oltre a specificare una <quote>costante
	vincolata</quote>, che è appropriata se i vettori di cointegrazione
	possono avere un'intercetta diversa da zero, ma le variabili
	<lit>Y</lit> non hanno trend.
      </para>
      <para context="cli">
	Dopo la stima di un VECM sono disponibili alcuni accessori
	specializzati: <lit>$jalpha</lit>, <lit>$jbeta</lit> e
	<lit>$jvbeta</lit> contengono, rispettivamente, le matrici &agr; e &bgr;
	e la varianza stimata di &bgr;.  Per accedere a una specifica
	funzione di risposta di impulso in forma matriciale, si veda
	la funzione <fncref targ="irf"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Serie storiche/VECM</menu-path>
    </gui-access>

  </command>

  <command name="vif" section="Tests" context="cli"
	   label="Fattori di inflazione della varianza">

    <usage>
      <options>
	<option>
	  <flag>--quiet</flag>
	  <effect>soppprime la stampa dei risultati</effect>
	</option>
      </options>
      <examples>
	<demos>
	  <demo>longley.inp</demo>
	</demos>
      </examples>
    </usage>

    <description>
      <para>
	Deve seguire la stima di un modello che includa almeno due variabili
	indipendenti. Calcola e mostra i informazioni diagnostiche
	relative alla collinearità
      </para>
      <para>
	Il VIF per il regressore <math>j</math> è definito come
	<equation status="display" tex="\[\frac{1}{1-R_j^2}\]"
		  ascii="1/(1 - Rj^2)" graphic="vif"/> dove
	<math>R</math><sub>j</sub> è il coefficiente di correlazione
	multipla tra il regressore <math>j</math> e gli altri
	regressori. Il fattore ha un valore minimo di 1.0 quando la
	variabile in questione è ortogonale alle altre variabili
	indipendenti.  <cite key="neter-etal90">Neter, Wasserman, e
	Kutner (1990)</cite> suggeriscono di usare il VIF maggiore
	come test diagnostico per la collinearità; un valore superiore
	a 10 è in genere considerato indice di un grado di
	collinearità problematico.
      </para>
      <para>
	Dopo l'esecusione di questo comando, l'accessore <fncref
	targ="$result"/> conterrà un vetttore colonna con glil indici
	VIF. Per un approccio più sofisticato alla diagnosi della
	collinearità, si vedia il comando  <cmdref targ="bkw"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>Finestra del modello, /Test/collinearità</menu-path>
    </gui-access>

  </command>

  <command name="wls" section="Estimation" label="Minimi quadrati ponderati">

    <usage>
      <arguments>
	<argument>variabile-pesi</argument>
	<argument>variabile-dipendente</argument>
	<argument>variabili-indipendenti</argument>
    </arguments>
    <options>
      <option>
	<flag>--vcv</flag>
	<effect>mostra la matrice di covarianza</effect>
      </option>
      <option>
	<flag>--robust</flag>
	<effect>errori standard robusti</effect>
      </option>
      <option>
	<flag>--quiet</flag>
	<effect>non mostra i risultati</effect>
      </option>
       <option>
         <flag>--allow-zeros</flag>
         <effect>vedi sotto</effect>
       </option>
    </options>
  </usage>

  <description>
    <para context="cli">
      Calcola stime con minimi quadrati ponderati (WLS - Weighted Least
      Squares), prendendo i pesi da <repl>variabile-pesi</repl>.
      In pratica, detta <repl>w</repl> la radice quadrata positiva della
      <lit>variabile-pesi</lit>, viene calcolata una regressione OLS di
      <repl>w</repl> <lit>*</lit> <repl>variabile-dipendente</repl> rispetto a
      <repl>w</repl> <lit>*</lit> <repl>variabili-indipendenti</repl>.
      L'<emphasis>R</emphasis>-quadro, comunque, è calcolato in un modo
      speciale, ossia come
      <equation status="display"
		tex="\[R^2 = 1 - \frac{\rm ESS}{\rm WTSS}\]"
		ascii="R^2 = 1 - ESS / WTSS"
		graphic="wlsr2"/>
      dove ESS è la somma dei quadrati degli residui dalla regressione
      ponderata, mentre WTSS denota la <quote>somma totale ponderata
      dei quadrati</quote>, che è pari alla somma dei quadrati dei
      residui della regressione della variabile dipendente ponderata
      sulla sola costante ponderata.
    </para>
    <para>
      Nel caso particolare in cui <repl>variabile-pesi</repl> sia una
      variabile dummy, la stima WLS equivale a una stima OLS in cui
      tutte le osservazioni per cui essa vale zero sono eliminate. In
      tutti gli altri casi, la presenza di zeri nella variabile di
      ponderazione è considerata un errore, ma se per qualche motivo
      si desidera ponderare per una variabile che contenga degli zeri,
      si può disattivare tale errore usando l'opzione
      <opt>allow-zeros</opt>.
    </para>
    <para context="cli">
      Per la stima con minimi quadrati ponderati in un contesto panel,
      in cui i pesi sono basati sulle varianze delle unità
      longitudinali, si veda il comando  <cmdref targ="panel"/> con
      l'opzione <opt>unit-weights</opt> option.
    </para>
    <para context="gui">
      Detta "variabile-pesi" la variabile scelta nel campo "Variabile
      pesi", viene stimata una regressione OLS in cui la variabile
      dipendente è il prodotto della variabile dipendente selezionata
      e della radice quadrata della variabile-pesi, e anche le
      variabili indipendenti sono moltiplicate per la radice quadrata
      della variabile-pesi.  Le statistiche della regressione, come
      l'<emphasis>R</emphasis>-quadro sono basate sui dati
      ponderati. Se la variabile-pesi è una variabile dummy, ciò
      equivale a eliminare tutte le osservazioni per cui essa vale
      zero.
    </para>
    </description>

    <gui-access>
      <menu-path>/Modello/Altri modelli lineari/WLS - Minimi quadrati ponderati</menu-path>
    </gui-access>

  </command>

  <command name="workdir" section="Utilities" label="Directory di lavoro"
	   context="gui">

    <description>
      <para>
	La <quote>directory di lavoro</quote> è quella usata da gretl
	in modo predefinito nelle operazioni di letura o scrittura di
	file di dati o comandi, usando i comandi Apri e Salva.
	Inoltre, la directory di lavoro è usata anche per:
      </para>
      <ilist>
	<li>
          <para>
            leggere i file attraverso i comandi <lit>append</lit>,
            <lit>open</lit>, <lit>run</lit> e <lit>include</lit>;
          </para>
	</li>
	<li>
          <para>
            scrivere i file attraverso i comandi <lit>eqnprint</lit>,
            <lit>tabprint</lit>, <lit>gnuplot</lit>, <lit>outfile</lit>
            e <lit>store</lit>.
          </para>
	</li>
      </ilist>
      <para>
	La directory di lavoro può essere settata in due modi: o via
	la finestra di dialogo che comapre cliccando <quote>Directory
	di lavoro</quote> nel menu File, oppure usando il comando
	<cmdref targ="set"/>, come ad esempio
      </para>
      <code>
	set workdir /path/to/somewhere
      </code>
      <para>
	Il valore attuale della variabile <lit>workdir</lit> si può
	vedere o nella finestra di dialogo di cui sopra, oppure dando
	il comando
      </para>
      <code>
	eval $workdir
      </code>
      <para>
	Il valore predefinito di <lit>workdir</lit> viene preservato
	fra una sessione e un'altra. Se però si preferisce avviare
	gretl da un terminale testuale invece che da un menù o icona,
	può essere utile l'opzione che permette di usare la directory
	attuale (determinata dalla shell) al momento dell'avvio del
	programma. Quest'opzione può essere selezionata nelle
	Preferenza, oppure attraverso il comando
      </para>
      <code>
	set use_cwd on
      </code>
      <para>
	(<quote>cwd</quote> = current working directory).
      </para>
      <para>
	Nella finestra di dialogo per la directory di lavoro dialog è
	anche possibile settare il comportamento del selettore di file
	GUI: quando si apre o si salva un file da una certa cartella,
	quella cartella può rimanere in memoria o meno alla prossima
	invocazione.
      </para>
    </description>

    <gui-access>
      <menu-path>/File/Directory di lavoro</menu-path>
    </gui-access>

  </command>

  <command name="x12a" section="Utilities" context="gui"
	   label="X-12-ARIMA">

    <description>
      <para>
	Qui ci sono duo opzioni procedurali, controllate dal set
	inferiore di bottoni radio.
      </para>
      <para>
	Selezionando <quote>Esegui X-12-ARIMA direttamente</quote>
	gretl scriverà un file di comandi per X-12-ARIMA e chiamerà il
	programmma x12aper eseguirli. In questo caso, è possibile
	produrre un grafico e/o salvare le serie di output nel dataset
	di gretl.
      </para>
      <para>
	Selezionando invece <quote>Scrivi file di comandi
	X-12-ARIMA</quote> gretl scriverà un file di comandi per
	X-12-ARIMA, come sopra, ma poi questo file verrà aperto in una
	finestra di editor, così da poter apportare modifiche e
	salvarlo col nome voluto. Sarà anche possibile mandarlo in
	esecuzione con x12a (cliccando il bottone <quote>Run</quote>
	sulla barra degli strumenti dell'editor) e visualizzarne
	l'output. In questo caso, tuttavia, non c'è possibilità di
	salvare i dati prodotti o di di produrre grafici.
      </para>
    </description>
  </command>

  <command name="xcorrgm" section="Statistics" label="Correlogramma incrociato">

    <usage>
      <arguments>
	<argument>var1</argument>
	<argument>var2</argument>
	<argument optional="true">maxlag</argument>
      </arguments>
      <options>
	<option>
	  <flag>--plot</flag>
	  <optparm>mode-or-filename</optparm>
	  <effect>vedi sotto</effect>
	</option>
        <option>
	  <flag>--silent</flag>
	  <effect>sopprime l'output</effect>
        </option>
      </options>
      <examples>
	<example>xcorrgm x y 12</example>
      </examples>
    </usage>

    <description>
      <para>
	Mostra il correlogramma incrociato per le variabili
	<repl>var1</repl> e <repl>var2</repl>, che possono essere
	specificate per nome o per numero. I valori sono i
	coefficienti di correlazione campionari tra il valore presente
	di <repl>var1</repl> e i valori ritardati e anticipati di
	<repl>var2</repl>.
      </para>
      <para>
	Se si indica un valore <repl>maxlag</repl>, la lunghezza del
	correlogramma è limitata al numero di ritardi e anticipi
	indicati, altrimenti è determinata automaticamente in funzione
	della frequenza dei dati e del numero di osservazioni.
      </para>
      <para>
	Di default, viene prodotto un grafico del correlogramma
	incrociato: un grafico gnuplot in modo interattivo o un
	grafico ASCII in modalità batch. Questo comportamento può
	essere aggiustato con l'opzione <opt>plot</opt>. Per essa, i
	valori accettabili dei parametri sono <lit>none</lit> (pr
	sopprimere il grafico); <lit>ascii</lit> (per produrre un
	grafico testuale anche se in modo interattivo);
	<lit>display</lit> (per produrre un grafico gnuplot anche se
	in modo batch), o il nome di un file. L'effetto di
	quest'ultima scelta è identico a quello descritto sotto
	l'opzione <opt>output</opt> del comando <cmdref
	targ="gnuplot"/>.
      </para>
    </description>

    <gui-access>
      <menu-path>/Visualizza/Correlogramma</menu-path>
      <other-access>Menù pop-up nella finestra principale (selezione multipla)</other-access>
    </gui-access>
  </command>

  <command name="xtab" section="Statistics" label="Tabulazione incrociata">
    <usage>
      <arguments>
	<argument>lista-y</argument>
	<argument optional="true" separated="true">lista-x</argument>
      </arguments>
      <options>
	<option>
	  <flag>--row</flag>
	  <effect>mostra le percentuali per riga</effect>
	</option>
	<option>
	  <flag>--column</flag>
	  <effect>mostra le percentuali per colonna</effect>
	</option>
	<option>
	  <flag>--zeros</flag>
	  <effect>mostra i valori pari a zero</effect>
	</option>
	<option>
	  <flag>--no-totals</flag>
	  <effect>elimina la stampa delle marginali</effect>
	</option>
	<option>
	  <flag>--matrix</flag>
	  <optparm>matname</optparm>
	  <effect>usa le frequenze da una matrice</effect>
	</option>
	<option>
	  <flag>--quiet</flag>
	  <effect>vedi il caso bivariato più sotto</effect>
	</option>
	<option>
	  <flag>--tex</flag>
	  <optparm optional="true">nomefile</optparm>
	  <effect>produce output &latex;</effect>
	</option>
	<option>
	  <flag>--equal</flag>
	  <effect>vedi il caso &latex; più sotto</effect>
	</option>
      </options>
      <examples>
	<example>xtab 1 2</example>
	<example>xtab 1 ; 2 3 4</example>
	<example>xtab --matrix=A</example>
	<example>xtab 1 2 --tex="xtab.tex"</example>
      </examples>
      <demos>
	<demo>ooballot.inp</demo>
      </demos>
    </usage>

    <description context="cli">
      <para>
	Mostra la tabella di contingenza, o la tabulazione incrociata,
	tra ogni combinazione delle variabili della
	<repl>lista-y</repl>; se si indica anche una seconda lista,
	<repl>lista-x</repl>, ogni variabile della
	<repl>lista-y</repl> viene tabulata (per riga) rispetto ad
	ogni variabile della <repl>lista-x</repl> (per colonna). Le
	variabili in queste liste possono essere referenziate per nome
	o per numero, e devono essere state marcate come
	discrete. Alternativamente, con l'opzione <opt>matrix</opt>,
	la matrice specificata verrà trattata come un insieme di
	frequenze già calcolate e il comando si limiterà a stamparla
	col formato appropriato (vedi anche la funzione <fncref
	targ="mxtab"/>). In questo caso, gli argomenti di tipo lista
	vanno omessi.
      </para>
      <para>
	Per impostazione predefinita le celle indicano la frequenza
	assoluta.  Le opzioni <opt>row</opt> e <opt>column</opt> (che
	sono mutualmente esclusive) sostituiscono la frequenza
	assoluta con le frequenze in percentuale relativamente a
	ciascuna riga o colonna. Le celle con valore di frequenza
	nullo sono lasciate vuote, a meno che non venga usata
	l'opzione <opt>zeros</opt>, che mostra esplicitamente i valori
	pari a zero; questa opzione può essere comoda se occorre
	importare la tabella in un altro programma, come un foglio di
	calcolo.
      </para>
      <para>
	Il test chi quadro di Pearson per l'indipendenza viene
	mostrato se la frequenza attesa nell'ipotesi di indipendenza è
	pari almeno a 1.0e-7 per tutte le celle. Una regola
	approssimativa usata spesso nel giudicare la validità di
	questa statistica richiede che la frequenza attesa sia
	superiore a 5 per almeno l'80 per cento delle celle; se questa
	condizione non viene soddisfatta viene mostrato un messaggio
	di avvertimento.
      </para>
      <para>
	Se la tabella di contingenza è 2 x 2, viene calcolato il test
	esatto di Fisher per l'indipendenza. Si noti che questo test
	si basa sull'ipotesi che i totali per riga e colonna siano
	fissi; questo può essere appropriato o meno a seconda di come
	sono stati generati i dati.  Il p-value sinistro va usato nel
	caso in cui l'ipotesi alternativa a quella di indipendenza sia
	quella dell'associazione negativa (ossia i valori tendono ad
	accumularsi nelle celle che non appartengono alla diagonale
	della tabella), mentre il p-value destro va usato nell'ipotesi
	alternativa di associazione positiva. Il p-value a due code di
	questo test è calcolato seguendo il metodo (b) descritto in
	<cite key="agresti92">Agresti (1992)</cite>, (capitolo 2.1):
	esso è la somma delle probabilità di tutte le possibili
	tabelle che hanno i totali per riga e per colonna pari a
	quelli della tabella data e che hanno una probabilità minore o
	uguale a quella della tabella data.
      </para>

      <subhead>Il caso bivariato</subhead>
      <para>
	Nel caso base di una semplice tabella a doppia entrata, la
	tabella è accessibile tramite l'accessore <fncref
	targ="$result"/>, e si possono usare gli accessori <fncref
	targ="$test"/> e <fncref targ="$pvalue"/> per il test
	chi-quadro di Pearson ed il p-value corrispondente, a patto
	che sia rispettata la condizione sul valore atteso minimo. In
	questo contesto, l'opzione <opt>quiet</opt> fa sì che la
	tavola non venga stampata.
      </para>

      <subhead>&latex; output</subhead>
      <para>
	Dando l'opzione <opt>tex</opt>, la tabella a doppia entrata
	viene stampata sotto forma di un ambiente <lit>tabular</lit>
	di &latex;. L'output verrà prodotto direttamente (così da
	poterlo copincollare) o, se viene specificato il parametro
	<repl>nomefile</repl>, nel file corrispondente. (Se
	<repl>nomefile</repl> non contiene un percorso completo, il
	file sarà scritto nella locazione <cmdref targ="workdir"/>
	attuale). la statistica test non viene calcolata. L'opzione
	addizionale <opt>equal</opt> viene usata per far sì che
	venganp stampati in grassetto gli elementi della tabella per
	cui le variabili riga e colonna hanno lo stesso valore
	numerico. Quest'opzione è ignorata a se non è presente anche
	l'opzione <opt>tex</opt> o quando una delle due variabili sia
	di tipo stringa.
      </para>
    </description>
    <description context="gui">
      <para>
	Mostra la tabella di contingenza, o la tabulazione incrociata,
	tra ogni combinazione delle variabili selezionate. Si noti che
	tutte le variabili devono essere discrete.
      </para>
      <para>
	Per impostazione predefinita le celle indicano la frequenza
	assoluta, ma è possibile scegliere di avere le percentuali
	relative alle righe o alle colonne.
      </para>
      <para>
	Inoltre, le celle con un valore di frequenza nullo sono
	lasciate vuote, ma è possibile scegliere di avere i valori
	pari a zero esplicitamente.
      </para>
      <para>
	Il test chi quadro di Pearson per l'indipendenza viene
	mostrato se la frequenza attesa nell'ipotesi di indipendenza è
	pari almeno a 1.0e-7 per tutte le celle. Una regola
	approssimativa usata spesso nel giudicare la validità di
	questa statistica richiede che la frequenza attesa sia
	superiore a 5 per almeno l'80 per cento delle celle; se questa
	condizione non viene soddisfatta viene mostrato un messaggio
	di avvertimento.
      </para>
      <para>
	Se la tabella di contingenza è 2 x 2, viene calcolato il test
	esatto di Fisher per l'indipendenza. Si noti che questo test
	si basa sull'ipotesi che i totali per riga e colonna siano
	fissi; questo può essere appropriato o meno a seconda di come
	sono stati generati i dati.  Il p-value sinistro va usato nel
	caso in cui l'ipotesi alternativa a quella di indipendenza sia
	quella dell'associazione negativa (ossia i valori tendono ad
	accumularsi nelle celle che non appartengono alla diagonale
	della tabella), mentre il p-value destro va usato nell'ipotesi
	alternativa di associazione positiva. Il p-value a due code di
	questo test è calcolato seguendo il metodo (b) descritto in
	<cite key="agresti92">Agresti (1992)</cite>, capitolo 2.1:
	esso è la somma delle probabilità di tutte le possibili
	tabelle che hanno i totali per riga e per colonna pari a
	quelli della tabella data e che hanno una probabilità minore o
	uguale a quella della tabella data.
      </para>
    </description>

  </command>

</commandref>
