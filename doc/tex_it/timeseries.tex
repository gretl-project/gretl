\chapter{Modelli per serie storiche}
\label{chap:timeser}

\section{Introduzione}
\label{sec:tsintro}

Questo capitolo e il successivo discutono i modelli per serie storiche.
Questo capitolo si concentra sui modelli ARIMA, i test per radici unitarie
e i modelli GARCH, mentre il successivo tratta la cointegrazione e i modelli
a correzione d'errore.

\section{Modelli ARIMA}
\label{arma-estimation}

\subsection{Rappresentazione e sintassi}
\label{arma-repr}

Il comando \cmd{arma} effettua la stima di modelli autoregressivi integrati a media mobile
(ARIMA). Questi modelli possono essere scritti come
\begin{equation}
  \label{eq:plain-0-arma}
  \phi(L) y_t = \theta(L) \epsilon_t
\end{equation}
dove $\phi(L)$ e $\theta(L)$ sono polinomi nell'operatore ritardo, $L$, definito
in modo che $L^n x_t = x_{t-n}$, e $\epsilon_t$ è un processo di rumore bianco.
Il contenuto esatto di $y_t$, del polinomio AR $\phi()$ e del polinomio MA $\theta()$
verrà spiegato in seguito.

\subsection{Media del processo}
\label{sec:arma-nonzeromean}

Il processo $y_t$ mostrato nell'equazione (\ref{eq:plain-0-arma}) ha
media zero, se non si danno altre indicazioni. Se il modello deve essere
applicato a dati reali, è necessario includere un termine per gestire la
possibilità che $y_t$ abbia una media diversa da zero.
Ci sono due modi possibili per rappresentare processi con media nulla: uno
consiste nel definire $\mu_t$ come la media \emph{non condizionale} di $y_t$,
ossia il valore centrale della sua distribuzione marginale.
Quindi, la serie $\tilde{y}_t = y_t - \mu_t$ ha media 0, e il modello
(\ref{eq:plain-0-arma}) si applica a $\tilde{y}_t$. In pratica, assumendo che
$\mu_t$ sia una funzione lineare di alcune variabili osservabili $x_t$,
il modello diventa
\begin{equation}
  \label{eq:arma-with-x}
  \phi(L) (y_t - x_t \beta) = \theta(L) \epsilon_t
\end{equation}
Questo viene talvolta chiamato un ``modello di regressione con errori ARMA'';
la sua struttura può risultare più chiara se lo rappresentiamo usando due
equazioni:
\begin{eqnarray*}
  y_t & = & x_t \beta + u_t \\
  \phi(L) u_t & = & \theta(L) \epsilon_t
\end{eqnarray*}

Il modello appena presentato viene talvolta chiamato ``ARMAX'' (ARMA + variabili
esogene), anche se questo nome sembra più appropriato per un altro tipo di
modello: un altro modo per includere un termine di media nella
(\ref{eq:plain-0-arma}) consiste nel basare la rappresentazione sulla media
\emph{condizionale} di $y_t$, ossia il valore centrale della distribuzione di
$y_t$ \emph{dato il proprio passato}. Assumendo, ancora, che questa possa essere
rappresentata come combinazione lineare di qualche variabile osservabile
$z_t$, il modello diventerebbe
\begin{equation}
  \label{eq:arma-with-z}
  \phi(L) y_t = z_t \gamma + \theta(L) \epsilon_t
\end{equation}
La formulazione (\ref{eq:arma-with-z}) ha il vantaggio che $\gamma$
può essere immediatamente interpretato come il vettore degli effetti marginali
delle variabili $z_t$ sulla media condizionale di $y_t$.  E aggiungendo i
ritardi di $z_t$ a questa specificazione è possibile stimare dei \emph{modelli
di funzione di trasferimento} (che generalizzano gli ARMA aggiungendo gli effetti
delle variabili esogene distribuiti nel tempo).

\app{Gretl} fornisce un modo per stimare entrambe le forme. I modelli scritti
come nella (\ref{eq:arma-with-x}) vengono stimati con la massima
verosimiglianza; i modelli scritti come nella (\ref{eq:arma-with-z}) vengono
stimati con la massima verosimiglianza condizionale (per maggiori informazioni
su queste opzioni, si veda la sezione ``Stima'' in seguito).

Nel caso speciale in cui $x_t = z_t = 1$ (ossia il modello include una costante
ma nessuna variabile esogena) le due specificazioni discusse finora diventano
\begin{equation}
  \phi(L) (y_t - \mu) = \theta(L) \epsilon_t
  \label{eq:arma-with-xconst} 
\end{equation}
e
\begin{equation}
  \phi(L) y_t = \alpha + \theta(L) \epsilon_t
  \label{eq:arma-with-zconst}
\end{equation}
rispettivamente. Queste formulazioni sono essenzialmente equivalenti, ma se
rappresentano lo stesso processo, ovviamente $\mu$ e $\alpha$ non sono
numericamente identici; piuttosto:
\[
\alpha = \left(1 - \phi_1 - \ldots - \phi_p\right) \mu
\]

La sintassi di \app{gretl} per stimare la (\ref{eq:arma-with-xconst}) è
semplicemente
\begin{code}
arma p q ; y
\end{code}
Gli ordini di ritardo AR e MA, \verb|p| e \verb|q|, possono essere indicati come
numeri o come scalari definiti in precedenza. Il parametro $\mu$ può essere
omesso se necessario, aggiungendo l'opzione \cmd{--nc} (``no constant'') al
comando. Se occorre stimare la (\ref{eq:arma-with-zconst}), bisogna aggiungere
al comando l'opzione \texttt{--conditional}, come in
\begin{code}
arma p q ; y --conditional
\end{code}

Generalizzando questo principio alla stima della
(\ref{eq:arma-with-x}) o della (\ref{eq:arma-with-z}), si ottiene che
\begin{code}
arma p q ; y const x1 x2
\end{code}
stimerebbe il modello seguente:
\[
  y_t - x_t \beta = \phi_1 \left(y_{t-1} - x_{t-1} \beta \right) + \ldots + 
   \phi_p \left( y_{t-p} - x_{t-p} \beta \right) + 
  \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}
\]
dove in questo caso $x_t \beta = \beta_0 + x_{t,1} \beta_1 +
x_{t,2} \beta_2$. 

Usando l'opzione \texttt{--conditional}, come in
\begin{code}
arma p q ; y const x1 x2 --conditional
\end{code}
si stimerebbe il modello seguente:
\[
  y_t = x_t \gamma + \phi_1 y_{t-1} + \ldots +  \phi_p y_{t-p} + 
  \epsilon_t + \theta_1 \epsilon_{t-1} + \ldots + \theta_q \epsilon_{t-q}
\]

Idealmente, la situazione descritta finora potrebbe essere sistematizzata
scrivendo una specificazione più generale che comprende tutte le alternative,
ossia
\begin{equation}
 \label{armax-general}
  \phi(L) \left(y_t - x_t \beta\right) = z_t \gamma  + \theta(L) \epsilon_t ;
\end{equation}
Una possibile generalizzazione del comando \cmd{arma} permetterebbe all'utente di
specificare se, per ogni metodo di stima, certe variabili
esogene vanno trattate come $x_t$ o come $z_t$, ma non siamo ancora a questo
livello (né lo è la maggior parte degli altri pacchetti software).

\subsection{Modelli stagionali}

Quando si analizzano serie storiche che mostrano un marcato andamento
stagionale, è opportuno usare una struttura di ritardi più flessibile.
Il modello (\ref{eq:plain-0-arma}) può essere espanso nel seguente
\begin{equation}
  \label{eq:seasonal-arma}
  \phi(L) \Phi(L^s) y_t = \theta(L) \Theta(L^s) \epsilon_t .
\end{equation}
In questi casi, è disponibile una versione ampliata della sintassi, ossia:
\begin{code}
arma p q ; P Q ; y
\end{code}
dove \texttt{p} e \texttt{q} rappresentano gli ordini AR e MA non stagionali,
mentre \texttt{P} e \texttt{Q} gli ordini stagionali. Ad esempio
\begin{code}
arma 1 1 ; 1 1 ; y
\end{code}
stima il modello seguente:
\[
  (1 -\phi L)(1 -\Phi L^s) (y_t - \mu) = (1 + \theta L)(1 + \Theta L^s) \epsilon_t
\]
Se $y_t$ è una serie trimestrale (e quindi $s=4$), l'equazione precedente può
essere scritta in modo più esplicito come
\[
y_t - \mu = \phi (y_{t-1} - \mu) + \Phi (y_{t-4} - \mu) - (\phi
  \cdot \Phi) (y_{t-5} - \mu) + \epsilon_t + \theta \epsilon_{t-1} + \Theta
  \epsilon_{t-4} + (\theta \cdot \Theta) \epsilon_{t-5}
\]
Un tale modello è noto come ``modello ARMA stagionale moltiplicativo''.

\subsection{Buchi nella struttura dei ritardi}

Il modo standard di specificare un modello ARMA in \app{gretl} è usando
gli ordini AR e MA, ossia rispettivamente $p$ e $q$. In questo caso vengono
inclusi tutti i ritardi a partire dall'ordine 1 fino all'ordine specificato.
In alcuni casi, occorre includere solo alcuni specifici ritardi AR e/o MA; questo
risultato può essere ottenuto in due modi.
%
\begin{itemize}
\item È possibile costruire una matrice che contiene i ritardi desiderati
  (numeri interi positivi) e fornire il nome della matrice al posto di
  $p$ o $q$.
\item È possibile fornire una lista di ritardi separati da spazi e racchiusi
  tra parentesi graffe, al posto di $p$ o $q$.
\end{itemize}
%
Gli esempi seguenti illustrano le due possibilità:
%
\begin{code}
matrix pvec = {1, 4}
arma pvec 1 ; y
arma {1 4} 1 ; y
\end{code}
%
Entrambi i comandi specificano un modello ARMA in cui vengono usati i ritardi AR
1 e 4, ma non i 2 e 3.

Questo meccanismo è disponibile solo per la componente non stagionale della
specificazione ARMA.

\subsection{Differenziazione e ARIMA}

La discussione svolta finora presuppone che la serie storica $y_t$ sia già stata
soggetta a tutte le trasformazioni ritenute necessarie per assicurarne la
stazionarietà (si veda anche la sezione \ref{sec:uroot}). La differenziazione è
la più comune tra queste trasformazioni, e \app{gretl} fornisce un meccanismo
per includere questo passo nel comando \cmd{arma}: la sintassi
\begin{code}
arma p d q ; y 
\end{code}
stima un modello ARMA$(p,q)$ su $\Delta^d y_t$. È funzionalmente equivalente a
\begin{code}
series tmp = y
loop for i=1..d
  tmp = diff(tmp)
end loop
arma p q ; tmp 
\end{code}
tranne che per quanto riguarda la previsione dopo la stima (si veda oltre).

Quando la serie $y_t$ viene differenziata prima di effettuare l'analisi, il
modello viene chiamato ARIMA (la ``I'' sta per ``Integrato''); per questo
motivo, \app{gretl} fornisce anche il comando \cmd{arima} come alias per
\cmd{arma}.

La differenziazione stagionale è trattata in modo simile, con la sintassi
\begin{code}
arma p d q ; P D Q ; y 
\end{code}
dove \texttt{D} è l'ordine di differenziazione stagionale. Così, il comando
\begin{code}
arma 1 0 0 ; 1 1 1 ; y 
\end{code}
produrrebbe le stesse stime dei parametri date da
\begin{code}
genr dsy = sdiff(y)
arma 1 0 ; 1 1 ; dsy 
\end{code}
dove usiamo la funzione \texttt{sdiff} per creare una differenza stagionale (ad
esempio per dati trimestrali: $y_t - y_{t-4}$).

\subsection{Stima}
\label{arma-est}

Il metodo di stima predefinito per i modelli ARMA è quello della massima
verosimiglianza esatta (sotto l'ipotesi che il termine di errore sia distribuito
normalmente), usando il filtro di Kalman insieme all'algoritmo di
massimizzazione BFGS. Il gradiente della log-verosimiglianza rispetto alle stime
dei parametri è approssimato numericamente. Questo metodo produce risultati che
sono direttamente confrontabili con quelli di molti altri pacchetti software.
La costante ed eventuali altre variabili esogene sono trattate come mostrato
nell'equazione (\ref{eq:arma-with-x}). La matrice di covarianza per i parametri
è calcolata usando un'approssimazione numerica dell'Hessiana alla convergenza.

Il metodo alternativo, utilizzabile con l'opzione \verb|--conditional|, è quello
della massima verosimiglianza condizionale (CML), noto anche come ``somma dei
quadrati condizionale'' (si veda Hamilton 1994, p.\ 132). Questo metodo è stato
esemplificato nello script~\ref{jack-arma} e ne verrà qui data solo una breve
descrizione. Data un'ampiezza campionaria $T$, il metodo CML minimizza
la somma dei quadrati degli errori di previsione ``one-step-ahead'' (per il
periodo successivo) generata dal modello per le osservazioni $t_0, \ldots,
T$. Il punto di partenza $t_0$ dipende dall'ordine dei polinomi AR nel
modello. Il metodo numerico di massimizzazione usato è il BHHH, e la
matrice di covarianza è calcolata usando una regressione di Gauss--Newton.

Il metodo CML è quasi equivalente a quello della massima verosimiglianza in
ipotesi di normalità; la differenza sta nel fatto che le prime $(t_0 - 1)$
osservazioni sono considerate fisse ed entrano nella funzione di verosimiglianza
solo come variabili condizionanti. Di conseguenza, i due metodi sono
asintoticamente equivalenti sotto le consuete ipotesi, tranne per il fatto,
discusso sopra, che la nostra implementazione CML tratta la costante e le
variabili esogene come mostrato nell'equazione (\ref{eq:arma-with-z}).

I due metodi possono essere confrontati nell'esempio seguente
\begin{code}
open data10-1
arma 1 1 ; r
arma 1 1 ; r --conditional
\end{code}
che produce le stime mostrate nella Tabella~\ref{tab:ml-cml}. Come si può
vedere, le stime di $\phi$ e $\theta$ sono abbastanza simili. Le costanti
riportate sono molto diverse, come ci si può aspettare; in proposito,
si veda la discussione delle equazioni (\ref{eq:arma-with-xconst}) e
(\ref{eq:arma-with-zconst}). In ogni caso, dividendo la costante CML per
$1-\phi$ si ottiene 7.38, che non è molto distante dalla stima ML di 6.93.

\begin{table}[htbp]
\caption{Stime ML e CML}
\label{tab:ml-cml}
\begin{center}
  \begin{tabular}{crrrr}
    \hline
    Parametro & \multicolumn{2}{c}{ML} &
    \multicolumn{2}{c}{CML} \\
    \hline 
    $\mu$ & 6.93042 & (0.673202) & 1.07322 & (0.488661) \\
    $\phi$ & 0.855360 & (0.0512026) & 0.852772 & (0.0450252) \\
    $\theta$ & 0.588056 & (0.0809769) & 0.591838 & (0.0456662) \\
    \hline
  \end{tabular}
\end{center}
\end{table}

\subsection{Convergenza e inizializzazione}

I metodi numerici usati per massimizzare la verosimiglianza per i modelli ARMA
non sempre convergono. I valori iniziali dei parametri possono influire sul
raggiungimento della convergenza e sul raggiungimento del vero massimo della
funzione di verosimiglianza. \app{Gretl} utilizza uno dei due seguenti
meccanismi per inizializzare i parametri, a seconda della specificazione del
modello e del metodo di stima scelto.

\begin{enumerate}
\item Stima di un un modello AR puro usando i minimi quadrati (non lineari, se
  il modello lo richiede, altrimenti OLS). Impostazione del parametro AR secondo
  i risultati di questa regressione e impostazione dei parametri MA a un valore
  positivo ma piccolo (0.0001).
\item Il metodo di Hannan--Rissanen: per prima cosa, stima di un modello
  autoregressivo usando OLS e salvataggio dei residui. Quindi stima di un
  secondo modello OLS, aggiungendo appropriati ritardi dei residui della prima
  regressione, per ottenere le stime dei parametri MA.
\end{enumerate}

Per vedere i dettagli della procedura di stima ARMA, basta aggiungere l'opzione
\verb|--verbose| al comando. Verrà mostrato un messaggio sul metodo di
inizializzazione scelto, oltre che i valori dei parametri e della
log-verosimiglianza ad ogni iterazione.

Oltre a questi meccanismi automatici di inizializzazione, l'utente può
specificare manualmente un insieme di valori di partenza, attraverso il comando
\cmd{set}: il primo argomento deve essere la parola chiave
\texttt{initvals}, mentre il secondo dev'essere il nome di una matrice
pre-specificata che contiene i valori iniziali. Ad esempio
\begin{code}
matrix start = { 0, 0.85, 0.34 }
set initvals start
arma 1 1 ; y
\end{code}
La matrice specificata deve avere un numero di parametri pari a quello del
modello: nell'esempio precedente ci sono tre parametri, visto che il modello
contiene implicitamente una costante. La costante, se presente, è sempre
indicata per prima, altrimenti, l'ordine in cui vanno indicati i parametri è lo
stesso della specificazione nel comando \cmd{arma} o \cmd{arima}. Nell'esempio,
la costante è impostata a zero, $\phi_1$ a 0.85 e $\theta_1$ a 0.34.

Per far tornare \app{gretl} ad usare l'inizializzazione automatica, basta
eseguire il comando \cmd{set initvals auto}.

\subsection{Stima con X-12-ARIMA}

In alternativa alla stima di modelli ARMA usando le proprie funzionalità
interne, \app{gretl} offre l'opzione di usare il programma esterno
\app{X-12-ARIMA} per l'aggiustamento stagionale, curato dallo U.S. Census
Bureau.

\app{Gretl} include un modulo che si interfaccia con \app{X-12-ARIMA}:
traduce i comandi \cmd{arma} dalla sintassi vista sopra in una forma riconosciuta
da \app{X-12-ARIMA}, esegue il programma e recupera i risultati per ulteriori
analisi in \app{gretl}. Per usare questa funzionalità, occore installare
\app{X-12-ARIMA} separatamente: sul sito di \app{gretl},
\url{http://gretl.sourceforge.net/}, sono disponibili pacchetti per MS Windows e
GNU/Linux.

Per invocare \app{X-12-ARIMA} come motore di stima, basta usare l'opzione
\verb|--x-12-arima|, come in questo esempio:
\begin{code}
arma p q ; y --x-12-arima
\end{code}
Come accade con le stime effettuate da \app{gretl}, per impostazione predefinita
viene usata la massima verosimiglianza esatta, ma è possibile usare la
massima verosimiglianza condizionale con l'opzione \verb|--conditional|.
Comunque, occorre notare che quando si usa \app{X-12-ARIMA} in modalità di
massima verosimiglianza condizionale, quanto detto sopra a proposito dei
diversi modi di trattare la media del processo $y_t$ \textit{non si applica}.
Ossia, quando si usa \app{X-12-ARIMA} l'equazione stimata è la
(\ref{eq:arma-with-x}), a prescindere dal fatto che la stima sia condotta con la
massima verosimiglianza esatta o condizionale.


\subsection{Previsione}
\label{arma-fcast}

I modelli ARMA sono spesso usati a scopo previsionale. La componente
autoregressiva, in particolare, offre la possibilità di prevedere l'andamento
del processo ``fuori dal campione'' su un certo orizzonte temporale.

\app{Gretl} supporta le previsioni basate su modelli ARMA usando il metodo
illustrato da Box e Jenkins (1976)\footnote{Si veda in particolare il loro
``Programma 4'' alle pagine 505 e seguenti.}. L'algoritmo di Box e Jenkins
produce un insieme di coefficienti AR integrati che tiene conto delle operazioni
di differenziazione (stagionale e/o non stagionale) sulla variabile dipendente
in un contesto ARIMA, rendendo così possibile una previsione per il livello
della variabile originale. Per contrasto, se si differenzia una serie
manualmente e poi si applica ARMA alla serie differenziata, le previsioni
saranno riferite alla serie differenziata, non al suo livello. Questo punto è
illustrato dall'Esempio~\ref{arima-fcast-script}. Le stime dei parametri sono
identiche per i due modelli; le previsioni sono diverse ma coerenti tra loro: la
variabile \texttt{fcdiff} emula la previsione ARMA (statica, per il periodo
successivo all'interno del campione, e dinamica, fuori dal campione).

\begin{script}[htbp]
  \caption{Previsione ARIMA}
  \label{arima-fcast-script}
\begin{scode}
open greene18_2.gdt
# Logaritmo del PIL nominale trimestrale degli USA, da 1950:1 a 1983:4
genr y = log(Y)
# La sua differenza prima
genr dy = diff(y)
# Teniamo 2 anni per la previsione fuori dal campione
smpl ; 1981:4
# Stima con ARIMA
arima 1 1 1 ; y 
# Previsione su tutto il periodo
smpl --full
fcast fc1
# Torniamo al campione ristretto ed eseguiamo ARMA sulla differenza prima di y
smpl ; 1981:4
arma 1 1 ; dy
smpl --full
fcast fc2
genr fcdiff = (t<=1982:1)*(fc1 - y(-1)) + (t>1982:1)*(fc1 - fc1(-1))
# Confronto delle previsioni sull'ultimo periodo
smpl 1981:1 1983:4
print y fc1 fc2 fcdiff --byobs
\end{scode}

Il risultato dell'ultimo comando è:
%
\begin{code}
                  y          fc1          fc2       fcdiff
1981:1      7.964086     7.940930      0.02668      0.02668
1981:2      7.978654     7.997576      0.03349      0.03349
1981:3      8.009463     7.997503      0.01885      0.01885
1981:4      8.015625     8.033695      0.02423      0.02423
1982:1      8.014997     8.029698      0.01407      0.01407
1982:2      8.026562     8.046037      0.01634      0.01634
1982:3      8.032717     8.063636      0.01760      0.01760
1982:4      8.042249     8.081935      0.01830      0.01830
1983:1      8.062685     8.100623      0.01869      0.01869
1983:2      8.091627     8.119528      0.01891      0.01891
1983:3      8.115700     8.138554      0.01903      0.01903
1983:4      8.140811     8.157646      0.01909      0.01909
\end{code}
\end{script}


\section{Test per radici unitarie}
\label{sec:uroot}

\subsection{Il test ADF}
\label{sec:ADFtest}

Il test ADF (Augmented Dickey--Fuller) è implementato in \app{gretl} sotto forma
della statistica $t$ su $\varphi$ nella regressione seguente:
\begin{equation}
  \label{eq:ADFtest}
  \Delta y_t = \mu_t + \varphi y_{t-1} + \sum_{i=1}^p \gamma_i \Delta
  y_{t-i} + \epsilon_t .
\end{equation}

Questa statistica test è probabilmente il più famoso e utilizzato test per
radici unitarie. È un test a una coda la cui ipotesi nulla è
$\varphi = 0$, mentre quella alternativa è $\varphi < 0$. Sotto l'ipotesi nulla,
$y_t$ deve essere differenziata almeno una volta per raggiungere la
stazionarietà. Sotto l'ipotesi alternativa, $y_t$ è già stazionaria e non
richiede differenziazione. Quindi, grandi valori negativi della statistica test
portano a rifiutare l'ipotesi nulla.

Un aspetto peculiare di questo test è che la sua distribuzione limite non è
standard sotto l'ipotesi nulla: inoltre, la forma della distribuzione, e quindi
i valori critici per il test, dipendono dalla forma del termine
$\mu_t$. Un'eccellente analisi di tutti i casi possibili è contenuta in
Hamilton (1994), ma il soggetto è trattato anche in qualsiasi testo recente
sulle serie storiche. Per quanto riguarda \app{gretl}, esso permette all'utente
di scegliere la specificazione di $\mu_t$ tra quattro alternative:

\begin{center}
  \begin{tabular}{cc}
    \hline
    $\mu_t$ & Opzione del comando \\
    \hline
    0 & \verb|--nc| \\
    $\mu_0$ &  \verb|--c| \\
    $\mu_0 + \mu_1 t$ &  \verb|--ct| \\
    $\mu_0 + \mu_1 t + \mu_1 t^2$ &  \verb|--ctt| \\
    \hline
  \end{tabular}
\end{center}

Queste opzioni non sono mutualmente esclusive e possono essere usate insieme; in
questo caso, la statistica verrà calcolata separatamente per ognuno dei casi.
La scelta predefinita in \app{gretl} è quella di usare la combinazione
\verb|--c --ct --ctt|. Per ognuno dei casi, vengono calcolati p-value
approssimativi usando l'algoritmo descritto in MacKinnon 1996.

Il comando di \app{gretl} da usare per eseguire il test è \cmd{adf}; ad esempio
\begin{code}
adf 4 x1 --c --ct
\end{code}
calcola la statistica test come statistica-t per $\varphi$ nell'equazione
\ref{eq:ADFtest} con $p=4$ nei due casi $\mu_t = \mu_0$ e
$\mu_t = \mu_0 + \mu_1 t$.

Il numero di ritardi ($p$ nell'equazione \ref{eq:ADFtest}) deve essere scelto
per assicurarsi che la (\ref{eq:ADFtest}) sia una parametrizzazione abbastanza
flessibile per rappresentare adeguatamente la persistenza di breve termine di
$\Delta y_t$. Scegliere un $p$ troppo basso può portare a distorsioni di
dimensione nel test, mentre sceglierlo troppo alto porta a una perdita di
potenza del test. Per comodità dell'utente, il parametro $p$ può essere
determinato automaticamente. Impostando $p$ a un numero negativo viene attivata
una procedura sequenziale che parte da $p$ ritardi e decrementa $p$ fino a quando la statistica $t$
per il parametro $\gamma_p$ supera 1.645 in valore assoluto.

\subsection{Il test KPSS}
\label{sec:KPSStest}

Il test KPSS (Kwiatkowski, Phillips, Schmidt e Shin, 1992) è un test per radici
unitarie in cui l'ipotesi nulla è l'opposto di quella del test ADF: l'ipotesi
nulla è che la serie sia stazionaria, mentre l'ipotesi alternativa è che la serie
sia $I(1)$.
 
L'intuizione alla base di questa statistica test è molto semplice: se $y_t$ può
essere scritta come $y_t = \mu + u_t$, dove $u_t$ è un qualche processo
stazionario a media nulla, non solo la media campionaria di $y_t$ fornisce uno
stimatore consistente di $\mu$, ma la varianza di lungo periodo di $u_t$ è un
numero finito. Nessuna di queste proprietà è valida nel caso dell'ipotesi
alternativa.
 
Il test si basa sulla seguente statistica:

\begin{equation}
  \label{eq:KPSStest}
  \eta = \frac{\sum_{i=1}^T S_t^2 }{ T^2 \bar{\sigma}^2 }
\end{equation}
dove $S_t = \sum_{s=1}^t e_s$ e $\bar{\sigma}^2$ è una stima della varianza di
lungo periodo di $e_t = (y_t - \bar{y})$. Sotto l'ipotesi nulla, questa
statistica ha una distribuzione asintotica ben definita (non standard), che non
dipende da parametri di disturbo ed è stata tabulata con metodi di simulazione.
Sotto l'ipotesi alternativa, la statistica diverge.

Di conseguenza, è possibile costruire un test a una coda basato su
$\eta$, dove $H_0$ è rifiutata se $\eta$ è maggiore del valore critico
desiderato; \app{gretl} fornisce i quantili del 90\%, 95\%,
97.5\% e 99\%.

Esempio di uso:
\begin{code}
kpss m y
\end{code}
dove \verb|m| è un intero che rappresenta la larghezza di banda, o la dimensione
della finestra usata nella formula per stimare la varianza di lungo periodo:
\[
  \bar{\sigma}^2 = \sum_{i=-m}^m \left( 1 - \frac{|i|}{m+1} \right) \hat{\gamma}_i
\]
I termini $\hat{\gamma}_i$ denotano le autocovarianze empiriche di $e_t$
dall'ordine $-m$ fino al $m$.  Affinché questo stimatore sia consistente, $m$
deve essere abbastanza grande da accomodare la persistenza di breve periodo di
$e_t$, ma non troppo grande se paragonato all'ampiezza campionaria $T$.
Nell'interfaccia grafica di \app{gretl}, il valore predefinito è pari alla parte
intera di $4 \left( \frac{T}{100} \right)^{1/4}$.

Il concetto visto sopra può essere generalizzato al caso in cui $y_t$ è
stazionario attorno a un trend deterministico. In questo caso, la
formula (\ref{eq:KPSStest}) rimane invariata, ma la serie $e_t$ è definita come
residui della regressione OLS di $y_t$ su una costante e un trend lineare.
Questa seconda forma del test si ottiene aggiungendo l'opzione
\verb|--trend| al comando \cmd{kpss}:
\begin{code}
kpss n y --trend
\end{code}
Si noti che in questo caso la distribuzione asintotica del test è diversa, e i
valori critici riportati da \app{gretl} sono corretti di conseguenza.

\subsection{I test di cointegrazione}
\label{sec:coint-test}

FIXME discuss Engle---Granger here, and refer forward to
the next chapter for the Johansen tests.

\section{ARCH e GARCH}
\label{sec:arch-garch}

Il fenomeno dell'eteroschedasticità rappresenta la varianza non costante del
termine di errore in un modello di regressione. L'eteroschedasticità
condizionale autoregressiva (ARCH) è un fenomeno specifico dei modelli per serie
storiche, in cui la varianza del termine di errore presenta un comportamento
autoregressivo, ad esempio, la serie presenta periodi in cui la varianza
dell'errore è relativamente ampia e periodi in cui è relativamente piccola.
Questo tipo di comportamento si verifica spesso sui mercati finanziari: una
notizia inaspettata può provocare periodi di maggior volatilità del mercato.

Un processo di errore ARCH di ordine $q$ può essere rappresentato come
\[
u_t = \sigma_t \varepsilon_t; \qquad
\sigma^2_t \equiv {\rm E}(u^2_t|\Omega_{t-1}) = 
\alpha_0 + \sum_{i=1}^q \alpha_i u^2_{t-i}
\]
dove le $\varepsilon_t$ sono indipendenti e identicamente distribuite (iid)
con media zero e varianza uno, e dove $\sigma_t$ è la radice quadrata di
$\sigma^2_t$. $\Omega_{t-1}$ denota il set informativo al tempo $t-1$ e
$\sigma^2_t$ è la varianza condizionale: ossia, la varianza condizionata
all'informazione che risale al tempo $t-1$ e precedente.

È importante notare la differenza tra un processo ARCH e un normale processo di
errore autoregressivo. Quest'ultimo, nel caso più semplice (del primo ordine),
può essere scritto come
\[
u_t = \rho u_{t-1} + \varepsilon_t; \qquad -1 < \rho < 1
\]
dove le $\varepsilon_t$ sono iid con media zero e varianza costante $\sigma^2$.
Con un errore AR(1), se $\rho$ è positivo un valore positivo di $u_t$ tenderà ad
essere seguito, con probabilità maggiore di 0.5, da un valore positivo
$u_{t+1}$.  Con un processo di errore ARCH, un errore $u_t$ dal valore assoluto
elevato tenderà ad essere seguito da valori a loro volta elevati, ma senza
assumere che i valori successivi siano dello stesso segno. La presenza di
processi ARCH nelle serie finanziarie è un ``fatto stilizzato'' ed è coerente
con l'ipotesi di efficienza dei mercati; d'altra parte, un comportamento
autoregressivo dei prezzi dei titoli violerebbe l'efficienza del mercato.

È possibile testare per l'esistenza di un ARCH di ordine $q$ nel modo seguente:
\begin{enumerate}
\item Stimare il modello in esame con OLS e salvare i quadrati dei residui,
  $\hat{u}^2_t$.
\item Eseguire una regressione ausiliaria in cui i quadrati dei residui sono
  regrediti su una costante e su $q$ ritardi propri.
\item Trovare il valore $TR^2$ (ampiezza campionaria moltiplicata per $R^2$ non
  corretto) per la regressione ausiliaria.
\item Confrontare il valore $TR^2$ con la distribuzione $\chi^2$ con $q$ gradi
  di libertà, e se il p-value è ``abbastanza piccolo'' rifiutare l'ipotesi nulla
  di omoschedasticità, in favore dell'ipotesi alternativa dell'esistenza di un
  processo ARCH($q$).
\end{enumerate}

Questo test è implementato in \app{gretl} con il comando \cmd{arch}. Questo
comando può essere eseguito dopo la stima OLS di un modello di serie storiche, o
selezionandolo dal menù ``Test'' della finestra del modello (sempre dopo una
stima OLS). Verrà mostrato il risultato del test, e, se il valore
$TR^2$ dalla regressione ausiliaria ha un p-value minore di 0.10,
vengono mostrate anche le stime ARCH. Queste stime sono sotto forma di minimi
quadrati generalizzati (Generalized Least Squares, GLS), in particolare di
minimi quadrati ponderati, dove i pesi sono inversamente proporzionali agli
scarti quadratici medi stimati degli errori, $\hat{\sigma}_t$, derivati dalla
regressione ausiliaria.

Inoltre, il test ARCH è disponibile dopo aver stimato un'autoregressione
vettoriale (VAR). In questo caso però non viene eseguita la stima GLS.

\subsection{GARCH}
\label{subsec:garch}

Il semplice processo ARCH($q$) è utile per introdurre il concetto generale di
eteroschedasticità condizionale nelle serie storiche, ma si è rivelato
insufficiente per il lavoro empirico. La dinamica della varianza dell'errore
consentita dal modello ARCH($q$) non è abbastanza ricca per rappresentare
l'andamento tipico dei dati finanziari. Oggi è di uso più comune il modello ARCH
generalizzato, o GARCH.

La rappresentazione della varianza di un processo nel modello GARCH è abbastanza
(ma non esattamente) simile alla rappresentazione ARMA del livello di una serie
storica. La varianza al tempo $t$ può dipendere sia dai valori passati della
varianza, sia dai valori passati dei quadrati degli errori, come mostra il
seguente sistema di equazioni:
\begin{eqnarray}
  \label{eq:garch-meaneq}
  y_t &  = & X_t \beta + u_t \\
  \label{eq:garch-epseq}
  u_t &  = & \sigma_t \varepsilon_t \\
  \label{eq:garch-vareq}
  \sigma^2_t & = & \alpha_0 + \sum_{i=1}^q \alpha_i u^2_{t-i} +
	  \sum_{j=1}^p \delta_i \sigma^2_{t-j}
\end{eqnarray}

Come nel caso precedente, $\varepsilon_t$ è una variabile iid con varianza unitaria.
$X_t$ è una matrice di regressori (o nel caso più semplice un vettore con
elementi pari a 1, che consente una media di $y_t$ diversa da zero). Si noti che
se $p=0$, il GARCH si riduce a un ARCH($q$): la generalizzazione è incorporata
nei termini $\delta_i$ che moltiplicano i valori precedenti della varianza
dell'errore.

In linea di principio, l'innovazione sottostante, $\varepsilon_t$, potrebbe
seguire una qualsiasi distribuzione di probabilità, e oltre all'ovvia candidata
rappresentata dalla normale, o Gaussiana, anche la distribuzione $t$ è stata
usata in questo contesto. Al momento \app{gretl} gestisce solo il caso in cui
$\varepsilon_t$ viene ipotizzata Gaussiana. Però se si usa l'opzione
\verb|--robust| del comando \cmd{garch}, lo stimatore usato da \app{gretl} per
la matrice di covarianza può essere considerato uno stimatore di quasi massima
verosimiglianza anche con disturbi non normali. Si veda oltre per le altre
opzioni che riguardano la matrice di covarianza GARCH.

Esempio:
\begin{code}
garch p q ; y const x
\end{code}
dove \verb|p| $\ge 0$ e \verb|q| $>0$ denotano i rispettivi ordini di ritardo
come mostrati nell'equazione (\ref{eq:garch-vareq}).  Questi valori possono
essere forniti in forma numerica o come nomi di variabili scalari preesistenti.

\subsection{Stima GARCH}
\label{subsec:garch-est}

La stima dei parametri di un modello GARCH non è per nulla un compito semplice.
Si consideri l'equazione~\ref{eq:garch-vareq}: la varianza condizionale in ogni
periodo, $\sigma^2_t$, dipende dalla varianza condizionale nei periodi
precedenti, ma $\sigma^2_t$ non è osservata e deve essere stimata con qualche
tipo di procedura di massima verosimiglianza. \app{Gretl} usa il metodo proposto
da Fiorentini, Calzolari e Panattoni (1996)\footnote{L'algoritmo si basa sul
codice Fortran rilasciato dagli autori nell'archivio del \textit{Journal of
Applied Econometrics} ed è usato per gentile concessione del Professor
Fiorentini.} che è stato adottato come metro di paragone nello studio dei
risultati GARCH di McCullough e Renfro (1998). Esso usa le derivate analitiche
prime e seconde della log-verosimiglianza, adotta un algoritmo del gradiente
misto, sfruttando la matrice informativa nelle prime iterazioni, e quindi passa
all'Hessiano in prossimità della massima verosimiglianza (questo andamento può
essere verificato usando l'opzione \verb|--verbose| del comando \cmd{garch} di
\app{gretl}).

Sono disponibili varie opzioni per il calcolo della matrice di covarianza delle
stime dei parametri ottenute con il comando \cmd{garch}. Per prima cosa, è
possibile scegliere tra uno stimatore ``standard'' e uno ``robusto''.
La scelta predefinita è quella dell'Hessiano, a meno che non si usi l'opzione
\verb|--robust|, nel cui caso viene usato lo stimatore QML. Una scelta più
dettagliata è disponibile usando il comando \cmd{set}, come mostrato nella
tabella~\ref{tab:garch-vcv}.

\begin{table}[htbp]
\caption{Opzioni per la matrice di covarianza GARCH}
\label{tab:garch-vcv}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\textit{Commando}} &
\multicolumn{1}{c}{\textit{Effetto}} \\ [4pt]
\texttt{set garch\_vcv hessian} & Usa l'Hessiano \\
\texttt{set garch\_vcv im} & Usa la matrice di informazione \\
\texttt{set garch\_vcv op} & Usa il prodotto esterno del gradiente \\
\texttt{set garch\_vcv qml} & Stimatore QML \\
\texttt{set garch\_vcv bw} & Stimatore ``sandwich'' di Bollerslev--Wooldridge
\end{tabular}
\end{center}
\end{table}

Non è infrequente, nella stima di un modello GARCH, che il calcolo iterativo
delle stime fallisca nel raggiungere la convergenza. Affinché un modello GARCH
abbia senso, sono necessari vincoli stringenti sui valori ammissibili dei
parametri, e non sempre esiste un insieme di valori all'interno dello spazio dei
parametri per cui la verosimiglianza viene massimizzata.

I vincoli in questione possono essere spiegati riferendosi al più semplice (e
più comune) modello GARCH, dove $p = q = 1$. Nel modello GARCH(1, 1), la varianza
condizionale è
\begin{equation}
\label{eq:condvar}
\sigma^2_t = \alpha_0 + \alpha_1 u^2_{t-1} + \delta_1 \sigma^2_{t-1}
\end{equation}
Prendendo il valore atteso non condizionale della (\ref{eq:condvar}) si ottiene
\[
\sigma^2 = \alpha_0 + \alpha_1 \sigma^2 + \delta_1 \sigma^2
\]
così che
\[
\sigma^2 = \frac{\alpha_0}{1 - \alpha_1 - \delta_1}
\]
Affinché questa varianza non condizionale esista, occorre che
$\alpha_1 + \delta_1 < 1$, e quindi occorre richiedere $\alpha_0 > 0$.

Un motivo comune per la non convergenza delle stime GARCH (ossia, un motivo
comune per la non esistenza di valori $\alpha_i$ e $\delta_i$ che soddisfano le
condizioni precedenti e nello stesso tempo massimizzano la verosimiglianza dei
dati) è la cattiva specificazione del modello. È importante rendersi conto che
il modello GARCH in sé prevede \textit{solamente} che la volatilità dei dati dipende 
dal tempo. Se la \textit{media} della serie in questione non è costante, o se il
processo di errore non è solo eteroschedastico ma è anche autoregressivo, è
necessario tener conto di questi fatti per formulare un modello appropriato. Ad
esempio, può essere necessario dover prendere la differenza prima della
variabile in questione e/o aggiungere opportuni regressori $X_t$ al modello,
come mostrato nella (\ref{eq:garch-meaneq}).

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "gretl-guide-it"
%%% End: 

